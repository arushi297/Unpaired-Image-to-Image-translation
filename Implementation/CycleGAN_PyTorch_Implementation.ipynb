{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "imNXxFGjhhqF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DdQ79H2WJ_9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms\n",
        "import argparse\n",
        "import os, itertools\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.utils.data as data\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset preparation and Parameter Setting"
      ],
      "metadata": {
        "id": "OqwVGEA1hftH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the argparse module to define and parse command line arguments. It sets parameters for the data set, model, and learning. It also defines directories for loading data and saving results. The values of the arguments are printed and stored in the params variable."
      ],
      "metadata": {
        "id": "2xFhqW0sZDvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "#Data Set Parameter\n",
        "parser.add_argument('--dataset', required=False, default='summer2winter', help='input dataset')\n",
        "parser.add_argument('--batch_size', type=int, default=1, help='train batch size')\n",
        "parser.add_argument('--input_size', type=int, default=256, help='input size')\n",
        "parser.add_argument('--resize_scale', type=int, default=286, help='resize scale (0 is false)')\n",
        "parser.add_argument('--crop_size', type=int, default=256, help='crop size (0 is false)')\n",
        "parser.add_argument('--fliplr', type=bool, default=True, help='random fliplr True of False')\n",
        "\n",
        "#Model Parameters \n",
        "parser.add_argument('--ngf', type=int, default=32) # number of generator filters\n",
        "parser.add_argument('--ndf', type=int, default=64) # number of discriminator filters\n",
        "parser.add_argument('--num_resnet', type=int, default=6, help='number of resnet blocks in generator')\n",
        "\n",
        "#Learning Parameters\n",
        "parser.add_argument('--num_epochs', type=int, default=70, help='number of train epochs')\n",
        "parser.add_argument('--decay_epoch', type=int, default=100, help='start decaying learning rate after this number')\n",
        "parser.add_argument('--lrG', type=float, default=0.0002, help='learning rate for generator, default=0.0002')\n",
        "parser.add_argument('--lrD', type=float, default=0.0002, help='learning rate for discriminator, default=0.0002')\n",
        "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for Adam optimizer')\n",
        "parser.add_argument('--beta2', type=float, default=0.999, help='beta2 for Adam optimizer')\n",
        "parser.add_argument('--lambdaA', type=float, default=10, help='lambdaA for cycle loss')\n",
        "parser.add_argument('--lambdaB', type=float, default=10, help='lambdaB for cycle loss')\n",
        "params = parser.parse_args([])\n",
        "print(params)\n",
        "\n",
        "# Directories for loading data and saving results\n",
        "data_dir = '/content/data'\n",
        "save_dir = '/content/results/'\n",
        "plot_gif_dir = '/content/results/plot_gif/'\n",
        "test_res_dir = '/content/test_results/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCcbagfqak3Z",
        "outputId": "e719d2f6-cc69-435a-da89-e50c6b70d507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(dataset='summer2winter', batch_size=1, input_size=256, resize_scale=286, crop_size=256, fliplr=True, ngf=32, ndf=64, num_resnet=6, num_epochs=70, decay_epoch=100, lrG=0.0001, lrD=0.0001, beta1=0.5, beta2=0.999, lambdaA=10, lambdaB=10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensuring that the directories exist and can be used for storing and loading data and results."
      ],
      "metadata": {
        "id": "xFEh_bw4ZONG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir) \n",
        "\n",
        "if not os.path.exists(test_res_dir):\n",
        "    os.makedirs(test_res_dir)   \n",
        "\n",
        "if not os.path.exists(plot_gif_dir):\n",
        "    os.makedirs(plot_gif_dir) "
      ],
      "metadata": {
        "id": "dIi5kxbTl8tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(data_dir)\n",
        "!pip install kaggle --upgrade\n",
        "os.environ['KAGGLE_USERNAME'] = ''\n",
        "os.environ['KAGGLE_KEY'] = ''\n",
        "\n",
        "!kaggle datasets download -d balraj98/summer2winter-yosemite\n",
        "!unzip summer2winter-yosemite.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35uMv2lMWdER",
        "outputId": "39e90b90-d033-4612-a857-e65d43d6cfc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Downloading summer2winter-yosemite.zip to /content/data\n",
            " 89% 113M/126M [00:01<00:00, 69.7MB/s] \n",
            "100% 126M/126M [00:01<00:00, 73.2MB/s]\n",
            "Archive:  summer2winter-yosemite.zip\n",
            "  inflating: metadata.csv            \n",
            "  inflating: testA/2010-09-07 12_23_20.jpg  \n",
            "  inflating: testA/2010-10-05 13_45_11.jpg  \n",
            "  inflating: testA/2010-10-05 19_08_31.jpg  \n",
            "  inflating: testA/2011-05-23 17_46_40.jpg  \n",
            "  inflating: testA/2011-05-26 15_06_01.jpg  \n",
            "  inflating: testA/2011-05-28 15_13_21.jpg  \n",
            "  inflating: testA/2011-05-29 10_20_21.jpg  \n",
            "  inflating: testA/2011-05-29 13_29_21.jpg  \n",
            "  inflating: testA/2011-06-03 03_36_41.jpg  \n",
            "  inflating: testA/2011-06-03 15_29_50.jpg  \n",
            "  inflating: testA/2011-06-03 21_27_20.jpg  \n",
            "  inflating: testA/2011-06-04 19_38_11.jpg  \n",
            "  inflating: testA/2011-06-09 12_02_20.jpg  \n",
            "  inflating: testA/2011-06-14 23_29_30.jpg  \n",
            "  inflating: testA/2011-06-20 08_47_21.jpg  \n",
            "  inflating: testA/2011-06-26 19_33_40.jpg  \n",
            "  inflating: testA/2011-06-27 23_17_41.jpg  \n",
            "  inflating: testA/2011-06-29 20_57_51.jpg  \n",
            "  inflating: testA/2011-07-01 00_00_00.jpg  \n",
            "  inflating: testA/2011-07-02 10_57_31.jpg  \n",
            "  inflating: testA/2011-07-03 11_01_20.jpg  \n",
            "  inflating: testA/2011-07-03 17_23_51.jpg  \n",
            "  inflating: testA/2011-07-05 10_40_51.jpg  \n",
            "  inflating: testA/2011-07-05 11_52_10.jpg  \n",
            "  inflating: testA/2011-07-06 16_55_20.jpg  \n",
            "  inflating: testA/2011-07-08 15_49_30.jpg  \n",
            "  inflating: testA/2011-07-10 23_16_20.jpg  \n",
            "  inflating: testA/2011-07-11 23_18_31.jpg  \n",
            "  inflating: testA/2011-07-12 09_31_30.jpg  \n",
            "  inflating: testA/2011-07-12 17_33_01.jpg  \n",
            "  inflating: testA/2011-07-15 15_00_00.jpg  \n",
            "  inflating: testA/2011-07-22 18_53_10.jpg  \n",
            "  inflating: testA/2011-08-01 00_32_10.jpg  \n",
            "  inflating: testA/2011-08-04 17_22_40.jpg  \n",
            "  inflating: testA/2011-08-07 06_26_21.jpg  \n",
            "  inflating: testA/2011-08-11 15_32_10.jpg  \n",
            "  inflating: testA/2011-08-11 16_16_41.jpg  \n",
            "  inflating: testA/2011-08-13 16_50_20.jpg  \n",
            "  inflating: testA/2011-08-14 22_32_41.jpg  \n",
            "  inflating: testA/2011-08-16 09_43_51.jpg  \n",
            "  inflating: testA/2011-08-17 22_49_50.jpg  \n",
            "  inflating: testA/2011-08-18 18_37_21.jpg  \n",
            "  inflating: testA/2011-08-18 23_29_51.jpg  \n",
            "  inflating: testA/2011-08-20 16_07_10.jpg  \n",
            "  inflating: testA/2011-08-21 16_52_50.jpg  \n",
            "  inflating: testA/2011-08-24 19_39_10.jpg  \n",
            "  inflating: testA/2011-08-28 06_44_10.jpg  \n",
            "  inflating: testA/2011-08-29 17_50_50.jpg  \n",
            "  inflating: testA/2011-08-30 23_13_10.jpg  \n",
            "  inflating: testA/2011-09-02 12_31_40.jpg  \n",
            "  inflating: testA/2011-09-02 23_01_11.jpg  \n",
            "  inflating: testA/2011-09-04 05_55_21.jpg  \n",
            "  inflating: testA/2011-09-04 15_51_51.jpg  \n",
            "  inflating: testA/2011-09-09 10_40_40.jpg  \n",
            "  inflating: testA/2011-09-10 19_18_10.jpg  \n",
            "  inflating: testA/2011-09-11 00_22_50.jpg  \n",
            "  inflating: testA/2011-09-13 23_03_31.jpg  \n",
            "  inflating: testA/2011-09-14 22_27_01.jpg  \n",
            "  inflating: testA/2011-10-12 01_13_31.jpg  \n",
            "  inflating: testA/2011-11-24 08_43_51.jpg  \n",
            "  inflating: testA/2012-02-24 14_44_31.jpg  \n",
            "  inflating: testA/2012-05-15 07_40_41.jpg  \n",
            "  inflating: testA/2012-05-15 11_19_51.jpg  \n",
            "  inflating: testA/2012-05-16 07_48_01.jpg  \n",
            "  inflating: testA/2012-05-17 13_40_40.jpg  \n",
            "  inflating: testA/2012-05-17 14_33_00.jpg  \n",
            "  inflating: testA/2012-05-17 15_30_10.jpg  \n",
            "  inflating: testA/2012-05-20 11_16_50.jpg  \n",
            "  inflating: testA/2012-05-21 03_03_01.jpg  \n",
            "  inflating: testA/2012-05-28 23_58_50.jpg  \n",
            "  inflating: testA/2012-06-01 00_00_00.jpg  \n",
            "  inflating: testA/2012-06-03 14_20_10.jpg  \n",
            "  inflating: testA/2012-06-05 16_13_50.jpg  \n",
            "  inflating: testA/2012-06-09 08_51_30.jpg  \n",
            "  inflating: testA/2012-06-14 05_38_40.jpg  \n",
            "  inflating: testA/2012-06-14 16_55_30.jpg  \n",
            "  inflating: testA/2012-06-15 20_12_21.jpg  \n",
            "  inflating: testA/2012-06-24 17_16_11.jpg  \n",
            "  inflating: testA/2012-06-26 23_28_50.jpg  \n",
            "  inflating: testA/2012-07-02 08_16_51.jpg  \n",
            "  inflating: testA/2012-07-04 19_45_31.jpg  \n",
            "  inflating: testA/2012-07-05 01_19_10.jpg  \n",
            "  inflating: testA/2012-07-07 00_25_30.jpg  \n",
            "  inflating: testA/2012-07-08 08_32_51.jpg  \n",
            "  inflating: testA/2012-07-08 16_40_31.jpg  \n",
            "  inflating: testA/2012-07-11 14_42_10.jpg  \n",
            "  inflating: testA/2012-07-13 20_42_21.jpg  \n",
            "  inflating: testA/2012-07-14 04_40_30.jpg  \n",
            "  inflating: testA/2012-07-24 14_14_10.jpg  \n",
            "  inflating: testA/2012-07-27 04_56_41.jpg  \n",
            "  inflating: testA/2012-07-31 21_49_20.jpg  \n",
            "  inflating: testA/2012-08-01 00_00_00.jpg  \n",
            "  inflating: testA/2012-08-03 21_43_11.jpg  \n",
            "  inflating: testA/2012-08-07 10_29_31.jpg  \n",
            "  inflating: testA/2012-08-08 12_37_01.jpg  \n",
            "  inflating: testA/2012-08-09 20_46_11.jpg  \n",
            "  inflating: testA/2012-08-15 09_39_40.jpg  \n",
            "  inflating: testA/2012-08-20 12_51_40.jpg  \n",
            "  inflating: testA/2012-08-22 13_24_00.jpg  \n",
            "  inflating: testA/2012-08-31 00_15_10.jpg  \n",
            "  inflating: testA/2012-09-01 00_00_00.jpg  \n",
            "  inflating: testA/2012-09-02 07_56_40.jpg  \n",
            "  inflating: testA/2012-09-02 17_42_41.jpg  \n",
            "  inflating: testA/2012-09-05 04_45_40.jpg  \n",
            "  inflating: testA/2012-09-10 18_45_10.jpg  \n",
            "  inflating: testA/2012-09-15 12_40_30.jpg  \n",
            "  inflating: testA/2012-09-19 15_49_01.jpg  \n",
            "  inflating: testA/2013-05-15 14_16_11.jpg  \n",
            "  inflating: testA/2013-05-22 00_17_20.jpg  \n",
            "  inflating: testA/2013-05-30 19_59_00.jpg  \n",
            "  inflating: testA/2013-06-21 12_07_40.jpg  \n",
            "  inflating: testA/2013-06-23 02_33_21.jpg  \n",
            "  inflating: testA/2013-06-25 19_25_21.jpg  \n",
            "  inflating: testA/2013-06-27 03_56_41.jpg  \n",
            "  inflating: testA/2013-06-28 12_07_30.jpg  \n",
            "  inflating: testA/2013-07-04 05_27_51.jpg  \n",
            "  inflating: testA/2013-07-04 20_50_50.jpg  \n",
            "  inflating: testA/2013-07-06 22_41_01.jpg  \n",
            "  inflating: testA/2013-07-11 11_43_11.jpg  \n",
            "  inflating: testA/2013-07-12 20_32_51.jpg  \n",
            "  inflating: testA/2013-07-19 20_17_50.jpg  \n",
            "  inflating: testA/2013-07-22 00_17_40.jpg  \n",
            "  inflating: testA/2013-07-25 14_04_10.jpg  \n",
            "  inflating: testA/2013-07-27 04_16_21.jpg  \n",
            "  inflating: testA/2013-07-29 18_38_51.jpg  \n",
            "  inflating: testA/2013-08-06 09_04_50.jpg  \n",
            "  inflating: testA/2013-08-07 08_22_20.jpg  \n",
            "  inflating: testA/2013-08-08 08_25_11.jpg  \n",
            "  inflating: testA/2013-08-09 20_45_31.jpg  \n",
            "  inflating: testA/2013-08-12 21_43_30.jpg  \n",
            "  inflating: testA/2013-08-13 13_07_51.jpg  \n",
            "  inflating: testA/2013-08-13 19_51_41.jpg  \n",
            "  inflating: testA/2013-08-13 20_12_30.jpg  \n",
            "  inflating: testA/2013-08-17 03_43_50.jpg  \n",
            "  inflating: testA/2013-08-20 01_06_51.jpg  \n",
            "  inflating: testA/2013-08-21 04_54_41.jpg  \n",
            "  inflating: testA/2013-08-22 00_47_11.jpg  \n",
            "  inflating: testA/2013-08-23 20_48_11.jpg  \n",
            "  inflating: testA/2013-08-27 12_17_11.jpg  \n",
            "  inflating: testA/2013-08-28 06_26_41.jpg  \n",
            "  inflating: testA/2013-09-01 18_51_20.jpg  \n",
            "  inflating: testA/2013-09-02 11_07_31.jpg  \n",
            "  inflating: testA/2013-09-04 08_52_21.jpg  \n",
            "  inflating: testA/2013-09-09 15_09_50.jpg  \n",
            "  inflating: testA/2013-09-11 03_06_00.jpg  \n",
            "  inflating: testA/2013-09-11 19_11_41.jpg  \n",
            "  inflating: testA/2013-09-14 12_02_11.jpg  \n",
            "  inflating: testA/2013-12-02 10_39_51.jpg  \n",
            "  inflating: testA/2013-12-10 22_07_11.jpg  \n",
            "  inflating: testA/2014-01-21 05_13_00.jpg  \n",
            "  inflating: testA/2014-02-14 09_28_41.jpg  \n",
            "  inflating: testA/2014-04-04 10_50_01.jpg  \n",
            "  inflating: testA/2014-05-18 10_31_20.jpg  \n",
            "  inflating: testA/2014-05-19 05_07_21.jpg  \n",
            "  inflating: testA/2014-05-22 22_17_31.jpg  \n",
            "  inflating: testA/2014-05-24 03_00_10.jpg  \n",
            "  inflating: testA/2014-06-06 00_06_00.jpg  \n",
            "  inflating: testA/2014-06-07 01_21_41.jpg  \n",
            "  inflating: testA/2014-06-29 17_17_01.jpg  \n",
            "  inflating: testA/2014-07-01 00_00_00.jpg  \n",
            "  inflating: testA/2014-07-01 14_34_31.jpg  \n",
            "  inflating: testA/2014-07-01 23_36_11.jpg  \n",
            "  inflating: testA/2014-07-05 20_12_01.jpg  \n",
            "  inflating: testA/2014-07-05 20_15_00.jpg  \n",
            "  inflating: testA/2014-07-06 10_36_51.jpg  \n",
            "  inflating: testA/2014-07-14 19_49_41.jpg  \n",
            "  inflating: testA/2014-07-18 03_58_31.jpg  \n",
            "  inflating: testA/2014-07-19 04_26_01.jpg  \n",
            "  inflating: testA/2014-07-19 16_10_10.jpg  \n",
            "  inflating: testA/2014-07-19 17_48_21.jpg  \n",
            "  inflating: testA/2014-07-31 15_47_30.jpg  \n",
            "  inflating: testA/2014-07-31 22_48_41.jpg  \n",
            "  inflating: testA/2014-08-08 02_11_41.jpg  \n",
            "  inflating: testA/2014-08-09 18_26_40.jpg  \n",
            "  inflating: testA/2014-08-12 20_03_01.jpg  \n",
            "  inflating: testA/2014-08-13 22_02_31.jpg  \n",
            "  inflating: testA/2014-08-17 07_22_51.jpg  \n",
            "  inflating: testA/2014-08-24 15_57_50.jpg  \n",
            "  inflating: testA/2014-08-29 19_35_20.jpg  \n",
            "  inflating: testA/2014-08-30 17_14_40.jpg  \n",
            "  inflating: testA/2014-08-30 19_29_11.jpg  \n",
            "  inflating: testA/2014-09-07 18_07_50.jpg  \n",
            "  inflating: testA/2014-09-10 13_20_11.jpg  \n",
            "  inflating: testA/2014-09-10 21_23_00.jpg  \n",
            "  inflating: testA/2014-09-11 03_46_00.jpg  \n",
            "  inflating: testA/2014-09-14 20_39_50.jpg  \n",
            "  inflating: testA/2014-10-04 14_50_41.jpg  \n",
            "  inflating: testA/2014-10-17 23_25_01.jpg  \n",
            "  inflating: testA/2014-12-04 06_39_00.jpg  \n",
            "  inflating: testA/2015-01-21 07_56_30.jpg  \n",
            "  inflating: testA/2015-03-02 07_32_00.jpg  \n",
            "  inflating: testA/2015-04-10 14_20_11.jpg  \n",
            "  inflating: testA/2015-05-17 21_01_00.jpg  \n",
            "  inflating: testA/2015-05-27 05_15_41.jpg  \n",
            "  inflating: testA/2015-05-28 11_54_11.jpg  \n",
            "  inflating: testA/2015-05-30 09_24_30.jpg  \n",
            "  inflating: testA/2015-05-30 13_17_30.jpg  \n",
            "  inflating: testA/2015-06-03 14_44_31.jpg  \n",
            "  inflating: testA/2015-06-07 20_36_31.jpg  \n",
            "  inflating: testA/2015-06-12 09_24_11.jpg  \n",
            "  inflating: testA/2015-06-13 06_01_11.jpg  \n",
            "  inflating: testA/2015-06-14 10_50_00.jpg  \n",
            "  inflating: testA/2015-06-14 11_29_21.jpg  \n",
            "  inflating: testA/2015-06-20 05_48_20.jpg  \n",
            "  inflating: testA/2015-06-22 13_13_50.jpg  \n",
            "  inflating: testA/2015-06-25 14_30_40.jpg  \n",
            "  inflating: testA/2015-06-27 13_04_51.jpg  \n",
            "  inflating: testA/2015-06-29 08_41_20.jpg  \n",
            "  inflating: testA/2015-06-29 14_59_01.jpg  \n",
            "  inflating: testA/2015-07-01 23_06_51.jpg  \n",
            "  inflating: testA/2015-07-03 20_07_21.jpg  \n",
            "  inflating: testA/2015-07-04 07_00_01.jpg  \n",
            "  inflating: testA/2015-07-04 20_23_40.jpg  \n",
            "  inflating: testA/2015-07-06 20_20_50.jpg  \n",
            "  inflating: testA/2015-07-07 03_38_10.jpg  \n",
            "  inflating: testA/2015-07-08 02_02_31.jpg  \n",
            "  inflating: testA/2015-07-08 10_20_10.jpg  \n",
            "  inflating: testA/2015-07-10 13_16_51.jpg  \n",
            "  inflating: testA/2015-07-10 14_27_51.jpg  \n",
            "  inflating: testA/2015-07-15 00_39_20.jpg  \n",
            "  inflating: testA/2015-07-15 11_58_01.jpg  \n",
            "  inflating: testA/2015-07-17 05_30_20.jpg  \n",
            "  inflating: testA/2015-07-17 20_20_31.jpg  \n",
            "  inflating: testA/2015-07-23 09_18_31.jpg  \n",
            "  inflating: testA/2015-07-25 17_59_51.jpg  \n",
            "  inflating: testA/2015-07-26 18_54_20.jpg  \n",
            "  inflating: testA/2015-07-28 18_17_21.jpg  \n",
            "  inflating: testA/2015-07-29 10_38_50.jpg  \n",
            "  inflating: testA/2015-08-01 00_00_00.jpg  \n",
            "  inflating: testA/2015-08-03 07_48_51.jpg  \n",
            "  inflating: testA/2015-08-06 01_27_50.jpg  \n",
            "  inflating: testA/2015-08-06 15_45_40.jpg  \n",
            "  inflating: testA/2015-08-07 17_10_41.jpg  \n",
            "  inflating: testA/2015-08-12 19_56_20.jpg  \n",
            "  inflating: testA/2015-08-13 00_33_40.jpg  \n",
            "  inflating: testA/2015-08-13 20_10_21.jpg  \n",
            "  inflating: testA/2015-08-14 12_30_00.jpg  \n",
            "  inflating: testA/2015-08-14 15_49_40.jpg  \n",
            "  inflating: testA/2015-08-20 00_10_31.jpg  \n",
            "  inflating: testA/2015-08-24 07_22_30.jpg  \n",
            "  inflating: testA/2015-08-26 16_44_51.jpg  \n",
            "  inflating: testA/2015-08-30 02_05_30.jpg  \n",
            "  inflating: testA/2015-08-31 14_57_21.jpg  \n",
            "  inflating: testA/2015-09-04 19_13_40.jpg  \n",
            "  inflating: testA/2015-09-04 23_24_40.jpg  \n",
            "  inflating: testA/2015-09-08 18_12_30.jpg  \n",
            "  inflating: testA/2015-09-09 09_28_01.jpg  \n",
            "  inflating: testA/2015-09-09 22_12_40.jpg  \n",
            "  inflating: testA/2015-09-12 19_16_51.jpg  \n",
            "  inflating: testA/2015-09-12 20_18_01.jpg  \n",
            "  inflating: testA/2015-09-13 06_22_00.jpg  \n",
            "  inflating: testA/2015-09-19 18_30_11.jpg  \n",
            "  inflating: testA/2015-10-19 07_19_00.jpg  \n",
            "  inflating: testA/2016-01-02 01_45_01.jpg  \n",
            "  inflating: testA/2016-01-05 13_41_30.jpg  \n",
            "  inflating: testA/2016-05-12 17_00_00.jpg  \n",
            "  inflating: testA/2016-05-15 10_56_50.jpg  \n",
            "  inflating: testA/2016-05-15 14_34_51.jpg  \n",
            "  inflating: testA/2016-05-17 14_48_51.jpg  \n",
            "  inflating: testA/2016-05-17 22_39_30.jpg  \n",
            "  inflating: testA/2016-05-21 00_48_51.jpg  \n",
            "  inflating: testA/2016-05-21 13_24_41.jpg  \n",
            "  inflating: testA/2016-05-24 03_45_20.jpg  \n",
            "  inflating: testA/2016-05-28 08_19_11.jpg  \n",
            "  inflating: testA/2016-05-28 19_30_50.jpg  \n",
            "  inflating: testA/2016-05-29 03_08_40.jpg  \n",
            "  inflating: testA/2016-05-30 19_06_50.jpg  \n",
            "  inflating: testA/2016-05-31 11_07_11.jpg  \n",
            "  inflating: testA/2016-06-07 20_22_20.jpg  \n",
            "  inflating: testA/2016-06-07 23_55_11.jpg  \n",
            "  inflating: testA/2016-06-11 05_21_30.jpg  \n",
            "  inflating: testA/2016-06-11 16_42_20.jpg  \n",
            "  inflating: testA/2016-06-13 09_53_10.jpg  \n",
            "  inflating: testA/2016-06-19 15_16_20.jpg  \n",
            "  inflating: testA/2016-06-19 20_14_10.jpg  \n",
            "  inflating: testA/2016-06-25 09_08_21.jpg  \n",
            "  inflating: testA/2016-06-25 16_29_41.jpg  \n",
            "  inflating: testA/2016-07-03 02_49_41.jpg  \n",
            "  inflating: testA/2016-07-03 16_45_41.jpg  \n",
            "  inflating: testA/2016-07-03 23_52_30.jpg  \n",
            "  inflating: testA/2016-07-07 15_32_11.jpg  \n",
            "  inflating: testA/2016-07-07 18_54_30.jpg  \n",
            "  inflating: testA/2016-07-14 16_58_21.jpg  \n",
            "  inflating: testA/2016-07-14 22_30_41.jpg  \n",
            "  inflating: testA/2016-07-16 20_20_20.jpg  \n",
            "  inflating: testA/2016-07-18 15_01_51.jpg  \n",
            "  inflating: testA/2016-07-18 17_05_40.jpg  \n",
            "  inflating: testA/2016-07-20 12_17_41.jpg  \n",
            "  inflating: testA/2016-07-24 23_14_50.jpg  \n",
            "  inflating: testA/2016-07-31 09_42_40.jpg  \n",
            "  inflating: testA/2016-08-01 21_03_01.jpg  \n",
            "  inflating: testA/2016-08-05 00_00_00.jpg  \n",
            "  inflating: testA/2016-08-12 02_19_50.jpg  \n",
            "  inflating: testA/2016-08-15 19_44_01.jpg  \n",
            "  inflating: testA/2016-08-17 19_34_21.jpg  \n",
            "  inflating: testA/2016-08-27 21_22_00.jpg  \n",
            "  inflating: testA/2016-08-29 07_05_51.jpg  \n",
            "  inflating: testA/2016-09-01 00_00_00.jpg  \n",
            "  inflating: testA/2016-09-01 10_49_50.jpg  \n",
            "  inflating: testA/2016-09-01 19_12_00.jpg  \n",
            "  inflating: testA/2016-09-05 14_01_21.jpg  \n",
            "  inflating: testA/2016-09-07 17_43_20.jpg  \n",
            "  inflating: testA/2016-09-09 06_41_31.jpg  \n",
            "  inflating: testA/2016-09-10 10_05_20.jpg  \n",
            "  inflating: testA/2016-09-10 10_45_11.jpg  \n",
            "  inflating: testA/2016-09-11 09_15_21.jpg  \n",
            "  inflating: testA/2016-09-15 07_31_50.jpg  \n",
            "  inflating: testA/2016-09-20 14_47_31.jpg  \n",
            "  inflating: testA/2016-12-22 08_48_40.jpg  \n",
            "  inflating: testB/2006-04-11 11_21_20.jpg  \n",
            "  inflating: testB/2006-08-26 18_17_00.jpg  \n",
            "  inflating: testB/2007-05-02 01_07_01.jpg  \n",
            "  inflating: testB/2007-05-28 16_24_51.jpg  \n",
            "  inflating: testB/2007-06-24 08_14_31.jpg  \n",
            "  inflating: testB/2007-12-17 20_30_41.jpg  \n",
            "  inflating: testB/2008-01-28 14_23_10.jpg  \n",
            "  inflating: testB/2008-06-12 13_28_41.jpg  \n",
            "  inflating: testB/2008-06-23 19_37_41.jpg  \n",
            "  inflating: testB/2008-07-09 20_32_51.jpg  \n",
            "  inflating: testB/2008-08-24 22_51_11.jpg  \n",
            "  inflating: testB/2008-10-13 16_16_50.jpg  \n",
            "  inflating: testB/2009-01-30 00_38_10.jpg  \n",
            "  inflating: testB/2009-02-01 08_37_11.jpg  \n",
            "  inflating: testB/2009-02-20 00_18_51.jpg  \n",
            "  inflating: testB/2009-02-22 00_35_30.jpg  \n",
            "  inflating: testB/2009-03-12 12_42_31.jpg  \n",
            "  inflating: testB/2009-03-19 16_59_51.jpg  \n",
            "  inflating: testB/2009-03-30 19_12_10.jpg  \n",
            "  inflating: testB/2009-03-31 19_29_30.jpg  \n",
            "  inflating: testB/2009-04-28 12_09_31.jpg  \n",
            "  inflating: testB/2009-11-15 17_03_20.jpg  \n",
            "  inflating: testB/2009-12-24 17_19_20.jpg  \n",
            "  inflating: testB/2009-12-28 08_41_51.jpg  \n",
            "  inflating: testB/2010-01-16 09_45_20.jpg  \n",
            "  inflating: testB/2010-03-15 13_28_31.jpg  \n",
            "  inflating: testB/2010-03-23 14_38_50.jpg  \n",
            "  inflating: testB/2010-09-17 20_48_41.jpg  \n",
            "  inflating: testB/2010-10-07 08_36_51.jpg  \n",
            "  inflating: testB/2010-10-13 23_08_10.jpg  \n",
            "  inflating: testB/2010-10-17 22_30_20.jpg  \n",
            "  inflating: testB/2010-11-01 15_58_51.jpg  \n",
            "  inflating: testB/2010-11-04 16_00_00.jpg  \n",
            "  inflating: testB/2010-12-05 23_59_01.jpg  \n",
            "  inflating: testB/2010-12-27 16_16_10.jpg  \n",
            "  inflating: testB/2010-12-29 23_09_11.jpg  \n",
            "  inflating: testB/2011-01-09 22_59_11.jpg  \n",
            "  inflating: testB/2011-01-16 08_46_31.jpg  \n",
            "  inflating: testB/2011-01-19 18_14_51.jpg  \n",
            "  inflating: testB/2011-01-21 23_22_40.jpg  \n",
            "  inflating: testB/2011-01-22 19_12_20.jpg  \n",
            "  inflating: testB/2011-02-15 11_00_01.jpg  \n",
            "  inflating: testB/2011-03-07 13_37_20.jpg  \n",
            "  inflating: testB/2011-03-12 23_16_01.jpg  \n",
            "  inflating: testB/2011-04-02 12_03_50.jpg  \n",
            "  inflating: testB/2011-05-17 14_54_00.jpg  \n",
            "  inflating: testB/2011-05-30 23_45_11.jpg  \n",
            "  inflating: testB/2011-07-06 14_48_30.jpg  \n",
            "  inflating: testB/2011-08-16 01_51_21.jpg  \n",
            "  inflating: testB/2011-08-19 00_21_40.jpg  \n",
            "  inflating: testB/2011-09-13 09_54_51.jpg  \n",
            "  inflating: testB/2011-09-23 19_18_00.jpg  \n",
            "  inflating: testB/2011-10-31 11_56_00.jpg  \n",
            "  inflating: testB/2011-12-03 11_17_01.jpg  \n",
            "  inflating: testB/2011-12-14 12_29_11.jpg  \n",
            "  inflating: testB/2011-12-29 09_02_31.jpg  \n",
            "  inflating: testB/2011-12-31 08_56_41.jpg  \n",
            "  inflating: testB/2011-12-31 17_23_30.jpg  \n",
            "  inflating: testB/2012-01-01 00_00_00.jpg  \n",
            "  inflating: testB/2012-01-01 00_07_11.jpg  \n",
            "  inflating: testB/2012-01-03 22_37_41.jpg  \n",
            "  inflating: testB/2012-01-07 11_08_11.jpg  \n",
            "  inflating: testB/2012-01-15 17_12_50.jpg  \n",
            "  inflating: testB/2012-01-18 20_28_00.jpg  \n",
            "  inflating: testB/2012-01-25 20_10_21.jpg  \n",
            "  inflating: testB/2012-01-26 04_22_20.jpg  \n",
            "  inflating: testB/2012-01-28 10_51_31.jpg  \n",
            "  inflating: testB/2012-01-29 09_25_31.jpg  \n",
            "  inflating: testB/2012-02-02 17_06_41.jpg  \n",
            "  inflating: testB/2012-02-15 12_22_01.jpg  \n",
            "  inflating: testB/2012-02-17 13_10_50.jpg  \n",
            "  inflating: testB/2012-02-23 20_55_31.jpg  \n",
            "  inflating: testB/2012-02-29 22_20_01.jpg  \n",
            "  inflating: testB/2012-03-21 19_11_31.jpg  \n",
            "  inflating: testB/2012-03-23 01_13_40.jpg  \n",
            "  inflating: testB/2012-04-03 14_36_40.jpg  \n",
            "  inflating: testB/2012-04-10 20_33_00.jpg  \n",
            "  inflating: testB/2012-04-17 12_43_11.jpg  \n",
            "  inflating: testB/2012-04-17 13_47_10.jpg  \n",
            "  inflating: testB/2012-06-15 16_43_00.jpg  \n",
            "  inflating: testB/2012-11-14 17_01_31.jpg  \n",
            "  inflating: testB/2012-11-20 18_34_50.jpg  \n",
            "  inflating: testB/2012-12-05 18_32_11.jpg  \n",
            "  inflating: testB/2012-12-11 18_32_10.jpg  \n",
            "  inflating: testB/2012-12-15 21_53_31.jpg  \n",
            "  inflating: testB/2012-12-16 17_51_00.jpg  \n",
            "  inflating: testB/2012-12-17 23_02_20.jpg  \n",
            "  inflating: testB/2012-12-21 10_10_40.jpg  \n",
            "  inflating: testB/2012-12-22 19_57_10.jpg  \n",
            "  inflating: testB/2012-12-25 14_28_50.jpg  \n",
            "  inflating: testB/2012-12-26 15_00_31.jpg  \n",
            "  inflating: testB/2012-12-27 08_53_50.jpg  \n",
            "  inflating: testB/2012-12-27 17_27_11.jpg  \n",
            "  inflating: testB/2012-12-28 22_50_21.jpg  \n",
            "  inflating: testB/2012-12-29 22_00_30.jpg  \n",
            "  inflating: testB/2012-12-30 08_58_40.jpg  \n",
            "  inflating: testB/2013-01-02 19_16_00.jpg  \n",
            "  inflating: testB/2013-01-03 17_57_00.jpg  \n",
            "  inflating: testB/2013-01-05 15_17_11.jpg  \n",
            "  inflating: testB/2013-01-08 00_53_51.jpg  \n",
            "  inflating: testB/2013-01-12 14_04_51.jpg  \n",
            "  inflating: testB/2013-01-15 02_25_31.jpg  \n",
            "  inflating: testB/2013-01-19 18_13_10.jpg  \n",
            "  inflating: testB/2013-01-23 08_02_01.jpg  \n",
            "  inflating: testB/2013-01-26 06_15_01.jpg  \n",
            "  inflating: testB/2013-01-30 12_51_20.jpg  \n",
            "  inflating: testB/2013-02-13 19_37_40.jpg  \n",
            "  inflating: testB/2013-02-13 22_06_40.jpg  \n",
            "  inflating: testB/2013-02-19 02_00_40.jpg  \n",
            "  inflating: testB/2013-02-20 08_05_00.jpg  \n",
            "  inflating: testB/2013-02-20 20_25_00.jpg  \n",
            "  inflating: testB/2013-03-02 03_57_51.jpg  \n",
            "  inflating: testB/2013-03-02 09_23_00.jpg  \n",
            "  inflating: testB/2013-03-08 07_49_21.jpg  \n",
            "  inflating: testB/2013-03-10 20_44_20.jpg  \n",
            "  inflating: testB/2013-03-12 19_35_40.jpg  \n",
            "  inflating: testB/2013-03-14 21_20_01.jpg  \n",
            "  inflating: testB/2013-03-16 22_09_40.jpg  \n",
            "  inflating: testB/2013-04-10 22_57_01.jpg  \n",
            "  inflating: testB/2013-05-03 06_54_00.jpg  \n",
            "  inflating: testB/2013-05-12 08_39_51.jpg  \n",
            "  inflating: testB/2013-05-15 18_20_40.jpg  \n",
            "  inflating: testB/2013-06-23 11_12_40.jpg  \n",
            "  inflating: testB/2013-08-01 00_20_40.jpg  \n",
            "  inflating: testB/2013-08-19 17_13_00.jpg  \n",
            "  inflating: testB/2013-09-02 08_06_11.jpg  \n",
            "  inflating: testB/2013-10-02 20_41_40.jpg  \n",
            "  inflating: testB/2013-11-25 15_45_21.jpg  \n",
            "  inflating: testB/2013-12-05 00_11_10.jpg  \n",
            "  inflating: testB/2013-12-08 23_03_21.jpg  \n",
            "  inflating: testB/2013-12-23 16_16_01.jpg  \n",
            "  inflating: testB/2013-12-24 17_54_21.jpg  \n",
            "  inflating: testB/2013-12-28 14_46_00.jpg  \n",
            "  inflating: testB/2013-12-30 14_15_40.jpg  \n",
            "  inflating: testB/2014-01-01 00_00_00.jpg  \n",
            "  inflating: testB/2014-01-01 00_59_31.jpg  \n",
            "  inflating: testB/2014-01-09 12_33_30.jpg  \n",
            "  inflating: testB/2014-01-12 14_57_30.jpg  \n",
            "  inflating: testB/2014-01-17 21_39_00.jpg  \n",
            "  inflating: testB/2014-01-23 08_02_11.jpg  \n",
            "  inflating: testB/2014-02-14 09_28_41.jpg  \n",
            "  inflating: testB/2014-02-16 03_34_00.jpg  \n",
            "  inflating: testB/2014-03-08 12_26_51.jpg  \n",
            "  inflating: testB/2014-03-10 15_54_20.jpg  \n",
            "  inflating: testB/2014-03-26 08_00_41.jpg  \n",
            "  inflating: testB/2014-08-19 00_01_21.jpg  \n",
            "  inflating: testB/2014-10-30 17_30_21.jpg  \n",
            "  inflating: testB/2014-11-12 16_55_11.jpg  \n",
            "  inflating: testB/2014-11-14 21_15_11.jpg  \n",
            "  inflating: testB/2015-01-03 18_27_31.jpg  \n",
            "  inflating: testB/2015-01-15 07_37_20.jpg  \n",
            "  inflating: testB/2015-01-17 17_23_41.jpg  \n",
            "  inflating: testB/2015-01-17 17_28_31.jpg  \n",
            "  inflating: testB/2015-02-02 21_53_51.jpg  \n",
            "  inflating: testB/2015-04-09 19_49_21.jpg  \n",
            "  inflating: testB/2015-06-06 08_28_20.jpg  \n",
            "  inflating: testB/2015-06-09 21_44_40.jpg  \n",
            "  inflating: testB/2015-08-10 13_39_30.jpg  \n",
            "  inflating: testB/2015-09-22 00_37_01.jpg  \n",
            "  inflating: testB/2015-11-24 13_27_40.jpg  \n",
            "  inflating: testB/2015-11-26 18_17_01.jpg  \n",
            "  inflating: testB/2015-11-27 19_32_30.jpg  \n",
            "  inflating: testB/2015-11-28 11_56_01.jpg  \n",
            "  inflating: testB/2015-11-28 14_31_41.jpg  \n",
            "  inflating: testB/2015-12-01 18_56_31.jpg  \n",
            "  inflating: testB/2015-12-04 09_58_10.jpg  \n",
            "  inflating: testB/2015-12-04 23_02_30.jpg  \n",
            "  inflating: testB/2015-12-06 19_22_20.jpg  \n",
            "  inflating: testB/2015-12-09 18_26_20.jpg  \n",
            "  inflating: testB/2015-12-11 08_46_51.jpg  \n",
            "  inflating: testB/2015-12-14 19_22_50.jpg  \n",
            "  inflating: testB/2015-12-16 08_32_11.jpg  \n",
            "  inflating: testB/2015-12-18 11_42_10.jpg  \n",
            "  inflating: testB/2015-12-19 18_41_51.jpg  \n",
            "  inflating: testB/2015-12-23 20_24_21.jpg  \n",
            "  inflating: testB/2015-12-27 00_46_41.jpg  \n",
            "  inflating: testB/2015-12-28 07_27_51.jpg  \n",
            "  inflating: testB/2015-12-28 17_44_20.jpg  \n",
            "  inflating: testB/2015-12-31 14_54_20.jpg  \n",
            "  inflating: testB/2015-12-31 17_23_30.jpg  \n",
            "  inflating: testB/2016-01-02 20_15_00.jpg  \n",
            "  inflating: testB/2016-01-03 01_15_50.jpg  \n",
            "  inflating: testB/2016-01-05 10_52_21.jpg  \n",
            "  inflating: testB/2016-01-09 10_43_01.jpg  \n",
            "  inflating: testB/2016-01-10 01_31_41.jpg  \n",
            "  inflating: testB/2016-01-10 20_11_01.jpg  \n",
            "  inflating: testB/2016-01-12 10_28_40.jpg  \n",
            "  inflating: testB/2016-01-12 20_58_51.jpg  \n",
            "  inflating: testB/2016-01-19 15_33_31.jpg  \n",
            "  inflating: testB/2016-01-22 14_09_31.jpg  \n",
            "  inflating: testB/2016-01-23 09_16_20.jpg  \n",
            "  inflating: testB/2016-01-24 16_17_40.jpg  \n",
            "  inflating: testB/2016-01-26 07_40_40.jpg  \n",
            "  inflating: testB/2016-01-27 10_55_50.jpg  \n",
            "  inflating: testB/2016-02-04 14_41_51.jpg  \n",
            "  inflating: testB/2016-02-11 08_52_10.jpg  \n",
            "  inflating: testB/2016-02-11 10_37_00.jpg  \n",
            "  inflating: testB/2016-02-12 08_54_31.jpg  \n",
            "  inflating: testB/2016-02-24 22_02_31.jpg  \n",
            "  inflating: testB/2016-02-27 19_30_10.jpg  \n",
            "  inflating: testB/2016-02-28 04_04_00.jpg  \n",
            "  inflating: testB/2016-02-28 18_19_11.jpg  \n",
            "  inflating: testB/2016-02-28 23_49_50.jpg  \n",
            "  inflating: testB/2016-02-28 23_50_31.jpg  \n",
            "  inflating: testB/2016-03-04 16_21_31.jpg  \n",
            "  inflating: testB/2016-03-11 22_19_10.jpg  \n",
            "  inflating: testB/2016-03-17 21_53_00.jpg  \n",
            "  inflating: testB/2016-04-04 09_26_00.jpg  \n",
            "  inflating: testB/2016-05-10 15_33_51.jpg  \n",
            "  inflating: testB/2016-05-14 14_26_10.jpg  \n",
            "  inflating: testB/2016-05-27 17_56_10.jpg  \n",
            "  inflating: testB/2016-06-15 14_04_11.jpg  \n",
            "  inflating: testB/2016-08-07 15_40_20.jpg  \n",
            "  inflating: testB/2016-08-17 00_35_20.jpg  \n",
            "  inflating: testB/2016-11-11 01_00_51.jpg  \n",
            "  inflating: testB/2016-12-02 07_25_40.jpg  \n",
            "  inflating: testB/2016-12-03 13_08_11.jpg  \n",
            "  inflating: testB/2016-12-06 12_15_00.jpg  \n",
            "  inflating: testB/2016-12-07 20_10_11.jpg  \n",
            "  inflating: testB/2016-12-15 13_21_20.jpg  \n",
            "  inflating: testB/2016-12-21 06_56_11.jpg  \n",
            "  inflating: testB/2016-12-22 10_43_10.jpg  \n",
            "  inflating: testB/2016-12-24 15_16_10.jpg  \n",
            "  inflating: testB/2016-12-28 21_58_50.jpg  \n",
            "  inflating: testB/2016-12-29 15_19_00.jpg  \n",
            "  inflating: testB/2016-12-30 11_28_51.jpg  \n",
            "  inflating: testB/2016-12-31 14_41_50.jpg  \n",
            "  inflating: testB/2017-01-04 16_32_01.jpg  \n",
            "  inflating: testB/2017-01-11 23_11_01.jpg  \n",
            "  inflating: testB/2017-01-12 22_27_10.jpg  \n",
            "  inflating: testB/2017-01-14 08_55_50.jpg  \n",
            "  inflating: testB/2017-01-24 07_01_11.jpg  \n",
            "  inflating: testB/2017-01-31 21_19_41.jpg  \n",
            "  inflating: testB/2017-02-19 07_50_41.jpg  \n",
            "  inflating: testB/2017-02-27 22_10_41.jpg  \n",
            "  inflating: testB/2017-03-03 01_07_50.jpg  \n",
            "  inflating: testB/2017-03-03 09_20_41.jpg  \n",
            "  inflating: testB/2017-03-05 17_15_40.jpg  \n",
            "  inflating: trainA/2009-12-06 06_58_39.jpg  \n",
            "  inflating: trainA/2009-12-24 12_09_12.jpg  \n",
            "  inflating: trainA/2010-02-21 16_52_39.jpg  \n",
            "  inflating: trainA/2010-07-03 22_53_07.jpg  \n",
            "  inflating: trainA/2010-07-13 22_34_03.jpg  \n",
            "  inflating: trainA/2010-08-07 10_18_22.jpg  \n",
            "  inflating: trainA/2010-08-10 00_15_25.jpg  \n",
            "  inflating: trainA/2010-08-24 17_43_18.jpg  \n",
            "  inflating: trainA/2010-09-02 18_48_52.jpg  \n",
            "  inflating: trainA/2010-09-09 11_41_45.jpg  \n",
            "  inflating: trainA/2010-09-11 03_15_45.jpg  \n",
            "  inflating: trainA/2010-09-17 14_59_04.jpg  \n",
            "  inflating: trainA/2010-09-21 06_41_59.jpg  \n",
            "  inflating: trainA/2010-10-09 15_56_24.jpg  \n",
            "  inflating: trainA/2010-11-08 17_33_13.jpg  \n",
            "  inflating: trainA/2011-01-19 14_17_29.jpg  \n",
            "  inflating: trainA/2011-01-23 00_06_43.jpg  \n",
            "  inflating: trainA/2011-02-15 14_41_35.jpg  \n",
            "  inflating: trainA/2011-02-28 14_43_59.jpg  \n",
            "  inflating: trainA/2011-04-11 12_59_33.jpg  \n",
            "  inflating: trainA/2011-05-04 08_59_56.jpg  \n",
            "  inflating: trainA/2011-05-15 10_58_57.jpg  \n",
            "  inflating: trainA/2011-05-15 18_05_22.jpg  \n",
            "  inflating: trainA/2011-05-17 01_22_15.jpg  \n",
            "  inflating: trainA/2011-05-17 15_09_34.jpg  \n",
            "  inflating: trainA/2011-05-19 11_26_37.jpg  \n",
            "  inflating: trainA/2011-05-19 17_27_18.jpg  \n",
            "  inflating: trainA/2011-05-21 00_00_03.jpg  \n",
            "  inflating: trainA/2011-05-21 09_22_37.jpg  \n",
            "  inflating: trainA/2011-05-21 13_16_46.jpg  \n",
            "  inflating: trainA/2011-05-22 14_56_17.jpg  \n",
            "  inflating: trainA/2011-05-22 17_18_42.jpg  \n",
            "  inflating: trainA/2011-05-24 19_18_16.jpg  \n",
            "  inflating: trainA/2011-05-26 15_42_19.jpg  \n",
            "  inflating: trainA/2011-05-26 19_35_25.jpg  \n",
            "  inflating: trainA/2011-05-26 20_52_05.jpg  \n",
            "  inflating: trainA/2011-05-27 03_45_48.jpg  \n",
            "  inflating: trainA/2011-05-27 10_07_09.jpg  \n",
            "  inflating: trainA/2011-05-28 09_45_52.jpg  \n",
            "  inflating: trainA/2011-05-28 17_21_32.jpg  \n",
            "  inflating: trainA/2011-05-29 12_46_29.jpg  \n",
            "  inflating: trainA/2011-05-30 16_53_54.jpg  \n",
            "  inflating: trainA/2011-05-30 18_05_07.jpg  \n",
            "  inflating: trainA/2011-05-30 20_18_25.jpg  \n",
            "  inflating: trainA/2011-05-31 22_24_37.jpg  \n",
            "  inflating: trainA/2011-06-01 14_19_15.jpg  \n",
            "  inflating: trainA/2011-06-02 19_54_59.jpg  \n",
            "  inflating: trainA/2011-06-03 15_23_45.jpg  \n",
            "  inflating: trainA/2011-06-06 06_40_13.jpg  \n",
            "  inflating: trainA/2011-06-06 21_06_06.jpg  \n",
            "  inflating: trainA/2011-06-07 13_42_28.jpg  \n",
            "  inflating: trainA/2011-06-09 09_29_25.jpg  \n",
            "  inflating: trainA/2011-06-10 01_19_14.jpg  \n",
            "  inflating: trainA/2011-06-10 11_07_35.jpg  \n",
            "  inflating: trainA/2011-06-10 18_57_09.jpg  \n",
            "  inflating: trainA/2011-06-11 09_17_48.jpg  \n",
            "  inflating: trainA/2011-06-11 12_24_25.jpg  \n",
            "  inflating: trainA/2011-06-11 14_19_42.jpg  \n",
            "  inflating: trainA/2011-06-11 14_48_42.jpg  \n",
            "  inflating: trainA/2011-06-12 13_08_47.jpg  \n",
            "  inflating: trainA/2011-06-13 11_13_26.jpg  \n",
            "  inflating: trainA/2011-06-13 11_54_12.jpg  \n",
            "  inflating: trainA/2011-06-13 18_41_03.jpg  \n",
            "  inflating: trainA/2011-06-14 11_10_27.jpg  \n",
            "  inflating: trainA/2011-06-14 13_33_53.jpg  \n",
            "  inflating: trainA/2011-06-14 14_27_43.jpg  \n",
            "  inflating: trainA/2011-06-14 23_07_23.jpg  \n",
            "  inflating: trainA/2011-06-15 21_18_44.jpg  \n",
            "  inflating: trainA/2011-06-15 21_28_02.jpg  \n",
            "  inflating: trainA/2011-06-15 22_42_27.jpg  \n",
            "  inflating: trainA/2011-06-16 01_14_07.jpg  \n",
            "  inflating: trainA/2011-06-16 10_36_17.jpg  \n",
            "  inflating: trainA/2011-06-16 13_40_07.jpg  \n",
            "  inflating: trainA/2011-06-16 17_40_39.jpg  \n",
            "  inflating: trainA/2011-06-17 06_31_03.jpg  \n",
            "  inflating: trainA/2011-06-18 10_53_48.jpg  \n",
            "  inflating: trainA/2011-06-18 11_25_48.jpg  \n",
            "  inflating: trainA/2011-06-18 14_29_28.jpg  \n",
            "  inflating: trainA/2011-06-18 19_29_15.jpg  \n",
            "  inflating: trainA/2011-06-18 20_34_43.jpg  \n",
            "  inflating: trainA/2011-06-19 00_47_35.jpg  \n",
            "  inflating: trainA/2011-06-22 13_17_18.jpg  \n",
            "  inflating: trainA/2011-06-22 13_46_17.jpg  \n",
            "  inflating: trainA/2011-06-23 17_51_49.jpg  \n",
            "  inflating: trainA/2011-06-24 02_36_16.jpg  \n",
            "  inflating: trainA/2011-06-24 20_56_22.jpg  \n",
            "  inflating: trainA/2011-06-25 11_10_49.jpg  \n",
            "  inflating: trainA/2011-06-25 18_53_13.jpg  \n",
            "  inflating: trainA/2011-06-26 17_58_48.jpg  \n",
            "  inflating: trainA/2011-06-26 18_41_14.jpg  \n",
            "  inflating: trainA/2011-06-26 21_13_18.jpg  \n",
            "  inflating: trainA/2011-06-27 01_06_52.jpg  \n",
            "  inflating: trainA/2011-06-27 10_27_55.jpg  \n",
            "  inflating: trainA/2011-06-27 10_49_57.jpg  \n",
            "  inflating: trainA/2011-06-27 10_59_38.jpg  \n",
            "  inflating: trainA/2011-06-27 20_24_39.jpg  \n",
            "  inflating: trainA/2011-06-28 08_45_48.jpg  \n",
            "  inflating: trainA/2011-06-28 14_13_16.jpg  \n",
            "  inflating: trainA/2011-06-28 20_00_43.jpg  \n",
            "  inflating: trainA/2011-06-29 08_11_24.jpg  \n",
            "  inflating: trainA/2011-06-30 16_41_08.jpg  \n",
            "  inflating: trainA/2011-06-30 18_09_33.jpg  \n",
            "  inflating: trainA/2011-07-01 15_09_16.jpg  \n",
            "  inflating: trainA/2011-07-01 15_59_44.jpg  \n",
            "  inflating: trainA/2011-07-01 16_47_13.jpg  \n",
            "  inflating: trainA/2011-07-01 23_15_23.jpg  \n",
            "  inflating: trainA/2011-07-02 02_15_07.jpg  \n",
            "  inflating: trainA/2011-07-03 00_29_45.jpg  \n",
            "  inflating: trainA/2011-07-03 04_09_18.jpg  \n",
            "  inflating: trainA/2011-07-03 07_34_06.jpg  \n",
            "  inflating: trainA/2011-07-03 12_04_58.jpg  \n",
            "  inflating: trainA/2011-07-03 18_08_02.jpg  \n",
            "  inflating: trainA/2011-07-03 19_56_13.jpg  \n",
            "  inflating: trainA/2011-07-03 20_55_29.jpg  \n",
            "  inflating: trainA/2011-07-03 23_18_02.jpg  \n",
            "  inflating: trainA/2011-07-04 13_56_35.jpg  \n",
            "  inflating: trainA/2011-07-04 15_59_58.jpg  \n",
            "  inflating: trainA/2011-07-04 17_20_09.jpg  \n",
            "  inflating: trainA/2011-07-04 19_09_37.jpg  \n",
            "  inflating: trainA/2011-07-05 01_15_27.jpg  \n",
            "  inflating: trainA/2011-07-05 03_50_13.jpg  \n",
            "  inflating: trainA/2011-07-05 15_38_57.jpg  \n",
            "  inflating: trainA/2011-07-07 13_24_22.jpg  \n",
            "  inflating: trainA/2011-07-07 15_37_22.jpg  \n",
            "  inflating: trainA/2011-07-07 15_53_38.jpg  \n",
            "  inflating: trainA/2011-07-08 01_32_16.jpg  \n",
            "  inflating: trainA/2011-07-08 11_22_29.jpg  \n",
            "  inflating: trainA/2011-07-09 03_32_34.jpg  \n",
            "  inflating: trainA/2011-07-09 06_38_02.jpg  \n",
            "  inflating: trainA/2011-07-09 14_38_02.jpg  \n",
            "  inflating: trainA/2011-07-09 20_52_39.jpg  \n",
            "  inflating: trainA/2011-07-10 17_15_13.jpg  \n",
            "  inflating: trainA/2011-07-12 06_45_49.jpg  \n",
            "  inflating: trainA/2011-07-12 19_20_05.jpg  \n",
            "  inflating: trainA/2011-07-14 19_10_09.jpg  \n",
            "  inflating: trainA/2011-07-15 04_15_53.jpg  \n",
            "  inflating: trainA/2011-07-15 04_39_13.jpg  \n",
            "  inflating: trainA/2011-07-17 07_47_59.jpg  \n",
            "  inflating: trainA/2011-07-17 15_10_03.jpg  \n",
            "  inflating: trainA/2011-07-18 00_18_16.jpg  \n",
            "  inflating: trainA/2011-07-19 12_22_28.jpg  \n",
            "  inflating: trainA/2011-07-20 00_33_52.jpg  \n",
            "  inflating: trainA/2011-07-22 10_45_52.jpg  \n",
            "  inflating: trainA/2011-07-22 12_12_58.jpg  \n",
            "  inflating: trainA/2011-07-23 00_00_05.jpg  \n",
            "  inflating: trainA/2011-07-23 20_26_12.jpg  \n",
            "  inflating: trainA/2011-07-24 08_33_09.jpg  \n",
            "  inflating: trainA/2011-07-24 12_51_28.jpg  \n",
            "  inflating: trainA/2011-07-25 14_43_07.jpg  \n",
            "  inflating: trainA/2011-07-30 11_04_45.jpg  \n",
            "  inflating: trainA/2011-07-31 17_56_16.jpg  \n",
            "  inflating: trainA/2011-07-31 18_05_16.jpg  \n",
            "  inflating: trainA/2011-08-01 21_10_35.jpg  \n",
            "  inflating: trainA/2011-08-02 00_14_07.jpg  \n",
            "  inflating: trainA/2011-08-02 17_55_36.jpg  \n",
            "  inflating: trainA/2011-08-04 21_26_23.jpg  \n",
            "  inflating: trainA/2011-08-06 14_26_36.jpg  \n",
            "  inflating: trainA/2011-08-06 22_38_35.jpg  \n",
            "  inflating: trainA/2011-08-07 13_23_19.jpg  \n",
            "  inflating: trainA/2011-08-08 02_13_44.jpg  \n",
            "  inflating: trainA/2011-08-08 06_19_46.jpg  \n",
            "  inflating: trainA/2011-08-08 18_20_58.jpg  \n",
            "  inflating: trainA/2011-08-09 03_51_17.jpg  \n",
            "  inflating: trainA/2011-08-12 06_11_52.jpg  \n",
            "  inflating: trainA/2011-08-12 10_38_42.jpg  \n",
            "  inflating: trainA/2011-08-12 15_25_57.jpg  \n",
            "  inflating: trainA/2011-08-12 18_57_04.jpg  \n",
            "  inflating: trainA/2011-08-12 22_20_33.jpg  \n",
            "  inflating: trainA/2011-08-13 11_40_06.jpg  \n",
            "  inflating: trainA/2011-08-14 01_24_02.jpg  \n",
            "  inflating: trainA/2011-08-14 18_01_53.jpg  \n",
            "  inflating: trainA/2011-08-15 15_45_39.jpg  \n",
            "  inflating: trainA/2011-08-17 10_39_42.jpg  \n",
            "  inflating: trainA/2011-08-17 13_02_13.jpg  \n",
            "  inflating: trainA/2011-08-18 21_52_09.jpg  \n",
            "  inflating: trainA/2011-08-19 05_51_16.jpg  \n",
            "  inflating: trainA/2011-08-19 10_33_38.jpg  \n",
            "  inflating: trainA/2011-08-19 11_40_32.jpg  \n",
            "  inflating: trainA/2011-08-20 13_09_55.jpg  \n",
            "  inflating: trainA/2011-08-22 08_32_37.jpg  \n",
            "  inflating: trainA/2011-08-22 17_53_16.jpg  \n",
            "  inflating: trainA/2011-08-23 04_48_29.jpg  \n",
            "  inflating: trainA/2011-08-23 16_04_06.jpg  \n",
            "  inflating: trainA/2011-08-23 23_05_24.jpg  \n",
            "  inflating: trainA/2011-08-24 13_17_22.jpg  \n",
            "  inflating: trainA/2011-08-26 18_11_04.jpg  \n",
            "  inflating: trainA/2011-08-26 19_24_37.jpg  \n",
            "  inflating: trainA/2011-08-27 07_14_02.jpg  \n",
            "  inflating: trainA/2011-08-27 17_42_43.jpg  \n",
            "  inflating: trainA/2011-08-27 21_06_37.jpg  \n",
            "  inflating: trainA/2011-08-27 22_08_52.jpg  \n",
            "  inflating: trainA/2011-08-28 05_55_38.jpg  \n",
            "  inflating: trainA/2011-08-28 07_56_24.jpg  \n",
            "  inflating: trainA/2011-08-28 21_27_59.jpg  \n",
            "  inflating: trainA/2011-08-30 20_24_08.jpg  \n",
            "  inflating: trainA/2011-08-31 06_52_34.jpg  \n",
            "  inflating: trainA/2011-09-01 13_44_45.jpg  \n",
            "  inflating: trainA/2011-09-03 13_43_32.jpg  \n",
            "  inflating: trainA/2011-09-03 16_40_04.jpg  \n",
            "  inflating: trainA/2011-09-05 03_02_57.jpg  \n",
            "  inflating: trainA/2011-09-06 00_44_43.jpg  \n",
            "  inflating: trainA/2011-09-07 09_07_45.jpg  \n",
            "  inflating: trainA/2011-09-07 12_29_45.jpg  \n",
            "  inflating: trainA/2011-09-07 16_54_42.jpg  \n",
            "  inflating: trainA/2011-09-08 02_30_23.jpg  \n",
            "  inflating: trainA/2011-09-08 10_57_37.jpg  \n",
            "  inflating: trainA/2011-09-08 18_41_19.jpg  \n",
            "  inflating: trainA/2011-09-09 16_47_42.jpg  \n",
            "  inflating: trainA/2011-09-10 08_31_54.jpg  \n",
            "  inflating: trainA/2011-09-11 12_13_34.jpg  \n",
            "  inflating: trainA/2011-09-11 12_38_47.jpg  \n",
            "  inflating: trainA/2011-09-12 15_24_14.jpg  \n",
            "  inflating: trainA/2011-09-12 19_17_33.jpg  \n",
            "  inflating: trainA/2011-09-13 06_57_02.jpg  \n",
            "  inflating: trainA/2011-09-13 14_15_54.jpg  \n",
            "  inflating: trainA/2011-09-14 22_23_18.jpg  \n",
            "  inflating: trainA/2011-09-14 23_32_35.jpg  \n",
            "  inflating: trainA/2011-09-15 06_35_17.jpg  \n",
            "  inflating: trainA/2011-09-22 20_18_38.jpg  \n",
            "  inflating: trainA/2011-10-10 17_35_05.jpg  \n",
            "  inflating: trainA/2011-10-10 21_54_58.jpg  \n",
            "  inflating: trainA/2011-11-03 15_48_37.jpg  \n",
            "  inflating: trainA/2011-11-17 12_11_35.jpg  \n",
            "  inflating: trainA/2011-11-28 18_28_49.jpg  \n",
            "  inflating: trainA/2011-11-30 13_16_47.jpg  \n",
            "  inflating: trainA/2012-01-04 21_02_16.jpg  \n",
            "  inflating: trainA/2012-01-06 16_13_52.jpg  \n",
            "  inflating: trainA/2012-02-03 09_18_17.jpg  \n",
            "  inflating: trainA/2012-03-23 00_14_28.jpg  \n",
            "  inflating: trainA/2012-03-26 14_51_19.jpg  \n",
            "  inflating: trainA/2012-04-15 15_32_03.jpg  \n",
            "  inflating: trainA/2012-04-23 15_03_05.jpg  \n",
            "  inflating: trainA/2012-04-25 08_00_19.jpg  \n",
            "  inflating: trainA/2012-04-26 20_00_47.jpg  \n",
            "  inflating: trainA/2012-05-15 08_50_36.jpg  \n",
            "  inflating: trainA/2012-05-15 11_49_08.jpg  \n",
            "  inflating: trainA/2012-05-15 19_29_19.jpg  \n",
            "  inflating: trainA/2012-05-16 18_28_23.jpg  \n",
            "  inflating: trainA/2012-05-19 13_31_28.jpg  \n",
            "  inflating: trainA/2012-05-21 19_57_52.jpg  \n",
            "  inflating: trainA/2012-05-22 07_34_23.jpg  \n",
            "  inflating: trainA/2012-05-24 09_29_03.jpg  \n",
            "  inflating: trainA/2012-05-25 14_16_22.jpg  \n",
            "  inflating: trainA/2012-05-25 20_06_14.jpg  \n",
            "  inflating: trainA/2012-05-26 14_09_54.jpg  \n",
            "  inflating: trainA/2012-05-26 17_08_03.jpg  \n",
            "  inflating: trainA/2012-05-26 18_28_03.jpg  \n",
            "  inflating: trainA/2012-05-27 17_59_16.jpg  \n",
            "  inflating: trainA/2012-05-28 14_33_34.jpg  \n",
            "  inflating: trainA/2012-05-29 17_10_28.jpg  \n",
            "  inflating: trainA/2012-05-30 06_35_44.jpg  \n",
            "  inflating: trainA/2012-06-01 02_17_48.jpg  \n",
            "  inflating: trainA/2012-06-01 16_14_33.jpg  \n",
            "  inflating: trainA/2012-06-01 19_37_52.jpg  \n",
            "  inflating: trainA/2012-06-03 20_17_16.jpg  \n",
            "  inflating: trainA/2012-06-04 13_38_16.jpg  \n",
            "  inflating: trainA/2012-06-04 19_59_13.jpg  \n",
            "  inflating: trainA/2012-06-05 06_09_05.jpg  \n",
            "  inflating: trainA/2012-06-05 12_27_14.jpg  \n",
            "  inflating: trainA/2012-06-06 05_54_05.jpg  \n",
            "  inflating: trainA/2012-06-06 10_23_22.jpg  \n",
            "  inflating: trainA/2012-06-08 10_03_58.jpg  \n",
            "  inflating: trainA/2012-06-09 19_49_22.jpg  \n",
            "  inflating: trainA/2012-06-10 11_56_53.jpg  \n",
            "  inflating: trainA/2012-06-10 17_12_49.jpg  \n",
            "  inflating: trainA/2012-06-11 14_00_34.jpg  \n",
            "  inflating: trainA/2012-06-12 09_12_49.jpg  \n",
            "  inflating: trainA/2012-06-12 16_15_19.jpg  \n",
            "  inflating: trainA/2012-06-12 19_13_58.jpg  \n",
            "  inflating: trainA/2012-06-12 19_16_15.jpg  \n",
            "  inflating: trainA/2012-06-12 22_36_02.jpg  \n",
            "  inflating: trainA/2012-06-13 02_11_06.jpg  \n",
            "  inflating: trainA/2012-06-14 17_12_05.jpg  \n",
            "  inflating: trainA/2012-06-15 09_48_43.jpg  \n",
            "  inflating: trainA/2012-06-16 15_12_07.jpg  \n",
            "  inflating: trainA/2012-06-16 18_54_55.jpg  \n",
            "  inflating: trainA/2012-06-16 18_58_32.jpg  \n",
            "  inflating: trainA/2012-06-17 14_49_18.jpg  \n",
            "  inflating: trainA/2012-06-17 22_08_15.jpg  \n",
            "  inflating: trainA/2012-06-18 18_15_08.jpg  \n",
            "  inflating: trainA/2012-06-19 18_19_25.jpg  \n",
            "  inflating: trainA/2012-06-20 12_38_15.jpg  \n",
            "  inflating: trainA/2012-06-20 20_35_38.jpg  \n",
            "  inflating: trainA/2012-06-20 22_29_56.jpg  \n",
            "  inflating: trainA/2012-06-21 03_33_06.jpg  \n",
            "  inflating: trainA/2012-06-21 20_06_05.jpg  \n",
            "  inflating: trainA/2012-06-22 09_33_14.jpg  \n",
            "  inflating: trainA/2012-06-22 10_43_46.jpg  \n",
            "  inflating: trainA/2012-06-22 13_44_24.jpg  \n",
            "  inflating: trainA/2012-06-23 05_14_12.jpg  \n",
            "  inflating: trainA/2012-06-23 11_13_47.jpg  \n",
            "  inflating: trainA/2012-06-23 20_28_22.jpg  \n",
            "  inflating: trainA/2012-06-23 23_44_46.jpg  \n",
            "  inflating: trainA/2012-06-24 13_18_58.jpg  \n",
            "  inflating: trainA/2012-06-24 22_43_44.jpg  \n",
            "  inflating: trainA/2012-06-25 16_45_36.jpg  \n",
            "  inflating: trainA/2012-06-25 17_05_57.jpg  \n",
            "  inflating: trainA/2012-06-26 11_12_24.jpg  \n",
            "  inflating: trainA/2012-06-27 15_44_12.jpg  \n",
            "  inflating: trainA/2012-06-27 19_50_02.jpg  \n",
            "  inflating: trainA/2012-06-28 08_18_04.jpg  \n",
            "  inflating: trainA/2012-06-30 05_34_08.jpg  \n",
            "  inflating: trainA/2012-07-01 14_32_15.jpg  \n",
            "  inflating: trainA/2012-07-03 08_07_27.jpg  \n",
            "  inflating: trainA/2012-07-03 20_06_53.jpg  \n",
            "  inflating: trainA/2012-07-04 13_35_33.jpg  \n",
            "  inflating: trainA/2012-07-04 22_41_44.jpg  \n",
            "  inflating: trainA/2012-07-06 08_23_45.jpg  \n",
            "  inflating: trainA/2012-07-06 18_06_55.jpg  \n",
            "  inflating: trainA/2012-07-07 11_28_54.jpg  \n",
            "  inflating: trainA/2012-07-07 15_24_03.jpg  \n",
            "  inflating: trainA/2012-07-07 20_17_57.jpg  \n",
            "  inflating: trainA/2012-07-09 20_27_59.jpg  \n",
            "  inflating: trainA/2012-07-10 18_40_19.jpg  \n",
            "  inflating: trainA/2012-07-11 13_53_39.jpg  \n",
            "  inflating: trainA/2012-07-11 19_10_44.jpg  \n",
            "  inflating: trainA/2012-07-12 10_53_19.jpg  \n",
            "  inflating: trainA/2012-07-12 19_24_38.jpg  \n",
            "  inflating: trainA/2012-07-13 11_00_25.jpg  \n",
            "  inflating: trainA/2012-07-15 12_37_08.jpg  \n",
            "  inflating: trainA/2012-07-16 21_12_57.jpg  \n",
            "  inflating: trainA/2012-07-17 07_03_56.jpg  \n",
            "  inflating: trainA/2012-07-17 14_05_09.jpg  \n",
            "  inflating: trainA/2012-07-17 16_29_35.jpg  \n",
            "  inflating: trainA/2012-07-18 08_16_18.jpg  \n",
            "  inflating: trainA/2012-07-18 21_23_07.jpg  \n",
            "  inflating: trainA/2012-07-19 05_01_39.jpg  \n",
            "  inflating: trainA/2012-07-19 06_59_54.jpg  \n",
            "  inflating: trainA/2012-07-20 19_58_48.jpg  \n",
            "  inflating: trainA/2012-07-20 20_00_15.jpg  \n",
            "  inflating: trainA/2012-07-20 23_06_36.jpg  \n",
            "  inflating: trainA/2012-07-21 16_29_27.jpg  \n",
            "  inflating: trainA/2012-07-24 18_29_34.jpg  \n",
            "  inflating: trainA/2012-07-24 19_25_34.jpg  \n",
            "  inflating: trainA/2012-07-27 17_20_57.jpg  \n",
            "  inflating: trainA/2012-07-27 17_35_59.jpg  \n",
            "  inflating: trainA/2012-07-28 06_08_26.jpg  \n",
            "  inflating: trainA/2012-07-28 13_13_33.jpg  \n",
            "  inflating: trainA/2012-07-29 05_49_42.jpg  \n",
            "  inflating: trainA/2012-07-30 14_42_28.jpg  \n",
            "  inflating: trainA/2012-07-31 21_17_27.jpg  \n",
            "  inflating: trainA/2012-08-01 23_34_45.jpg  \n",
            "  inflating: trainA/2012-08-03 04_25_39.jpg  \n",
            "  inflating: trainA/2012-08-03 13_40_45.jpg  \n",
            "  inflating: trainA/2012-08-05 13_08_05.jpg  \n",
            "  inflating: trainA/2012-08-06 16_35_59.jpg  \n",
            "  inflating: trainA/2012-08-07 08_22_59.jpg  \n",
            "  inflating: trainA/2012-08-07 08_25_59.jpg  \n",
            "  inflating: trainA/2012-08-08 15_20_26.jpg  \n",
            "  inflating: trainA/2012-08-10 18_34_09.jpg  \n",
            "  inflating: trainA/2012-08-10 21_39_02.jpg  \n",
            "  inflating: trainA/2012-08-11 19_02_13.jpg  \n",
            "  inflating: trainA/2012-08-11 19_06_25.jpg  \n",
            "  inflating: trainA/2012-08-12 00_33_04.jpg  \n",
            "  inflating: trainA/2012-08-12 02_03_58.jpg  \n",
            "  inflating: trainA/2012-08-12 13_31_52.jpg  \n",
            "  inflating: trainA/2012-08-13 08_08_27.jpg  \n",
            "  inflating: trainA/2012-08-15 01_54_39.jpg  \n",
            "  inflating: trainA/2012-08-15 09_53_27.jpg  \n",
            "  inflating: trainA/2012-08-15 16_27_18.jpg  \n",
            "  inflating: trainA/2012-08-16 17_30_45.jpg  \n",
            "  inflating: trainA/2012-08-17 06_12_35.jpg  \n",
            "  inflating: trainA/2012-08-17 13_29_12.jpg  \n",
            "  inflating: trainA/2012-08-17 16_51_54.jpg  \n",
            "  inflating: trainA/2012-08-17 18_26_47.jpg  \n",
            "  inflating: trainA/2012-08-18 23_29_18.jpg  \n",
            "  inflating: trainA/2012-08-19 13_12_44.jpg  \n",
            "  inflating: trainA/2012-08-19 17_18_04.jpg  \n",
            "  inflating: trainA/2012-08-19 18_58_39.jpg  \n",
            "  inflating: trainA/2012-08-20 20_56_07.jpg  \n",
            "  inflating: trainA/2012-08-23 08_43_59.jpg  \n",
            "  inflating: trainA/2012-08-24 12_54_33.jpg  \n",
            "  inflating: trainA/2012-08-25 10_10_43.jpg  \n",
            "  inflating: trainA/2012-08-25 13_19_04.jpg  \n",
            "  inflating: trainA/2012-08-25 14_03_09.jpg  \n",
            "  inflating: trainA/2012-08-27 11_56_46.jpg  \n",
            "  inflating: trainA/2012-08-27 19_31_13.jpg  \n",
            "  inflating: trainA/2012-08-27 21_21_47.jpg  \n",
            "  inflating: trainA/2012-08-28 18_56_26.jpg  \n",
            "  inflating: trainA/2012-08-28 19_20_03.jpg  \n",
            "  inflating: trainA/2012-08-30 11_22_56.jpg  \n",
            "  inflating: trainA/2012-08-31 01_10_02.jpg  \n",
            "  inflating: trainA/2012-09-02 10_57_09.jpg  \n",
            "  inflating: trainA/2012-09-02 19_48_04.jpg  \n",
            "  inflating: trainA/2012-09-03 23_19_59.jpg  \n",
            "  inflating: trainA/2012-09-06 08_33_54.jpg  \n",
            "  inflating: trainA/2012-09-06 14_53_33.jpg  \n",
            "  inflating: trainA/2012-09-07 13_27_54.jpg  \n",
            "  inflating: trainA/2012-09-08 17_57_28.jpg  \n",
            "  inflating: trainA/2012-09-10 00_02_07.jpg  \n",
            "  inflating: trainA/2012-09-10 12_33_05.jpg  \n",
            "  inflating: trainA/2012-09-11 02_37_06.jpg  \n",
            "  inflating: trainA/2012-09-12 18_14_59.jpg  \n",
            "  inflating: trainA/2012-09-12 18_18_03.jpg  \n",
            "  inflating: trainA/2012-09-13 18_01_33.jpg  \n",
            "  inflating: trainA/2012-09-14 22_41_04.jpg  \n",
            "  inflating: trainA/2012-09-15 12_38_09.jpg  \n",
            "  inflating: trainA/2012-09-17 20_49_25.jpg  \n",
            "  inflating: trainA/2012-09-26 22_01_57.jpg  \n",
            "  inflating: trainA/2012-10-13 09_52_13.jpg  \n",
            "  inflating: trainA/2012-10-15 00_46_37.jpg  \n",
            "  inflating: trainA/2012-12-01 04_47_08.jpg  \n",
            "  inflating: trainA/2012-12-18 08_06_06.jpg  \n",
            "  inflating: trainA/2012-12-18 22_15_55.jpg  \n",
            "  inflating: trainA/2012-12-24 13_06_53.jpg  \n",
            "  inflating: trainA/2013-01-05 03_00_52.jpg  \n",
            "  inflating: trainA/2013-01-21 10_49_37.jpg  \n",
            "  inflating: trainA/2013-02-03 03_04_52.jpg  \n",
            "  inflating: trainA/2013-03-09 11_55_45.jpg  \n",
            "  inflating: trainA/2013-03-17 19_48_03.jpg  \n",
            "  inflating: trainA/2013-05-15 08_10_03.jpg  \n",
            "  inflating: trainA/2013-05-15 14_24_42.jpg  \n",
            "  inflating: trainA/2013-05-15 17_50_48.jpg  \n",
            "  inflating: trainA/2013-05-15 18_32_36.jpg  \n",
            "  inflating: trainA/2013-05-16 18_12_46.jpg  \n",
            "  inflating: trainA/2013-05-17 16_33_43.jpg  \n",
            "  inflating: trainA/2013-05-18 04_38_17.jpg  \n",
            "  inflating: trainA/2013-05-18 12_10_06.jpg  \n",
            "  inflating: trainA/2013-05-19 15_50_15.jpg  \n",
            "  inflating: trainA/2013-05-22 10_02_38.jpg  \n",
            "  inflating: trainA/2013-05-22 13_51_52.jpg  \n",
            "  inflating: trainA/2013-05-25 06_52_13.jpg  \n",
            "  inflating: trainA/2013-05-25 18_21_08.jpg  \n",
            "  inflating: trainA/2013-05-26 19_14_42.jpg  \n",
            "  inflating: trainA/2013-05-27 01_29_08.jpg  \n",
            "  inflating: trainA/2013-05-27 19_06_44.jpg  \n",
            "  inflating: trainA/2013-05-30 19_32_29.jpg  \n",
            "  inflating: trainA/2013-06-01 09_21_55.jpg  \n",
            "  inflating: trainA/2013-06-01 14_34_42.jpg  \n",
            "  inflating: trainA/2013-06-02 05_46_39.jpg  \n",
            "  inflating: trainA/2013-06-02 14_29_53.jpg  \n",
            "  inflating: trainA/2013-06-02 16_50_07.jpg  \n",
            "  inflating: trainA/2013-06-05 20_47_05.jpg  \n",
            "  inflating: trainA/2013-06-06 20_08_08.jpg  \n",
            "  inflating: trainA/2013-06-06 23_59_34.jpg  \n",
            "  inflating: trainA/2013-06-07 23_07_25.jpg  \n",
            "  inflating: trainA/2013-06-09 09_04_47.jpg  \n",
            "  inflating: trainA/2013-06-10 05_46_13.jpg  \n",
            "  inflating: trainA/2013-06-10 12_58_17.jpg  \n",
            "  inflating: trainA/2013-06-12 15_59_24.jpg  \n",
            "  inflating: trainA/2013-06-13 04_10_15.jpg  \n",
            "  inflating: trainA/2013-06-14 01_54_39.jpg  \n",
            "  inflating: trainA/2013-06-14 14_47_49.jpg  \n",
            "  inflating: trainA/2013-06-15 16_32_24.jpg  \n",
            "  inflating: trainA/2013-06-15 18_15_22.jpg  \n",
            "  inflating: trainA/2013-06-15 20_21_49.jpg  \n",
            "  inflating: trainA/2013-06-16 17_46_13.jpg  \n",
            "  inflating: trainA/2013-06-17 19_19_48.jpg  \n",
            "  inflating: trainA/2013-06-20 05_12_46.jpg  \n",
            "  inflating: trainA/2013-06-20 20_56_06.jpg  \n",
            "  inflating: trainA/2013-06-23 01_56_49.jpg  \n",
            "  inflating: trainA/2013-06-23 08_20_19.jpg  \n",
            "  inflating: trainA/2013-06-23 12_10_05.jpg  \n",
            "  inflating: trainA/2013-06-23 20_02_36.jpg  \n",
            "  inflating: trainA/2013-06-24 00_32_15.jpg  \n",
            "  inflating: trainA/2013-06-24 06_23_19.jpg  \n",
            "  inflating: trainA/2013-06-24 15_26_24.jpg  \n",
            "  inflating: trainA/2013-06-24 19_30_19.jpg  \n",
            "  inflating: trainA/2013-06-25 04_45_48.jpg  \n",
            "  inflating: trainA/2013-06-25 10_15_25.jpg  \n",
            "  inflating: trainA/2013-06-25 18_21_37.jpg  \n",
            "  inflating: trainA/2013-06-25 21_57_38.jpg  \n",
            "  inflating: trainA/2013-06-25 22_38_29.jpg  \n",
            "  inflating: trainA/2013-06-26 11_38_42.jpg  \n",
            "  inflating: trainA/2013-06-28 20_38_52.jpg  \n",
            "  inflating: trainA/2013-06-30 09_29_27.jpg  \n",
            "  inflating: trainA/2013-07-02 12_13_34.jpg  \n",
            "  inflating: trainA/2013-07-02 19_59_13.jpg  \n",
            "  inflating: trainA/2013-07-03 10_12_18.jpg  \n",
            "  inflating: trainA/2013-07-04 10_15_56.jpg  \n",
            "  inflating: trainA/2013-07-04 19_35_59.jpg  \n",
            "  inflating: trainA/2013-07-06 17_30_17.jpg  \n",
            "  inflating: trainA/2013-07-07 15_25_06.jpg  \n",
            "  inflating: trainA/2013-07-08 17_57_48.jpg  \n",
            "  inflating: trainA/2013-07-09 12_01_15.jpg  \n",
            "  inflating: trainA/2013-07-12 14_04_28.jpg  \n",
            "  inflating: trainA/2013-07-12 14_49_05.jpg  \n",
            "  inflating: trainA/2013-07-13 04_05_49.jpg  \n",
            "  inflating: trainA/2013-07-14 06_39_09.jpg  \n",
            "  inflating: trainA/2013-07-15 12_53_24.jpg  \n",
            "  inflating: trainA/2013-07-15 21_12_17.jpg  \n",
            "  inflating: trainA/2013-07-15 21_31_46.jpg  \n",
            "  inflating: trainA/2013-07-16 00_17_37.jpg  \n",
            "  inflating: trainA/2013-07-17 03_13_45.jpg  \n",
            "  inflating: trainA/2013-07-17 14_53_25.jpg  \n",
            "  inflating: trainA/2013-07-17 19_41_55.jpg  \n",
            "  inflating: trainA/2013-07-17 21_01_55.jpg  \n",
            "  inflating: trainA/2013-07-19 16_58_23.jpg  \n",
            "  inflating: trainA/2013-07-19 17_13_59.jpg  \n",
            "  inflating: trainA/2013-07-20 01_19_13.jpg  \n",
            "  inflating: trainA/2013-07-20 13_18_56.jpg  \n",
            "  inflating: trainA/2013-07-20 14_55_02.jpg  \n",
            "  inflating: trainA/2013-07-20 17_25_33.jpg  \n",
            "  inflating: trainA/2013-07-21 06_18_45.jpg  \n",
            "  inflating: trainA/2013-07-22 06_08_08.jpg  \n",
            "  inflating: trainA/2013-07-22 14_06_24.jpg  \n",
            "  inflating: trainA/2013-07-22 23_21_24.jpg  \n",
            "  inflating: trainA/2013-07-24 18_56_26.jpg  \n",
            "  inflating: trainA/2013-07-26 17_38_23.jpg  \n",
            "  inflating: trainA/2013-07-26 22_58_48.jpg  \n",
            "  inflating: trainA/2013-07-27 17_34_56.jpg  \n",
            "  inflating: trainA/2013-07-27 18_00_56.jpg  \n",
            "  inflating: trainA/2013-07-28 02_39_42.jpg  \n",
            "  inflating: trainA/2013-07-28 12_27_06.jpg  \n",
            "  inflating: trainA/2013-07-28 14_28_19.jpg  \n",
            "  inflating: trainA/2013-07-28 20_06_34.jpg  \n",
            "  inflating: trainA/2013-07-29 09_31_29.jpg  \n",
            "  inflating: trainA/2013-07-29 12_00_02.jpg  \n",
            "  inflating: trainA/2013-07-29 19_19_05.jpg  \n",
            "  inflating: trainA/2013-07-29 19_27_22.jpg  \n",
            "  inflating: trainA/2013-07-30 01_34_48.jpg  \n",
            "  inflating: trainA/2013-07-30 08_14_38.jpg  \n",
            "  inflating: trainA/2013-07-30 15_39_56.jpg  \n",
            "  inflating: trainA/2013-07-31 16_08_05.jpg  \n",
            "  inflating: trainA/2013-07-31 18_38_06.jpg  \n",
            "  inflating: trainA/2013-07-31 21_08_47.jpg  \n",
            "  inflating: trainA/2013-08-02 09_18_58.jpg  \n",
            "  inflating: trainA/2013-08-02 10_39_27.jpg  \n",
            "  inflating: trainA/2013-08-02 10_45_24.jpg  \n",
            "  inflating: trainA/2013-08-02 12_43_14.jpg  \n",
            "  inflating: trainA/2013-08-03 01_14_53.jpg  \n",
            "  inflating: trainA/2013-08-03 14_02_23.jpg  \n",
            "  inflating: trainA/2013-08-03 14_48_15.jpg  \n",
            "  inflating: trainA/2013-08-05 18_28_34.jpg  \n",
            "  inflating: trainA/2013-08-05 19_48_23.jpg  \n",
            "  inflating: trainA/2013-08-06 13_31_24.jpg  \n",
            "  inflating: trainA/2013-08-06 18_52_22.jpg  \n",
            "  inflating: trainA/2013-08-06 22_22_17.jpg  \n",
            "  inflating: trainA/2013-08-07 12_34_48.jpg  \n",
            "  inflating: trainA/2013-08-07 17_58_46.jpg  \n",
            "  inflating: trainA/2013-08-07 19_58_18.jpg  \n",
            "  inflating: trainA/2013-08-07 20_15_47.jpg  \n",
            "  inflating: trainA/2013-08-09 06_07_54.jpg  \n",
            "  inflating: trainA/2013-08-09 19_32_58.jpg  \n",
            "  inflating: trainA/2013-08-10 08_47_05.jpg  \n",
            "  inflating: trainA/2013-08-10 15_55_43.jpg  \n",
            "  inflating: trainA/2013-08-11 04_45_34.jpg  \n",
            "  inflating: trainA/2013-08-12 00_09_52.jpg  \n",
            "  inflating: trainA/2013-08-12 08_52_04.jpg  \n",
            "  inflating: trainA/2013-08-12 15_49_12.jpg  \n",
            "  inflating: trainA/2013-08-13 00_41_12.jpg  \n",
            "  inflating: trainA/2013-08-13 18_43_48.jpg  \n",
            "  inflating: trainA/2013-08-13 19_19_34.jpg  \n",
            "  inflating: trainA/2013-08-14 08_21_27.jpg  \n",
            "  inflating: trainA/2013-08-14 13_39_08.jpg  \n",
            "  inflating: trainA/2013-08-15 02_00_27.jpg  \n",
            "  inflating: trainA/2013-08-15 08_58_14.jpg  \n",
            "  inflating: trainA/2013-08-16 13_32_02.jpg  \n",
            "  inflating: trainA/2013-08-17 07_59_38.jpg  \n",
            "  inflating: trainA/2013-08-17 19_48_52.jpg  \n",
            "  inflating: trainA/2013-08-18 01_26_03.jpg  \n",
            "  inflating: trainA/2013-08-18 06_29_45.jpg  \n",
            "  inflating: trainA/2013-08-18 08_18_48.jpg  \n",
            "  inflating: trainA/2013-08-18 09_33_02.jpg  \n",
            "  inflating: trainA/2013-08-18 18_56_23.jpg  \n",
            "  inflating: trainA/2013-08-19 03_41_52.jpg  \n",
            "  inflating: trainA/2013-08-19 15_21_44.jpg  \n",
            "  inflating: trainA/2013-08-19 17_50_47.jpg  \n",
            "  inflating: trainA/2013-08-20 17_13_33.jpg  \n",
            "  inflating: trainA/2013-08-21 08_03_04.jpg  \n",
            "  inflating: trainA/2013-08-21 18_38_46.jpg  \n",
            "  inflating: trainA/2013-08-24 05_57_27.jpg  \n",
            "  inflating: trainA/2013-08-24 17_02_16.jpg  \n",
            "  inflating: trainA/2013-08-24 19_50_24.jpg  \n",
            "  inflating: trainA/2013-08-25 12_27_25.jpg  \n",
            "  inflating: trainA/2013-08-25 13_40_59.jpg  \n",
            "  inflating: trainA/2013-08-25 19_36_23.jpg  \n",
            "  inflating: trainA/2013-08-26 01_13_38.jpg  \n",
            "  inflating: trainA/2013-08-27 20_04_35.jpg  \n",
            "  inflating: trainA/2013-08-30 09_31_33.jpg  \n",
            "  inflating: trainA/2013-08-31 12_35_54.jpg  \n",
            "  inflating: trainA/2013-09-01 10_07_09.jpg  \n",
            "  inflating: trainA/2013-09-01 10_57_15.jpg  \n",
            "  inflating: trainA/2013-09-01 11_43_59.jpg  \n",
            "  inflating: trainA/2013-09-02 13_12_13.jpg  \n",
            "  inflating: trainA/2013-09-02 21_17_26.jpg  \n",
            "  inflating: trainA/2013-09-04 14_58_35.jpg  \n",
            "  inflating: trainA/2013-09-05 16_26_57.jpg  \n",
            "  inflating: trainA/2013-09-06 21_55_22.jpg  \n",
            "  inflating: trainA/2013-09-07 17_01_07.jpg  \n",
            "  inflating: trainA/2013-09-08 19_48_29.jpg  \n",
            "  inflating: trainA/2013-09-09 03_43_43.jpg  \n",
            "  inflating: trainA/2013-09-10 17_29_42.jpg  \n",
            "  inflating: trainA/2013-09-10 18_51_45.jpg  \n",
            "  inflating: trainA/2013-09-12 10_46_08.jpg  \n",
            "  inflating: trainA/2013-09-12 13_25_33.jpg  \n",
            "  inflating: trainA/2013-09-13 16_13_34.jpg  \n",
            "  inflating: trainA/2013-09-14 22_09_42.jpg  \n",
            "  inflating: trainA/2013-09-15 04_03_54.jpg  \n",
            "  inflating: trainA/2013-09-15 20_09_52.jpg  \n",
            "  inflating: trainA/2013-09-22 12_29_32.jpg  \n",
            "  inflating: trainA/2013-09-25 05_19_53.jpg  \n",
            "  inflating: trainA/2013-09-29 21_33_33.jpg  \n",
            "  inflating: trainA/2013-10-26 21_35_38.jpg  \n",
            "  inflating: trainA/2013-11-21 13_43_57.jpg  \n",
            "  inflating: trainA/2014-01-06 04_55_23.jpg  \n",
            "  inflating: trainA/2014-01-11 13_01_47.jpg  \n",
            "  inflating: trainA/2014-01-13 10_57_19.jpg  \n",
            "  inflating: trainA/2014-01-14 22_15_17.jpg  \n",
            "  inflating: trainA/2014-01-29 13_20_43.jpg  \n",
            "  inflating: trainA/2014-04-15 14_56_44.jpg  \n",
            "  inflating: trainA/2014-04-24 11_56_43.jpg  \n",
            "  inflating: trainA/2014-05-13 02_35_47.jpg  \n",
            "  inflating: trainA/2014-05-13 21_38_13.jpg  \n",
            "  inflating: trainA/2014-05-17 08_41_03.jpg  \n",
            "  inflating: trainA/2014-05-17 19_04_23.jpg  \n",
            "  inflating: trainA/2014-05-19 03_02_45.jpg  \n",
            "  inflating: trainA/2014-05-25 08_27_07.jpg  \n",
            "  inflating: trainA/2014-05-25 19_20_18.jpg  \n",
            "  inflating: trainA/2014-05-26 00_07_22.jpg  \n",
            "  inflating: trainA/2014-05-26 10_30_36.jpg  \n",
            "  inflating: trainA/2014-05-26 15_49_38.jpg  \n",
            "  inflating: trainA/2014-05-28 20_44_39.jpg  \n",
            "  inflating: trainA/2014-05-29 22_50_45.jpg  \n",
            "  inflating: trainA/2014-05-31 14_18_03.jpg  \n",
            "  inflating: trainA/2014-06-01 11_38_24.jpg  \n",
            "  inflating: trainA/2014-06-05 13_29_38.jpg  \n",
            "  inflating: trainA/2014-06-06 14_33_49.jpg  \n",
            "  inflating: trainA/2014-06-07 02_12_44.jpg  \n",
            "  inflating: trainA/2014-06-08 19_30_06.jpg  \n",
            "  inflating: trainA/2014-06-09 19_04_14.jpg  \n",
            "  inflating: trainA/2014-06-10 09_11_47.jpg  \n",
            "  inflating: trainA/2014-06-10 22_06_03.jpg  \n",
            "  inflating: trainA/2014-06-11 18_48_02.jpg  \n",
            "  inflating: trainA/2014-06-12 23_24_26.jpg  \n",
            "  inflating: trainA/2014-06-13 11_33_39.jpg  \n",
            "  inflating: trainA/2014-06-13 22_42_07.jpg  \n",
            "  inflating: trainA/2014-06-15 18_37_36.jpg  \n",
            "  inflating: trainA/2014-06-16 16_21_55.jpg  \n",
            "  inflating: trainA/2014-06-16 20_08_44.jpg  \n",
            "  inflating: trainA/2014-06-19 17_34_38.jpg  \n",
            "  inflating: trainA/2014-06-19 20_24_55.jpg  \n",
            "  inflating: trainA/2014-06-19 22_33_37.jpg  \n",
            "  inflating: trainA/2014-06-21 19_32_04.jpg  \n",
            "  inflating: trainA/2014-06-22 05_13_48.jpg  \n",
            "  inflating: trainA/2014-06-23 03_22_38.jpg  \n",
            "  inflating: trainA/2014-06-23 21_17_12.jpg  \n",
            "  inflating: trainA/2014-06-26 09_07_32.jpg  \n",
            "  inflating: trainA/2014-06-26 18_06_43.jpg  \n",
            "  inflating: trainA/2014-06-26 22_14_05.jpg  \n",
            "  inflating: trainA/2014-06-27 20_22_16.jpg  \n",
            "  inflating: trainA/2014-06-29 20_48_09.jpg  \n",
            "  inflating: trainA/2014-06-30 04_40_25.jpg  \n",
            "  inflating: trainA/2014-06-30 18_33_25.jpg  \n",
            "  inflating: trainA/2014-06-30 18_59_03.jpg  \n",
            "  inflating: trainA/2014-07-01 04_34_44.jpg  \n",
            "  inflating: trainA/2014-07-01 10_31_48.jpg  \n",
            "  inflating: trainA/2014-07-01 18_13_17.jpg  \n",
            "  inflating: trainA/2014-07-02 12_16_14.jpg  \n",
            "  inflating: trainA/2014-07-02 16_24_24.jpg  \n",
            "  inflating: trainA/2014-07-02 23_11_19.jpg  \n",
            "  inflating: trainA/2014-07-03 09_48_35.jpg  \n",
            "  inflating: trainA/2014-07-04 02_24_09.jpg  \n",
            "  inflating: trainA/2014-07-05 02_00_53.jpg  \n",
            "  inflating: trainA/2014-07-05 16_01_49.jpg  \n",
            "  inflating: trainA/2014-07-05 20_05_04.jpg  \n",
            "  inflating: trainA/2014-07-06 18_53_19.jpg  \n",
            "  inflating: trainA/2014-07-07 17_22_03.jpg  \n",
            "  inflating: trainA/2014-07-07 18_00_52.jpg  \n",
            "  inflating: trainA/2014-07-08 15_50_42.jpg  \n",
            "  inflating: trainA/2014-07-08 21_55_29.jpg  \n",
            "  inflating: trainA/2014-07-10 17_38_57.jpg  \n",
            "  inflating: trainA/2014-07-11 20_16_56.jpg  \n",
            "  inflating: trainA/2014-07-13 01_12_07.jpg  \n",
            "  inflating: trainA/2014-07-14 05_30_04.jpg  \n",
            "  inflating: trainA/2014-07-14 20_17_08.jpg  \n",
            "  inflating: trainA/2014-07-14 20_31_27.jpg  \n",
            "  inflating: trainA/2014-07-14 22_37_58.jpg  \n",
            "  inflating: trainA/2014-07-15 05_01_27.jpg  \n",
            "  inflating: trainA/2014-07-15 12_17_14.jpg  \n",
            "  inflating: trainA/2014-07-15 16_44_47.jpg  \n",
            "  inflating: trainA/2014-07-15 18_31_18.jpg  \n",
            "  inflating: trainA/2014-07-16 23_53_07.jpg  \n",
            "  inflating: trainA/2014-07-17 21_34_08.jpg  \n",
            "  inflating: trainA/2014-07-19 10_15_07.jpg  \n",
            "  inflating: trainA/2014-07-20 20_12_39.jpg  \n",
            "  inflating: trainA/2014-07-22 03_16_24.jpg  \n",
            "  inflating: trainA/2014-07-22 08_48_36.jpg  \n",
            "  inflating: trainA/2014-07-25 23_34_07.jpg  \n",
            "  inflating: trainA/2014-07-26 12_59_48.jpg  \n",
            "  inflating: trainA/2014-07-26 18_44_44.jpg  \n",
            "  inflating: trainA/2014-07-26 19_45_59.jpg  \n",
            "  inflating: trainA/2014-07-26 23_22_25.jpg  \n",
            "  inflating: trainA/2014-07-27 21_50_52.jpg  \n",
            "  inflating: trainA/2014-07-29 22_35_43.jpg  \n",
            "  inflating: trainA/2014-07-30 12_19_17.jpg  \n",
            "  inflating: trainA/2014-07-30 22_20_53.jpg  \n",
            "  inflating: trainA/2014-07-31 15_30_42.jpg  \n",
            "  inflating: trainA/2014-07-31 21_00_39.jpg  \n",
            "  inflating: trainA/2014-07-31 22_54_37.jpg  \n",
            "  inflating: trainA/2014-08-01 16_35_05.jpg  \n",
            "  inflating: trainA/2014-08-01 18_31_55.jpg  \n",
            "  inflating: trainA/2014-08-01 19_17_15.jpg  \n",
            "  inflating: trainA/2014-08-03 15_50_04.jpg  \n",
            "  inflating: trainA/2014-08-04 17_16_12.jpg  \n",
            "  inflating: trainA/2014-08-06 10_17_18.jpg  \n",
            "  inflating: trainA/2014-08-07 23_36_25.jpg  \n",
            "  inflating: trainA/2014-08-08 04_28_48.jpg  \n",
            "  inflating: trainA/2014-08-08 13_31_55.jpg  \n",
            "  inflating: trainA/2014-08-09 00_50_17.jpg  \n",
            "  inflating: trainA/2014-08-09 13_49_58.jpg  \n",
            "  inflating: trainA/2014-08-09 19_07_08.jpg  \n",
            "  inflating: trainA/2014-08-10 10_14_59.jpg  \n",
            "  inflating: trainA/2014-08-10 15_06_55.jpg  \n",
            "  inflating: trainA/2014-08-12 11_31_02.jpg  \n",
            "  inflating: trainA/2014-08-12 11_38_42.jpg  \n",
            "  inflating: trainA/2014-08-12 20_08_27.jpg  \n",
            "  inflating: trainA/2014-08-13 03_39_02.jpg  \n",
            "  inflating: trainA/2014-08-13 10_18_28.jpg  \n",
            "  inflating: trainA/2014-08-13 21_23_53.jpg  \n",
            "  inflating: trainA/2014-08-13 22_04_22.jpg  \n",
            "  inflating: trainA/2014-08-16 02_15_36.jpg  \n",
            "  inflating: trainA/2014-08-16 05_23_42.jpg  \n",
            "  inflating: trainA/2014-08-16 07_43_23.jpg  \n",
            "  inflating: trainA/2014-08-16 15_10_04.jpg  \n",
            "  inflating: trainA/2014-08-16 19_59_37.jpg  \n",
            "  inflating: trainA/2014-08-16 22_08_28.jpg  \n",
            "  inflating: trainA/2014-08-16 22_23_26.jpg  \n",
            "  inflating: trainA/2014-08-17 03_09_49.jpg  \n",
            "  inflating: trainA/2014-08-17 10_47_45.jpg  \n",
            "  inflating: trainA/2014-08-17 12_10_02.jpg  \n",
            "  inflating: trainA/2014-08-18 23_14_07.jpg  \n",
            "  inflating: trainA/2014-08-19 03_20_14.jpg  \n",
            "  inflating: trainA/2014-08-19 08_05_29.jpg  \n",
            "  inflating: trainA/2014-08-20 18_23_03.jpg  \n",
            "  inflating: trainA/2014-08-22 14_36_06.jpg  \n",
            "  inflating: trainA/2014-08-22 19_38_17.jpg  \n",
            "  inflating: trainA/2014-08-22 22_29_27.jpg  \n",
            "  inflating: trainA/2014-08-23 18_29_08.jpg  \n",
            "  inflating: trainA/2014-08-24 04_34_25.jpg  \n",
            "  inflating: trainA/2014-08-24 05_30_07.jpg  \n",
            "  inflating: trainA/2014-08-24 13_29_44.jpg  \n",
            "  inflating: trainA/2014-08-24 14_42_57.jpg  \n",
            "  inflating: trainA/2014-08-26 03_23_49.jpg  \n",
            "  inflating: trainA/2014-08-26 05_33_17.jpg  \n",
            "  inflating: trainA/2014-08-26 20_11_34.jpg  \n",
            "  inflating: trainA/2014-08-27 02_26_08.jpg  \n",
            "  inflating: trainA/2014-08-27 08_07_37.jpg  \n",
            "  inflating: trainA/2014-08-27 09_35_03.jpg  \n",
            "  inflating: trainA/2014-08-27 22_33_53.jpg  \n",
            "  inflating: trainA/2014-08-29 12_48_44.jpg  \n",
            "  inflating: trainA/2014-08-29 17_53_25.jpg  \n",
            "  inflating: trainA/2014-08-29 20_31_09.jpg  \n",
            "  inflating: trainA/2014-08-30 04_00_23.jpg  \n",
            "  inflating: trainA/2014-08-30 12_57_34.jpg  \n",
            "  inflating: trainA/2014-08-31 08_08_43.jpg  \n",
            "  inflating: trainA/2014-09-01 09_56_57.jpg  \n",
            "  inflating: trainA/2014-09-02 22_53_12.jpg  \n",
            "  inflating: trainA/2014-09-03 01_26_47.jpg  \n",
            "  inflating: trainA/2014-09-04 07_32_17.jpg  \n",
            "  inflating: trainA/2014-09-04 19_41_35.jpg  \n",
            "  inflating: trainA/2014-09-05 12_55_32.jpg  \n",
            "  inflating: trainA/2014-09-05 21_47_44.jpg  \n",
            "  inflating: trainA/2014-09-07 15_41_16.jpg  \n",
            "  inflating: trainA/2014-09-07 20_28_25.jpg  \n",
            "  inflating: trainA/2014-09-08 10_11_14.jpg  \n",
            "  inflating: trainA/2014-09-08 15_48_57.jpg  \n",
            "  inflating: trainA/2014-09-08 22_40_14.jpg  \n",
            "  inflating: trainA/2014-09-09 00_25_52.jpg  \n",
            "  inflating: trainA/2014-09-09 06_56_45.jpg  \n",
            "  inflating: trainA/2014-09-09 10_38_17.jpg  \n",
            "  inflating: trainA/2014-09-09 10_54_18.jpg  \n",
            "  inflating: trainA/2014-09-10 22_17_28.jpg  \n",
            "  inflating: trainA/2014-09-11 13_48_29.jpg  \n",
            "  inflating: trainA/2014-09-12 07_02_34.jpg  \n",
            "  inflating: trainA/2014-09-12 14_09_43.jpg  \n",
            "  inflating: trainA/2014-09-14 09_55_57.jpg  \n",
            "  inflating: trainA/2014-09-14 09_58_08.jpg  \n",
            "  inflating: trainA/2014-09-14 13_30_13.jpg  \n",
            "  inflating: trainA/2014-09-18 14_59_03.jpg  \n",
            "  inflating: trainA/2014-10-02 14_07_29.jpg  \n",
            "  inflating: trainA/2014-10-31 21_12_16.jpg  \n",
            "  inflating: trainA/2014-11-05 14_30_02.jpg  \n",
            "  inflating: trainA/2014-11-06 10_00_03.jpg  \n",
            "  inflating: trainA/2014-11-17 06_49_53.jpg  \n",
            "  inflating: trainA/2014-11-30 13_40_15.jpg  \n",
            "  inflating: trainA/2015-01-02 16_38_48.jpg  \n",
            "  inflating: trainA/2015-01-10 09_54_03.jpg  \n",
            "  inflating: trainA/2015-02-15 11_47_24.jpg  \n",
            "  inflating: trainA/2015-02-28 15_38_54.jpg  \n",
            "  inflating: trainA/2015-04-09 07_49_25.jpg  \n",
            "  inflating: trainA/2015-05-11 21_41_58.jpg  \n",
            "  inflating: trainA/2015-05-15 18_26_45.jpg  \n",
            "  inflating: trainA/2015-05-17 16_13_55.jpg  \n",
            "  inflating: trainA/2015-05-19 03_34_36.jpg  \n",
            "  inflating: trainA/2015-05-20 19_06_09.jpg  \n",
            "  inflating: trainA/2015-05-21 20_25_43.jpg  \n",
            "  inflating: trainA/2015-05-23 15_48_12.jpg  \n",
            "  inflating: trainA/2015-05-23 17_05_48.jpg  \n",
            "  inflating: trainA/2015-05-23 23_58_46.jpg  \n",
            "  inflating: trainA/2015-05-25 09_34_22.jpg  \n",
            "  inflating: trainA/2015-05-30 13_31_57.jpg  \n",
            "  inflating: trainA/2015-05-31 21_05_47.jpg  \n",
            "  inflating: trainA/2015-06-01 21_50_37.jpg  \n",
            "  inflating: trainA/2015-06-02 13_24_38.jpg  \n",
            "  inflating: trainA/2015-06-04 09_08_25.jpg  \n",
            "  inflating: trainA/2015-06-04 16_36_59.jpg  \n",
            "  inflating: trainA/2015-06-05 17_02_39.jpg  \n",
            "  inflating: trainA/2015-06-05 21_45_04.jpg  \n",
            "  inflating: trainA/2015-06-06 05_45_57.jpg  \n",
            "  inflating: trainA/2015-06-06 12_58_59.jpg  \n",
            "  inflating: trainA/2015-06-06 17_07_35.jpg  \n",
            "  inflating: trainA/2015-06-06 17_43_33.jpg  \n",
            "  inflating: trainA/2015-06-06 19_40_22.jpg  \n",
            "  inflating: trainA/2015-06-07 01_03_27.jpg  \n",
            "  inflating: trainA/2015-06-07 16_55_27.jpg  \n",
            "  inflating: trainA/2015-06-08 02_19_32.jpg  \n",
            "  inflating: trainA/2015-06-08 09_04_57.jpg  \n",
            "  inflating: trainA/2015-06-09 16_05_38.jpg  \n",
            "  inflating: trainA/2015-06-10 18_31_29.jpg  \n",
            "  inflating: trainA/2015-06-10 22_52_08.jpg  \n",
            "  inflating: trainA/2015-06-10 23_35_46.jpg  \n",
            "  inflating: trainA/2015-06-11 06_24_54.jpg  \n",
            "  inflating: trainA/2015-06-11 10_18_16.jpg  \n",
            "  inflating: trainA/2015-06-13 02_09_54.jpg  \n",
            "  inflating: trainA/2015-06-13 19_28_56.jpg  \n",
            "  inflating: trainA/2015-06-13 22_26_12.jpg  \n",
            "  inflating: trainA/2015-06-16 15_43_24.jpg  \n",
            "  inflating: trainA/2015-06-17 02_57_53.jpg  \n",
            "  inflating: trainA/2015-06-17 18_20_47.jpg  \n",
            "  inflating: trainA/2015-06-19 20_42_18.jpg  \n",
            "  inflating: trainA/2015-06-19 21_31_25.jpg  \n",
            "  inflating: trainA/2015-06-20 09_46_17.jpg  \n",
            "  inflating: trainA/2015-06-20 10_48_25.jpg  \n",
            "  inflating: trainA/2015-06-20 11_47_02.jpg  \n",
            "  inflating: trainA/2015-06-20 16_21_04.jpg  \n",
            "  inflating: trainA/2015-06-20 20_24_39.jpg  \n",
            "  inflating: trainA/2015-06-21 19_27_03.jpg  \n",
            "  inflating: trainA/2015-06-22 13_14_16.jpg  \n",
            "  inflating: trainA/2015-06-22 13_59_04.jpg  \n",
            "  inflating: trainA/2015-06-23 07_47_45.jpg  \n",
            "  inflating: trainA/2015-06-23 09_56_56.jpg  \n",
            "  inflating: trainA/2015-06-23 22_07_18.jpg  \n",
            "  inflating: trainA/2015-06-24 19_13_24.jpg  \n",
            "  inflating: trainA/2015-06-26 11_03_46.jpg  \n",
            "  inflating: trainA/2015-06-26 12_24_54.jpg  \n",
            "  inflating: trainA/2015-06-26 19_33_09.jpg  \n",
            "  inflating: trainA/2015-06-27 04_59_47.jpg  \n",
            "  inflating: trainA/2015-06-27 11_34_04.jpg  \n",
            "  inflating: trainA/2015-06-27 23_02_09.jpg  \n",
            "  inflating: trainA/2015-06-28 07_12_03.jpg  \n",
            "  inflating: trainA/2015-06-28 15_18_05.jpg  \n",
            "  inflating: trainA/2015-06-29 03_42_43.jpg  \n",
            "  inflating: trainA/2015-06-29 04_54_24.jpg  \n",
            "  inflating: trainA/2015-06-29 06_54_44.jpg  \n",
            "  inflating: trainA/2015-06-29 10_47_05.jpg  \n",
            "  inflating: trainA/2015-06-29 13_45_12.jpg  \n",
            "  inflating: trainA/2015-06-30 10_15_57.jpg  \n",
            "  inflating: trainA/2015-06-30 22_20_25.jpg  \n",
            "  inflating: trainA/2015-06-30 22_28_37.jpg  \n",
            "  inflating: trainA/2015-07-01 01_19_47.jpg  \n",
            "  inflating: trainA/2015-07-01 17_43_23.jpg  \n",
            "  inflating: trainA/2015-07-01 23_43_46.jpg  \n",
            "  inflating: trainA/2015-07-02 14_36_54.jpg  \n",
            "  inflating: trainA/2015-07-02 19_54_16.jpg  \n",
            "  inflating: trainA/2015-07-03 09_39_09.jpg  \n",
            "  inflating: trainA/2015-07-03 12_24_26.jpg  \n",
            "  inflating: trainA/2015-07-03 14_35_56.jpg  \n",
            "  inflating: trainA/2015-07-03 20_11_57.jpg  \n",
            "  inflating: trainA/2015-07-04 01_15_17.jpg  \n",
            "  inflating: trainA/2015-07-04 13_01_03.jpg  \n",
            "  inflating: trainA/2015-07-04 13_34_49.jpg  \n",
            "  inflating: trainA/2015-07-04 20_55_17.jpg  \n",
            "  inflating: trainA/2015-07-05 08_23_14.jpg  \n",
            "  inflating: trainA/2015-07-05 17_31_57.jpg  \n",
            "  inflating: trainA/2015-07-06 02_19_05.jpg  \n",
            "  inflating: trainA/2015-07-06 10_53_44.jpg  \n",
            "  inflating: trainA/2015-07-06 20_03_53.jpg  \n",
            "  inflating: trainA/2015-07-07 07_13_05.jpg  \n",
            "  inflating: trainA/2015-07-07 13_29_22.jpg  \n",
            "  inflating: trainA/2015-07-08 03_55_25.jpg  \n",
            "  inflating: trainA/2015-07-08 19_36_38.jpg  \n",
            "  inflating: trainA/2015-07-09 09_49_16.jpg  \n",
            "  inflating: trainA/2015-07-10 08_24_46.jpg  \n",
            "  inflating: trainA/2015-07-10 13_15_18.jpg  \n",
            "  inflating: trainA/2015-07-11 20_31_28.jpg  \n",
            "  inflating: trainA/2015-07-12 14_23_43.jpg  \n",
            "  inflating: trainA/2015-07-12 16_20_15.jpg  \n",
            "  inflating: trainA/2015-07-12 18_56_43.jpg  \n",
            "  inflating: trainA/2015-07-12 20_08_05.jpg  \n",
            "  inflating: trainA/2015-07-12 20_23_26.jpg  \n",
            "  inflating: trainA/2015-07-13 06_02_24.jpg  \n",
            "  inflating: trainA/2015-07-13 12_46_24.jpg  \n",
            "  inflating: trainA/2015-07-13 21_23_36.jpg  \n",
            "  inflating: trainA/2015-07-14 17_40_16.jpg  \n",
            "  inflating: trainA/2015-07-15 00_19_32.jpg  \n",
            "  inflating: trainA/2015-07-15 07_47_12.jpg  \n",
            "  inflating: trainA/2015-07-15 18_54_09.jpg  \n",
            "  inflating: trainA/2015-07-16 19_47_18.jpg  \n",
            "  inflating: trainA/2015-07-16 21_34_39.jpg  \n",
            "  inflating: trainA/2015-07-16 21_44_25.jpg  \n",
            "  inflating: trainA/2015-07-17 19_24_18.jpg  \n",
            "  inflating: trainA/2015-07-18 04_50_54.jpg  \n",
            "  inflating: trainA/2015-07-18 13_50_14.jpg  \n",
            "  inflating: trainA/2015-07-19 07_39_45.jpg  \n",
            "  inflating: trainA/2015-07-19 16_27_43.jpg  \n",
            "  inflating: trainA/2015-07-19 16_54_03.jpg  \n",
            "  inflating: trainA/2015-07-19 20_28_53.jpg  \n",
            "  inflating: trainA/2015-07-20 10_38_12.jpg  \n",
            "  inflating: trainA/2015-07-20 17_39_23.jpg  \n",
            "  inflating: trainA/2015-07-20 21_30_35.jpg  \n",
            "  inflating: trainA/2015-07-20 21_59_53.jpg  \n",
            "  inflating: trainA/2015-07-21 21_10_13.jpg  \n",
            "  inflating: trainA/2015-07-22 12_32_56.jpg  \n",
            "  inflating: trainA/2015-07-22 19_45_43.jpg  \n",
            "  inflating: trainA/2015-07-23 09_56_29.jpg  \n",
            "  inflating: trainA/2015-07-23 12_51_24.jpg  \n",
            "  inflating: trainA/2015-07-23 19_06_35.jpg  \n",
            "  inflating: trainA/2015-07-24 14_22_17.jpg  \n",
            "  inflating: trainA/2015-07-25 16_30_37.jpg  \n",
            "  inflating: trainA/2015-07-25 21_40_48.jpg  \n",
            "  inflating: trainA/2015-07-26 08_24_59.jpg  \n",
            "  inflating: trainA/2015-07-27 01_29_59.jpg  \n",
            "  inflating: trainA/2015-07-28 11_01_03.jpg  \n",
            "  inflating: trainA/2015-07-28 12_36_04.jpg  \n",
            "  inflating: trainA/2015-07-28 16_40_35.jpg  \n",
            "  inflating: trainA/2015-07-28 20_02_28.jpg  \n",
            "  inflating: trainA/2015-07-29 16_46_14.jpg  \n",
            "  inflating: trainA/2015-07-29 20_31_04.jpg  \n",
            "  inflating: trainA/2015-07-30 04_44_07.jpg  \n",
            "  inflating: trainA/2015-07-30 13_20_47.jpg  \n",
            "  inflating: trainA/2015-07-30 18_49_03.jpg  \n",
            "  inflating: trainA/2015-07-31 19_11_25.jpg  \n",
            "  inflating: trainA/2015-07-31 23_33_26.jpg  \n",
            "  inflating: trainA/2015-08-01 11_22_59.jpg  \n",
            "  inflating: trainA/2015-08-01 13_30_47.jpg  \n",
            "  inflating: trainA/2015-08-01 14_23_02.jpg  \n",
            "  inflating: trainA/2015-08-01 14_49_46.jpg  \n",
            "  inflating: trainA/2015-08-01 20_02_54.jpg  \n",
            "  inflating: trainA/2015-08-01 20_10_37.jpg  \n",
            "  inflating: trainA/2015-08-02 02_14_24.jpg  \n",
            "  inflating: trainA/2015-08-02 06_38_35.jpg  \n",
            "  inflating: trainA/2015-08-03 04_53_52.jpg  \n",
            "  inflating: trainA/2015-08-03 16_06_49.jpg  \n",
            "  inflating: trainA/2015-08-04 00_09_46.jpg  \n",
            "  inflating: trainA/2015-08-04 07_29_52.jpg  \n",
            "  inflating: trainA/2015-08-04 09_32_49.jpg  \n",
            "  inflating: trainA/2015-08-04 16_23_36.jpg  \n",
            "  inflating: trainA/2015-08-05 00_35_43.jpg  \n",
            "  inflating: trainA/2015-08-05 11_09_23.jpg  \n",
            "  inflating: trainA/2015-08-06 01_05_04.jpg  \n",
            "  inflating: trainA/2015-08-06 15_28_46.jpg  \n",
            "  inflating: trainA/2015-08-08 14_49_32.jpg  \n",
            "  inflating: trainA/2015-08-09 03_22_06.jpg  \n",
            "  inflating: trainA/2015-08-09 19_35_44.jpg  \n",
            "  inflating: trainA/2015-08-12 21_51_34.jpg  \n",
            "  inflating: trainA/2015-08-12 21_53_23.jpg  \n",
            "  inflating: trainA/2015-08-13 07_30_33.jpg  \n",
            "  inflating: trainA/2015-08-14 10_29_18.jpg  \n",
            "  inflating: trainA/2015-08-14 12_55_32.jpg  \n",
            "  inflating: trainA/2015-08-14 12_56_56.jpg  \n",
            "  inflating: trainA/2015-08-14 13_39_03.jpg  \n",
            "  inflating: trainA/2015-08-14 20_07_17.jpg  \n",
            "  inflating: trainA/2015-08-14 22_12_14.jpg  \n",
            "  inflating: trainA/2015-08-15 10_34_54.jpg  \n",
            "  inflating: trainA/2015-08-16 11_20_48.jpg  \n",
            "  inflating: trainA/2015-08-16 12_54_47.jpg  \n",
            "  inflating: trainA/2015-08-17 06_31_45.jpg  \n",
            "  inflating: trainA/2015-08-17 20_02_54.jpg  \n",
            "  inflating: trainA/2015-08-17 22_10_28.jpg  \n",
            "  inflating: trainA/2015-08-19 00_39_56.jpg  \n",
            "  inflating: trainA/2015-08-19 19_35_22.jpg  \n",
            "  inflating: trainA/2015-08-20 22_18_52.jpg  \n",
            "  inflating: trainA/2015-08-22 16_21_52.jpg  \n",
            "  inflating: trainA/2015-08-23 02_18_34.jpg  \n",
            "  inflating: trainA/2015-08-23 04_20_39.jpg  \n",
            "  inflating: trainA/2015-08-23 07_58_08.jpg  \n",
            "  inflating: trainA/2015-08-23 12_03_27.jpg  \n",
            "  inflating: trainA/2015-08-24 14_12_42.jpg  \n",
            "  inflating: trainA/2015-08-25 20_40_35.jpg  \n",
            "  inflating: trainA/2015-08-26 00_23_12.jpg  \n",
            "  inflating: trainA/2015-08-27 19_20_15.jpg  \n",
            "  inflating: trainA/2015-08-28 01_54_14.jpg  \n",
            "  inflating: trainA/2015-08-30 04_30_57.jpg  \n",
            "  inflating: trainA/2015-08-31 09_41_48.jpg  \n",
            "  inflating: trainA/2015-08-31 18_14_34.jpg  \n",
            "  inflating: trainA/2015-09-01 11_32_08.jpg  \n",
            "  inflating: trainA/2015-09-01 15_36_56.jpg  \n",
            "  inflating: trainA/2015-09-02 23_25_58.jpg  \n",
            "  inflating: trainA/2015-09-04 12_05_04.jpg  \n",
            "  inflating: trainA/2015-09-04 14_21_56.jpg  \n",
            "  inflating: trainA/2015-09-05 15_22_29.jpg  \n",
            "  inflating: trainA/2015-09-05 21_17_29.jpg  \n",
            "  inflating: trainA/2015-09-06 11_02_38.jpg  \n",
            "  inflating: trainA/2015-09-07 00_02_25.jpg  \n",
            "  inflating: trainA/2015-09-07 13_27_36.jpg  \n",
            "  inflating: trainA/2015-09-07 15_49_32.jpg  \n",
            "  inflating: trainA/2015-09-07 21_48_49.jpg  \n",
            "  inflating: trainA/2015-09-09 11_14_27.jpg  \n",
            "  inflating: trainA/2015-09-09 13_47_07.jpg  \n",
            "  inflating: trainA/2015-09-09 16_01_23.jpg  \n",
            "  inflating: trainA/2015-09-09 19_09_12.jpg  \n",
            "  inflating: trainA/2015-09-09 19_38_09.jpg  \n",
            "  inflating: trainA/2015-09-11 12_09_45.jpg  \n",
            "  inflating: trainA/2015-09-12 08_09_53.jpg  \n",
            "  inflating: trainA/2015-09-13 11_30_06.jpg  \n",
            "  inflating: trainA/2015-09-14 02_05_22.jpg  \n",
            "  inflating: trainA/2015-09-21 18_26_43.jpg  \n",
            "  inflating: trainA/2015-09-29 02_10_02.jpg  \n",
            "  inflating: trainA/2015-10-01 18_02_38.jpg  \n",
            "  inflating: trainA/2015-10-01 21_38_04.jpg  \n",
            "  inflating: trainA/2015-10-27 21_01_02.jpg  \n",
            "  inflating: trainA/2015-11-18 02_37_24.jpg  \n",
            "  inflating: trainA/2015-11-18 11_38_09.jpg  \n",
            "  inflating: trainA/2015-11-18 17_37_27.jpg  \n",
            "  inflating: trainA/2015-11-22 00_56_39.jpg  \n",
            "  inflating: trainA/2015-11-25 21_09_53.jpg  \n",
            "  inflating: trainA/2015-12-10 08_33_16.jpg  \n",
            "  inflating: trainA/2015-12-28 15_49_17.jpg  \n",
            "  inflating: trainA/2016-01-17 22_27_37.jpg  \n",
            "  inflating: trainA/2016-01-31 03_25_26.jpg  \n",
            "  inflating: trainA/2016-02-02 00_50_53.jpg  \n",
            "  inflating: trainA/2016-02-10 21_18_43.jpg  \n",
            "  inflating: trainA/2016-04-07 15_55_58.jpg  \n",
            "  inflating: trainA/2016-04-08 05_27_23.jpg  \n",
            "  inflating: trainA/2016-04-30 03_57_38.jpg  \n",
            "  inflating: trainA/2016-05-15 14_54_07.jpg  \n",
            "  inflating: trainA/2016-05-16 12_12_26.jpg  \n",
            "  inflating: trainA/2016-05-16 22_12_32.jpg  \n",
            "  inflating: trainA/2016-05-16 22_56_44.jpg  \n",
            "  inflating: trainA/2016-05-17 01_00_57.jpg  \n",
            "  inflating: trainA/2016-05-17 16_04_59.jpg  \n",
            "  inflating: trainA/2016-05-18 04_41_48.jpg  \n",
            "  inflating: trainA/2016-05-18 15_31_23.jpg  \n",
            "  inflating: trainA/2016-05-18 19_44_23.jpg  \n",
            "  inflating: trainA/2016-05-19 17_29_45.jpg  \n",
            "  inflating: trainA/2016-05-19 18_10_05.jpg  \n",
            "  inflating: trainA/2016-05-20 05_14_03.jpg  \n",
            "  inflating: trainA/2016-05-21 16_54_38.jpg  \n",
            "  inflating: trainA/2016-05-21 19_12_03.jpg  \n",
            "  inflating: trainA/2016-05-21 20_56_35.jpg  \n",
            "  inflating: trainA/2016-05-22 06_23_47.jpg  \n",
            "  inflating: trainA/2016-05-22 20_01_19.jpg  \n",
            "  inflating: trainA/2016-05-23 02_43_04.jpg  \n",
            "  inflating: trainA/2016-05-23 16_57_14.jpg  \n",
            "  inflating: trainA/2016-05-24 20_53_06.jpg  \n",
            "  inflating: trainA/2016-05-25 16_08_05.jpg  \n",
            "  inflating: trainA/2016-05-25 19_38_46.jpg  \n",
            "  inflating: trainA/2016-05-26 11_38_38.jpg  \n",
            "  inflating: trainA/2016-05-27 17_16_39.jpg  \n",
            "  inflating: trainA/2016-05-28 04_45_36.jpg  \n",
            "  inflating: trainA/2016-05-28 13_29_34.jpg  \n",
            "  inflating: trainA/2016-05-29 05_11_04.jpg  \n",
            "  inflating: trainA/2016-05-29 15_01_08.jpg  \n",
            "  inflating: trainA/2016-05-29 18_32_55.jpg  \n",
            "  inflating: trainA/2016-05-30 19_54_38.jpg  \n",
            "  inflating: trainA/2016-05-31 21_58_23.jpg  \n",
            "  inflating: trainA/2016-06-01 22_16_13.jpg  \n",
            "  inflating: trainA/2016-06-02 11_08_27.jpg  \n",
            "  inflating: trainA/2016-06-02 19_55_42.jpg  \n",
            "  inflating: trainA/2016-06-03 04_02_17.jpg  \n",
            "  inflating: trainA/2016-06-03 20_02_48.jpg  \n",
            "  inflating: trainA/2016-06-04 10_51_27.jpg  \n",
            "  inflating: trainA/2016-06-04 18_22_33.jpg  \n",
            "  inflating: trainA/2016-06-04 19_56_58.jpg  \n",
            "  inflating: trainA/2016-06-06 19_18_18.jpg  \n",
            "  inflating: trainA/2016-06-07 22_56_48.jpg  \n",
            "  inflating: trainA/2016-06-08 20_27_07.jpg  \n",
            "  inflating: trainA/2016-06-10 05_23_33.jpg  \n",
            "  inflating: trainA/2016-06-11 06_46_54.jpg  \n",
            "  inflating: trainA/2016-06-11 14_53_14.jpg  \n",
            "  inflating: trainA/2016-06-11 19_02_37.jpg  \n",
            "  inflating: trainA/2016-06-12 07_39_02.jpg  \n",
            "  inflating: trainA/2016-06-12 15_33_14.jpg  \n",
            "  inflating: trainA/2016-06-12 18_48_28.jpg  \n",
            "  inflating: trainA/2016-06-13 13_57_54.jpg  \n",
            "  inflating: trainA/2016-06-13 17_19_05.jpg  \n",
            "  inflating: trainA/2016-06-13 20_47_49.jpg  \n",
            "  inflating: trainA/2016-06-14 12_23_25.jpg  \n",
            "  inflating: trainA/2016-06-16 13_35_44.jpg  \n",
            "  inflating: trainA/2016-06-16 23_36_39.jpg  \n",
            "  inflating: trainA/2016-06-17 06_08_16.jpg  \n",
            "  inflating: trainA/2016-06-17 13_07_33.jpg  \n",
            "  inflating: trainA/2016-06-17 15_57_36.jpg  \n",
            "  inflating: trainA/2016-06-18 13_47_36.jpg  \n",
            "  inflating: trainA/2016-06-18 18_32_53.jpg  \n",
            "  inflating: trainA/2016-06-19 20_35_56.jpg  \n",
            "  inflating: trainA/2016-06-20 01_25_42.jpg  \n",
            "  inflating: trainA/2016-06-21 15_46_49.jpg  \n",
            "  inflating: trainA/2016-06-21 23_03_49.jpg  \n",
            "  inflating: trainA/2016-06-22 11_18_33.jpg  \n",
            "  inflating: trainA/2016-06-22 20_09_22.jpg  \n",
            "  inflating: trainA/2016-06-24 07_39_35.jpg  \n",
            "  inflating: trainA/2016-06-24 19_55_23.jpg  \n",
            "  inflating: trainA/2016-06-24 23_31_02.jpg  \n",
            "  inflating: trainA/2016-06-25 09_28_15.jpg  \n",
            "  inflating: trainA/2016-06-26 01_38_48.jpg  \n",
            "  inflating: trainA/2016-06-29 02_21_04.jpg  \n",
            "  inflating: trainA/2016-06-29 13_39_36.jpg  \n",
            "  inflating: trainA/2016-06-30 00_06_57.jpg  \n",
            "  inflating: trainA/2016-07-02 14_06_22.jpg  \n",
            "  inflating: trainA/2016-07-03 02_15_39.jpg  \n",
            "  inflating: trainA/2016-07-03 16_43_43.jpg  \n",
            "  inflating: trainA/2016-07-03 22_12_55.jpg  \n",
            "  inflating: trainA/2016-07-04 00_51_36.jpg  \n",
            "  inflating: trainA/2016-07-04 08_41_04.jpg  \n",
            "  inflating: trainA/2016-07-06 00_27_45.jpg  \n",
            "  inflating: trainA/2016-07-06 01_44_46.jpg  \n",
            "  inflating: trainA/2016-07-06 11_37_39.jpg  \n",
            "  inflating: trainA/2016-07-06 19_57_19.jpg  \n",
            "  inflating: trainA/2016-07-07 03_49_26.jpg  \n",
            "  inflating: trainA/2016-07-07 10_01_46.jpg  \n",
            "  inflating: trainA/2016-07-07 16_59_53.jpg  \n",
            "  inflating: trainA/2016-07-07 17_59_33.jpg  \n",
            "  inflating: trainA/2016-07-08 04_09_24.jpg  \n",
            "  inflating: trainA/2016-07-09 13_15_54.jpg  \n",
            "  inflating: trainA/2016-07-09 14_35_06.jpg  \n",
            "  inflating: trainA/2016-07-12 13_57_26.jpg  \n",
            "  inflating: trainA/2016-07-12 21_47_54.jpg  \n",
            "  inflating: trainA/2016-07-13 06_49_46.jpg  \n",
            "  inflating: trainA/2016-07-13 10_47_28.jpg  \n",
            "  inflating: trainA/2016-07-14 20_09_54.jpg  \n",
            "  inflating: trainA/2016-07-15 10_41_53.jpg  \n",
            "  inflating: trainA/2016-07-15 19_29_29.jpg  \n",
            "  inflating: trainA/2016-07-16 08_13_48.jpg  \n",
            "  inflating: trainA/2016-07-17 07_35_07.jpg  \n",
            "  inflating: trainA/2016-07-17 10_33_08.jpg  \n",
            "  inflating: trainA/2016-07-17 21_31_42.jpg  \n",
            "  inflating: trainA/2016-07-17 22_01_49.jpg  \n",
            "  inflating: trainA/2016-07-18 10_53_05.jpg  \n",
            "  inflating: trainA/2016-07-18 18_43_28.jpg  \n",
            "  inflating: trainA/2016-07-18 21_47_23.jpg  \n",
            "  inflating: trainA/2016-07-20 11_28_33.jpg  \n",
            "  inflating: trainA/2016-07-20 22_34_43.jpg  \n",
            "  inflating: trainA/2016-07-21 20_06_32.jpg  \n",
            "  inflating: trainA/2016-07-23 02_48_36.jpg  \n",
            "  inflating: trainA/2016-07-23 03_37_33.jpg  \n",
            "  inflating: trainA/2016-07-23 13_18_05.jpg  \n",
            "  inflating: trainA/2016-07-26 09_44_43.jpg  \n",
            "  inflating: trainA/2016-07-26 16_21_38.jpg  \n",
            "  inflating: trainA/2016-07-26 22_27_19.jpg  \n",
            "  inflating: trainA/2016-07-27 04_00_04.jpg  \n",
            "  inflating: trainA/2016-07-27 16_46_28.jpg  \n",
            "  inflating: trainA/2016-07-28 07_13_55.jpg  \n",
            "  inflating: trainA/2016-07-28 19_07_24.jpg  \n",
            "  inflating: trainA/2016-07-29 23_00_19.jpg  \n",
            "  inflating: trainA/2016-07-30 03_40_16.jpg  \n",
            "  inflating: trainA/2016-07-30 08_15_54.jpg  \n",
            "  inflating: trainA/2016-07-30 20_20_17.jpg  \n",
            "  inflating: trainA/2016-07-31 06_00_29.jpg  \n",
            "  inflating: trainA/2016-07-31 17_04_34.jpg  \n",
            "  inflating: trainA/2016-08-01 05_15_03.jpg  \n",
            "  inflating: trainA/2016-08-01 22_53_25.jpg  \n",
            "  inflating: trainA/2016-08-02 12_45_58.jpg  \n",
            "  inflating: trainA/2016-08-02 17_59_22.jpg  \n",
            "  inflating: trainA/2016-08-02 19_50_33.jpg  \n",
            "  inflating: trainA/2016-08-03 19_26_22.jpg  \n",
            "  inflating: trainA/2016-08-04 11_30_32.jpg  \n",
            "  inflating: trainA/2016-08-04 16_46_47.jpg  \n",
            "  inflating: trainA/2016-08-05 00_48_43.jpg  \n",
            "  inflating: trainA/2016-08-06 15_03_35.jpg  \n",
            "  inflating: trainA/2016-08-07 05_41_24.jpg  \n",
            "  inflating: trainA/2016-08-07 19_43_24.jpg  \n",
            "  inflating: trainA/2016-08-07 20_08_49.jpg  \n",
            "  inflating: trainA/2016-08-07 20_43_23.jpg  \n",
            "  inflating: trainA/2016-08-07 21_14_52.jpg  \n",
            "  inflating: trainA/2016-08-08 04_07_39.jpg  \n",
            "  inflating: trainA/2016-08-08 16_20_05.jpg  \n",
            "  inflating: trainA/2016-08-10 02_02_08.jpg  \n",
            "  inflating: trainA/2016-08-10 09_17_57.jpg  \n",
            "  inflating: trainA/2016-08-10 11_26_13.jpg  \n",
            "  inflating: trainA/2016-08-10 12_14_04.jpg  \n",
            "  inflating: trainA/2016-08-10 15_36_17.jpg  \n",
            "  inflating: trainA/2016-08-11 19_02_44.jpg  \n",
            "  inflating: trainA/2016-08-13 00_28_37.jpg  \n",
            "  inflating: trainA/2016-08-13 02_21_25.jpg  \n",
            "  inflating: trainA/2016-08-13 22_10_37.jpg  \n",
            "  inflating: trainA/2016-08-15 09_41_23.jpg  \n",
            "  inflating: trainA/2016-08-16 21_40_14.jpg  \n",
            "  inflating: trainA/2016-08-17 15_19_27.jpg  \n",
            "  inflating: trainA/2016-08-18 08_51_23.jpg  \n",
            "  inflating: trainA/2016-08-19 08_31_05.jpg  \n",
            "  inflating: trainA/2016-08-19 08_32_28.jpg  \n",
            "  inflating: trainA/2016-08-20 19_17_22.jpg  \n",
            "  inflating: trainA/2016-08-20 23_00_34.jpg  \n",
            "  inflating: trainA/2016-08-21 09_39_08.jpg  \n",
            "  inflating: trainA/2016-08-21 12_39_29.jpg  \n",
            "  inflating: trainA/2016-08-21 19_02_07.jpg  \n",
            "  inflating: trainA/2016-08-22 07_20_48.jpg  \n",
            "  inflating: trainA/2016-08-22 11_54_44.jpg  \n",
            "  inflating: trainA/2016-08-22 23_28_45.jpg  \n",
            "  inflating: trainA/2016-08-23 22_43_57.jpg  \n",
            "  inflating: trainA/2016-08-24 01_11_56.jpg  \n",
            "  inflating: trainA/2016-08-24 16_43_58.jpg  \n",
            "  inflating: trainA/2016-08-24 22_48_35.jpg  \n",
            "  inflating: trainA/2016-08-25 13_36_17.jpg  \n",
            "  inflating: trainA/2016-08-28 20_55_57.jpg  \n",
            "  inflating: trainA/2016-08-29 10_23_47.jpg  \n",
            "  inflating: trainA/2016-08-29 18_31_46.jpg  \n",
            "  inflating: trainA/2016-08-29 19_38_06.jpg  \n",
            "  inflating: trainA/2016-08-30 02_06_35.jpg  \n",
            "  inflating: trainA/2016-08-30 04_09_02.jpg  \n",
            "  inflating: trainA/2016-08-31 22_47_05.jpg  \n",
            "  inflating: trainA/2016-09-04 23_49_32.jpg  \n",
            "  inflating: trainA/2016-09-05 10_43_55.jpg  \n",
            "  inflating: trainA/2016-09-05 21_29_59.jpg  \n",
            "  inflating: trainA/2016-09-06 03_40_17.jpg  \n",
            "  inflating: trainA/2016-09-06 18_32_34.jpg  \n",
            "  inflating: trainA/2016-09-06 22_18_14.jpg  \n",
            "  inflating: trainA/2016-09-07 14_13_57.jpg  \n",
            "  inflating: trainA/2016-09-07 21_56_25.jpg  \n",
            "  inflating: trainA/2016-09-08 15_29_45.jpg  \n",
            "  inflating: trainA/2016-09-08 17_15_18.jpg  \n",
            "  inflating: trainA/2016-09-08 20_05_17.jpg  \n",
            "  inflating: trainA/2016-09-08 22_06_35.jpg  \n",
            "  inflating: trainA/2016-09-08 23_21_04.jpg  \n",
            "  inflating: trainA/2016-09-10 13_27_34.jpg  \n",
            "  inflating: trainA/2016-09-11 10_03_22.jpg  \n",
            "  inflating: trainA/2016-09-11 13_38_16.jpg  \n",
            "  inflating: trainA/2016-09-12 21_34_08.jpg  \n",
            "  inflating: trainA/2016-09-12 21_39_34.jpg  \n",
            "  inflating: trainA/2016-09-13 01_08_45.jpg  \n",
            "  inflating: trainA/2016-09-13 14_31_52.jpg  \n",
            "  inflating: trainA/2016-09-13 14_54_17.jpg  \n",
            "  inflating: trainA/2016-09-13 23_58_54.jpg  \n",
            "  inflating: trainA/2016-09-14 03_30_15.jpg  \n",
            "  inflating: trainA/2016-09-14 05_35_47.jpg  \n",
            "  inflating: trainA/2016-09-14 10_49_54.jpg  \n",
            "  inflating: trainA/2016-09-14 13_36_44.jpg  \n",
            "  inflating: trainA/2016-09-14 17_51_46.jpg  \n",
            "  inflating: trainA/2016-09-14 21_28_53.jpg  \n",
            "  inflating: trainA/2016-09-25 08_37_53.jpg  \n",
            "  inflating: trainA/2016-10-11 10_38_28.jpg  \n",
            "  inflating: trainA/2016-10-14 14_49_49.jpg  \n",
            "  inflating: trainA/2016-12-30 20_01_54.jpg  \n",
            "  inflating: trainA/2017-01-30 13_36_29.jpg  \n",
            "  inflating: trainA/2017-02-12 13_10_05.jpg  \n",
            "  inflating: trainA/2017-03-05 05_37_07.jpg  \n",
            "  inflating: trainA/2017-03-08 21_46_34.jpg  \n",
            "  inflating: trainA/2017-03-13 03_05_48.jpg  \n",
            "  inflating: trainA/2017-03-14 10_23_56.jpg  \n",
            "  inflating: trainB/2005-06-26 14_04_52.jpg  \n",
            "  inflating: trainB/2005-08-02 09_19_52.jpg  \n",
            "  inflating: trainB/2005-08-10 13_03_58.jpg  \n",
            "  inflating: trainB/2005-09-01 10_05_22.jpg  \n",
            "  inflating: trainB/2006-02-26 17_07_52.jpg  \n",
            "  inflating: trainB/2006-03-14 21_56_17.jpg  \n",
            "  inflating: trainB/2006-03-20 23_39_46.jpg  \n",
            "  inflating: trainB/2006-07-05 20_27_58.jpg  \n",
            "  inflating: trainB/2006-07-16 14_00_05.jpg  \n",
            "  inflating: trainB/2006-09-26 21_50_33.jpg  \n",
            "  inflating: trainB/2006-12-24 08_44_26.jpg  \n",
            "  inflating: trainB/2007-01-15 20_05_43.jpg  \n",
            "  inflating: trainB/2007-01-23 19_32_24.jpg  \n",
            "  inflating: trainB/2007-01-27 00_13_15.jpg  \n",
            "  inflating: trainB/2007-02-28 14_15_05.jpg  \n",
            "  inflating: trainB/2007-03-06 10_22_16.jpg  \n",
            "  inflating: trainB/2007-03-16 21_52_46.jpg  \n",
            "  inflating: trainB/2007-04-05 00_31_04.jpg  \n",
            "  inflating: trainB/2007-04-30 20_41_22.jpg  \n",
            "  inflating: trainB/2007-06-06 03_56_19.jpg  \n",
            "  inflating: trainB/2007-06-21 18_15_16.jpg  \n",
            "  inflating: trainB/2007-08-27 22_57_52.jpg  \n",
            "  inflating: trainB/2007-09-12 08_05_38.jpg  \n",
            "  inflating: trainB/2007-09-12 14_05_14.jpg  \n",
            "  inflating: trainB/2007-09-25 13_22_25.jpg  \n",
            "  inflating: trainB/2007-10-16 14_04_05.jpg  \n",
            "  inflating: trainB/2007-10-17 02_48_15.jpg  \n",
            "  inflating: trainB/2007-10-20 10_55_45.jpg  \n",
            "  inflating: trainB/2007-12-16 07_54_17.jpg  \n",
            "  inflating: trainB/2008-01-08 20_39_08.jpg  \n",
            "  inflating: trainB/2008-01-19 07_55_07.jpg  \n",
            "  inflating: trainB/2008-01-19 08_51_37.jpg  \n",
            "  inflating: trainB/2008-01-27 10_47_04.jpg  \n",
            "  inflating: trainB/2008-01-27 17_47_34.jpg  \n",
            "  inflating: trainB/2008-02-03 17_24_26.jpg  \n",
            "  inflating: trainB/2008-02-03 19_31_33.jpg  \n",
            "  inflating: trainB/2008-02-19 22_23_33.jpg  \n",
            "  inflating: trainB/2008-02-21 17_19_02.jpg  \n",
            "  inflating: trainB/2008-03-16 12_41_07.jpg  \n",
            "  inflating: trainB/2008-03-16 20_11_44.jpg  \n",
            "  inflating: trainB/2008-03-21 06_49_23.jpg  \n",
            "  inflating: trainB/2008-03-21 23_50_36.jpg  \n",
            "  inflating: trainB/2008-04-06 15_45_33.jpg  \n",
            "  inflating: trainB/2008-04-12 09_09_08.jpg  \n",
            "  inflating: trainB/2008-05-17 11_11_13.jpg  \n",
            "  inflating: trainB/2008-06-06 22_25_26.jpg  \n",
            "  inflating: trainB/2008-07-16 07_44_17.jpg  \n",
            "  inflating: trainB/2008-07-17 22_56_47.jpg  \n",
            "  inflating: trainB/2008-07-23 03_40_07.jpg  \n",
            "  inflating: trainB/2008-07-23 08_39_48.jpg  \n",
            "  inflating: trainB/2008-08-11 23_15_19.jpg  \n",
            "  inflating: trainB/2008-09-08 18_23_56.jpg  \n",
            "  inflating: trainB/2008-10-29 13_42_05.jpg  \n",
            "  inflating: trainB/2008-11-09 10_21_43.jpg  \n",
            "  inflating: trainB/2008-12-24 21_04_18.jpg  \n",
            "  inflating: trainB/2008-12-24 21_26_26.jpg  \n",
            "  inflating: trainB/2008-12-30 12_52_03.jpg  \n",
            "  inflating: trainB/2008-12-31 15_34_39.jpg  \n",
            "  inflating: trainB/2009-01-04 22_10_03.jpg  \n",
            "  inflating: trainB/2009-01-11 10_23_59.jpg  \n",
            "  inflating: trainB/2009-01-18 04_39_56.jpg  \n",
            "  inflating: trainB/2009-01-21 15_55_45.jpg  \n",
            "  inflating: trainB/2009-01-24 00_59_35.jpg  \n",
            "  inflating: trainB/2009-02-20 16_02_22.jpg  \n",
            "  inflating: trainB/2009-02-22 13_10_42.jpg  \n",
            "  inflating: trainB/2009-02-23 07_47_26.jpg  \n",
            "  inflating: trainB/2009-02-25 09_02_53.jpg  \n",
            "  inflating: trainB/2009-02-27 00_55_22.jpg  \n",
            "  inflating: trainB/2009-03-20 10_02_28.jpg  \n",
            "  inflating: trainB/2009-03-31 09_21_06.jpg  \n",
            "  inflating: trainB/2009-04-01 10_17_19.jpg  \n",
            "  inflating: trainB/2009-04-06 17_22_09.jpg  \n",
            "  inflating: trainB/2009-05-01 07_24_33.jpg  \n",
            "  inflating: trainB/2009-05-12 13_53_37.jpg  \n",
            "  inflating: trainB/2009-05-13 15_01_35.jpg  \n",
            "  inflating: trainB/2009-05-17 13_15_25.jpg  \n",
            "  inflating: trainB/2009-05-28 09_22_54.jpg  \n",
            "  inflating: trainB/2009-06-06 20_59_54.jpg  \n",
            "  inflating: trainB/2009-06-20 06_32_25.jpg  \n",
            "  inflating: trainB/2009-06-24 02_06_39.jpg  \n",
            "  inflating: trainB/2009-07-01 18_07_28.jpg  \n",
            "  inflating: trainB/2009-07-11 22_56_02.jpg  \n",
            "  inflating: trainB/2009-07-17 15_37_15.jpg  \n",
            "  inflating: trainB/2009-10-15 11_28_18.jpg  \n",
            "  inflating: trainB/2009-11-04 14_28_46.jpg  \n",
            "  inflating: trainB/2009-11-17 00_03_25.jpg  \n",
            "  inflating: trainB/2009-11-27 12_00_43.jpg  \n",
            "  inflating: trainB/2009-11-29 16_01_54.jpg  \n",
            "  inflating: trainB/2009-12-01 18_29_53.jpg  \n",
            "  inflating: trainB/2009-12-21 11_37_04.jpg  \n",
            "  inflating: trainB/2009-12-26 19_11_59.jpg  \n",
            "  inflating: trainB/2009-12-29 13_08_17.jpg  \n",
            "  inflating: trainB/2010-01-01 22_07_47.jpg  \n",
            "  inflating: trainB/2010-01-02 22_47_38.jpg  \n",
            "  inflating: trainB/2010-01-06 09_41_43.jpg  \n",
            "  inflating: trainB/2010-01-10 21_32_38.jpg  \n",
            "  inflating: trainB/2010-01-13 21_43_54.jpg  \n",
            "  inflating: trainB/2010-01-15 22_26_56.jpg  \n",
            "  inflating: trainB/2010-01-18 16_47_35.jpg  \n",
            "  inflating: trainB/2010-01-20 13_14_28.jpg  \n",
            "  inflating: trainB/2010-02-01 16_54_22.jpg  \n",
            "  inflating: trainB/2010-02-12 09_28_55.jpg  \n",
            "  inflating: trainB/2010-02-14 01_36_25.jpg  \n",
            "  inflating: trainB/2010-02-15 11_31_18.jpg  \n",
            "  inflating: trainB/2010-02-17 21_19_09.jpg  \n",
            "  inflating: trainB/2010-02-18 13_54_37.jpg  \n",
            "  inflating: trainB/2010-03-05 12_52_53.jpg  \n",
            "  inflating: trainB/2010-03-09 00_00_07.jpg  \n",
            "  inflating: trainB/2010-03-11 07_59_22.jpg  \n",
            "  inflating: trainB/2010-03-13 13_38_19.jpg  \n",
            "  inflating: trainB/2010-03-23 08_05_53.jpg  \n",
            "  inflating: trainB/2010-03-27 14_48_34.jpg  \n",
            "  inflating: trainB/2010-03-29 00_29_56.jpg  \n",
            "  inflating: trainB/2010-04-02 15_14_55.jpg  \n",
            "  inflating: trainB/2010-04-05 08_01_37.jpg  \n",
            "  inflating: trainB/2010-04-07 17_34_27.jpg  \n",
            "  inflating: trainB/2010-04-08 21_48_56.jpg  \n",
            "  inflating: trainB/2010-04-14 16_45_17.jpg  \n",
            "  inflating: trainB/2010-04-14 21_39_26.jpg  \n",
            "  inflating: trainB/2010-04-17 12_07_09.jpg  \n",
            "  inflating: trainB/2010-05-07 17_42_43.jpg  \n",
            "  inflating: trainB/2010-05-18 02_58_18.jpg  \n",
            "  inflating: trainB/2010-05-23 18_45_32.jpg  \n",
            "  inflating: trainB/2010-05-25 21_08_33.jpg  \n",
            "  inflating: trainB/2010-06-09 16_43_22.jpg  \n",
            "  inflating: trainB/2010-06-14 00_09_53.jpg  \n",
            "  inflating: trainB/2010-06-18 21_35_28.jpg  \n",
            "  inflating: trainB/2010-06-28 19_35_49.jpg  \n",
            "  inflating: trainB/2010-07-11 20_28_03.jpg  \n",
            "  inflating: trainB/2010-08-01 16_36_28.jpg  \n",
            "  inflating: trainB/2010-08-16 00_19_33.jpg  \n",
            "  inflating: trainB/2010-09-02 06_44_17.jpg  \n",
            "  inflating: trainB/2010-09-07 13_26_25.jpg  \n",
            "  inflating: trainB/2010-09-14 19_50_46.jpg  \n",
            "  inflating: trainB/2010-09-17 23_00_42.jpg  \n",
            "  inflating: trainB/2010-10-13 16_17_38.jpg  \n",
            "  inflating: trainB/2010-10-14 20_05_03.jpg  \n",
            "  inflating: trainB/2010-10-24 23_06_14.jpg  \n",
            "  inflating: trainB/2010-10-29 09_58_13.jpg  \n",
            "  inflating: trainB/2010-11-06 09_26_09.jpg  \n",
            "  inflating: trainB/2010-11-22 22_46_13.jpg  \n",
            "  inflating: trainB/2010-11-24 10_00_38.jpg  \n",
            "  inflating: trainB/2010-12-01 09_32_23.jpg  \n",
            "  inflating: trainB/2010-12-02 10_52_29.jpg  \n",
            "  inflating: trainB/2010-12-04 12_09_12.jpg  \n",
            "  inflating: trainB/2010-12-04 12_20_06.jpg  \n",
            "  inflating: trainB/2010-12-07 14_12_18.jpg  \n",
            "  inflating: trainB/2010-12-10 08_57_26.jpg  \n",
            "  inflating: trainB/2010-12-10 17_37_22.jpg  \n",
            "  inflating: trainB/2010-12-11 05_52_09.jpg  \n",
            "  inflating: trainB/2010-12-11 17_14_52.jpg  \n",
            "  inflating: trainB/2010-12-12 18_13_04.jpg  \n",
            "  inflating: trainB/2010-12-13 04_11_25.jpg  \n",
            "  inflating: trainB/2010-12-15 16_06_58.jpg  \n",
            "  inflating: trainB/2010-12-15 18_32_44.jpg  \n",
            "  inflating: trainB/2010-12-16 13_21_05.jpg  \n",
            "  inflating: trainB/2010-12-18 12_05_18.jpg  \n",
            "  inflating: trainB/2010-12-24 16_58_28.jpg  \n",
            "  inflating: trainB/2010-12-27 10_50_47.jpg  \n",
            "  inflating: trainB/2010-12-27 12_58_07.jpg  \n",
            "  inflating: trainB/2010-12-27 16_01_47.jpg  \n",
            "  inflating: trainB/2010-12-27 16_17_44.jpg  \n",
            "  inflating: trainB/2010-12-30 11_25_27.jpg  \n",
            "  inflating: trainB/2010-12-30 18_12_24.jpg  \n",
            "  inflating: trainB/2010-12-31 10_55_04.jpg  \n",
            "  inflating: trainB/2010-12-31 11_14_54.jpg  \n",
            "  inflating: trainB/2010-12-31 13_43_22.jpg  \n",
            "  inflating: trainB/2010-12-31 16_38_06.jpg  \n",
            "  inflating: trainB/2011-01-01 19_20_14.jpg  \n",
            "  inflating: trainB/2011-01-01 23_21_17.jpg  \n",
            "  inflating: trainB/2011-01-02 16_10_55.jpg  \n",
            "  inflating: trainB/2011-01-04 23_56_27.jpg  \n",
            "  inflating: trainB/2011-01-05 07_51_54.jpg  \n",
            "  inflating: trainB/2011-01-05 20_30_03.jpg  \n",
            "  inflating: trainB/2011-01-06 22_15_33.jpg  \n",
            "  inflating: trainB/2011-01-07 10_09_47.jpg  \n",
            "  inflating: trainB/2011-01-07 15_49_57.jpg  \n",
            "  inflating: trainB/2011-01-08 11_57_43.jpg  \n",
            "  inflating: trainB/2011-01-09 08_03_02.jpg  \n",
            "  inflating: trainB/2011-01-09 14_32_42.jpg  \n",
            "  inflating: trainB/2011-01-09 14_33_02.jpg  \n",
            "  inflating: trainB/2011-01-11 19_21_46.jpg  \n",
            "  inflating: trainB/2011-01-11 20_06_09.jpg  \n",
            "  inflating: trainB/2011-01-13 04_56_19.jpg  \n",
            "  inflating: trainB/2011-01-14 20_01_19.jpg  \n",
            "  inflating: trainB/2011-01-15 21_45_08.jpg  \n",
            "  inflating: trainB/2011-01-16 08_13_52.jpg  \n",
            "  inflating: trainB/2011-01-16 14_04_54.jpg  \n",
            "  inflating: trainB/2011-01-16 16_58_45.jpg  \n",
            "  inflating: trainB/2011-01-16 20_36_37.jpg  \n",
            "  inflating: trainB/2011-01-17 07_47_37.jpg  \n",
            "  inflating: trainB/2011-01-22 07_45_04.jpg  \n",
            "  inflating: trainB/2011-01-22 09_05_37.jpg  \n",
            "  inflating: trainB/2011-01-22 15_15_14.jpg  \n",
            "  inflating: trainB/2011-01-22 17_08_58.jpg  \n",
            "  inflating: trainB/2011-01-22 17_49_29.jpg  \n",
            "  inflating: trainB/2011-01-22 20_09_12.jpg  \n",
            "  inflating: trainB/2011-01-23 09_42_42.jpg  \n",
            "  inflating: trainB/2011-01-26 22_41_29.jpg  \n",
            "  inflating: trainB/2011-01-30 04_10_12.jpg  \n",
            "  inflating: trainB/2011-01-30 17_20_36.jpg  \n",
            "  inflating: trainB/2011-01-31 15_52_53.jpg  \n",
            "  inflating: trainB/2011-01-31 22_44_38.jpg  \n",
            "  inflating: trainB/2011-02-01 19_09_14.jpg  \n",
            "  inflating: trainB/2011-02-06 23_49_34.jpg  \n",
            "  inflating: trainB/2011-02-19 13_48_28.jpg  \n",
            "  inflating: trainB/2011-02-22 23_13_54.jpg  \n",
            "  inflating: trainB/2011-02-25 08_13_05.jpg  \n",
            "  inflating: trainB/2011-02-27 10_57_18.jpg  \n",
            "  inflating: trainB/2011-02-27 17_56_32.jpg  \n",
            "  inflating: trainB/2011-02-28 05_37_26.jpg  \n",
            "  inflating: trainB/2011-02-28 14_43_59.jpg  \n",
            "  inflating: trainB/2011-03-01 22_05_36.jpg  \n",
            "  inflating: trainB/2011-03-06 11_38_49.jpg  \n",
            "  inflating: trainB/2011-03-07 00_05_49.jpg  \n",
            "  inflating: trainB/2011-03-10 14_37_59.jpg  \n",
            "  inflating: trainB/2011-03-11 15_53_06.jpg  \n",
            "  inflating: trainB/2011-03-15 18_14_56.jpg  \n",
            "  inflating: trainB/2011-03-19 15_24_35.jpg  \n",
            "  inflating: trainB/2011-03-21 06_23_28.jpg  \n",
            "  inflating: trainB/2011-03-24 20_56_26.jpg  \n",
            "  inflating: trainB/2011-03-28 15_15_48.jpg  \n",
            "  inflating: trainB/2011-04-02 13_06_12.jpg  \n",
            "  inflating: trainB/2011-04-03 09_56_56.jpg  \n",
            "  inflating: trainB/2011-04-08 17_38_52.jpg  \n",
            "  inflating: trainB/2011-04-09 12_52_15.jpg  \n",
            "  inflating: trainB/2011-04-09 15_40_45.jpg  \n",
            "  inflating: trainB/2011-04-09 16_34_42.jpg  \n",
            "  inflating: trainB/2011-04-23 11_40_15.jpg  \n",
            "  inflating: trainB/2011-04-26 20_44_32.jpg  \n",
            "  inflating: trainB/2011-05-08 14_31_34.jpg  \n",
            "  inflating: trainB/2011-05-11 00_08_49.jpg  \n",
            "  inflating: trainB/2011-05-11 09_59_17.jpg  \n",
            "  inflating: trainB/2011-05-16 07_20_13.jpg  \n",
            "  inflating: trainB/2011-05-17 09_22_49.jpg  \n",
            "  inflating: trainB/2011-05-31 16_02_49.jpg  \n",
            "  inflating: trainB/2011-06-02 09_57_25.jpg  \n",
            "  inflating: trainB/2011-06-06 15_15_24.jpg  \n",
            "  inflating: trainB/2011-06-14 06_30_17.jpg  \n",
            "  inflating: trainB/2011-06-20 10_26_43.jpg  \n",
            "  inflating: trainB/2011-06-26 21_13_18.jpg  \n",
            "  inflating: trainB/2011-06-28 23_15_39.jpg  \n",
            "  inflating: trainB/2011-07-03 16_57_09.jpg  \n",
            "  inflating: trainB/2011-07-04 21_29_52.jpg  \n",
            "  inflating: trainB/2011-07-07 16_31_45.jpg  \n",
            "  inflating: trainB/2011-07-09 06_38_02.jpg  \n",
            "  inflating: trainB/2011-07-10 15_39_59.jpg  \n",
            "  inflating: trainB/2011-07-17 07_47_59.jpg  \n",
            "  inflating: trainB/2011-07-25 15_53_52.jpg  \n",
            "  inflating: trainB/2011-07-27 16_46_06.jpg  \n",
            "  inflating: trainB/2011-08-02 19_37_49.jpg  \n",
            "  inflating: trainB/2011-08-14 05_50_05.jpg  \n",
            "  inflating: trainB/2011-08-18 15_47_08.jpg  \n",
            "  inflating: trainB/2011-08-27 18_59_05.jpg  \n",
            "  inflating: trainB/2011-08-28 11_39_23.jpg  \n",
            "  inflating: trainB/2011-09-23 22_24_49.jpg  \n",
            "  inflating: trainB/2011-10-02 11_45_45.jpg  \n",
            "  inflating: trainB/2011-10-24 08_51_25.jpg  \n",
            "  inflating: trainB/2011-10-25 18_23_22.jpg  \n",
            "  inflating: trainB/2011-10-30 04_37_49.jpg  \n",
            "  inflating: trainB/2011-11-20 01_25_28.jpg  \n",
            "  inflating: trainB/2011-11-22 08_55_47.jpg  \n",
            "  inflating: trainB/2011-11-24 13_39_56.jpg  \n",
            "  inflating: trainB/2011-11-28 18_28_49.jpg  \n",
            "  inflating: trainB/2011-12-07 15_50_49.jpg  \n",
            "  inflating: trainB/2011-12-12 08_56_18.jpg  \n",
            "  inflating: trainB/2011-12-16 01_36_17.jpg  \n",
            "  inflating: trainB/2011-12-16 04_48_47.jpg  \n",
            "  inflating: trainB/2011-12-18 14_00_58.jpg  \n",
            "  inflating: trainB/2011-12-28 14_51_14.jpg  \n",
            "  inflating: trainB/2011-12-29 13_30_12.jpg  \n",
            "  inflating: trainB/2011-12-30 16_28_32.jpg  \n",
            "  inflating: trainB/2011-12-31 10_59_49.jpg  \n",
            "  inflating: trainB/2011-12-31 17_02_24.jpg  \n",
            "  inflating: trainB/2011-12-31 18_00_22.jpg  \n",
            "  inflating: trainB/2012-01-01 00_00_17.jpg  \n",
            "  inflating: trainB/2012-01-02 16_51_43.jpg  \n",
            "  inflating: trainB/2012-01-02 17_03_14.jpg  \n",
            "  inflating: trainB/2012-01-02 20_24_05.jpg  \n",
            "  inflating: trainB/2012-01-05 18_58_09.jpg  \n",
            "  inflating: trainB/2012-01-06 15_37_42.jpg  \n",
            "  inflating: trainB/2012-01-07 16_08_56.jpg  \n",
            "  inflating: trainB/2012-01-08 02_31_07.jpg  \n",
            "  inflating: trainB/2012-01-08 12_38_12.jpg  \n",
            "  inflating: trainB/2012-01-08 18_06_56.jpg  \n",
            "  inflating: trainB/2012-01-12 21_42_13.jpg  \n",
            "  inflating: trainB/2012-01-13 02_53_26.jpg  \n",
            "  inflating: trainB/2012-01-13 13_12_56.jpg  \n",
            "  inflating: trainB/2012-01-14 06_17_43.jpg  \n",
            "  inflating: trainB/2012-01-14 19_54_26.jpg  \n",
            "  inflating: trainB/2012-01-15 00_28_33.jpg  \n",
            "  inflating: trainB/2012-01-15 10_31_36.jpg  \n",
            "  inflating: trainB/2012-01-15 17_05_56.jpg  \n",
            "  inflating: trainB/2012-01-15 17_37_25.jpg  \n",
            "  inflating: trainB/2012-01-16 09_37_14.jpg  \n",
            "  inflating: trainB/2012-01-16 16_52_39.jpg  \n",
            "  inflating: trainB/2012-01-16 16_54_23.jpg  \n",
            "  inflating: trainB/2012-01-17 11_07_15.jpg  \n",
            "  inflating: trainB/2012-01-18 01_24_13.jpg  \n",
            "  inflating: trainB/2012-01-19 14_13_46.jpg  \n",
            "  inflating: trainB/2012-01-19 22_05_58.jpg  \n",
            "  inflating: trainB/2012-01-24 17_18_38.jpg  \n",
            "  inflating: trainB/2012-01-24 22_01_44.jpg  \n",
            "  inflating: trainB/2012-01-24 23_09_06.jpg  \n",
            "  inflating: trainB/2012-01-26 15_27_43.jpg  \n",
            "  inflating: trainB/2012-01-28 16_20_33.jpg  \n",
            "  inflating: trainB/2012-01-28 17_18_26.jpg  \n",
            "  inflating: trainB/2012-01-28 21_01_42.jpg  \n",
            "  inflating: trainB/2012-01-29 18_22_08.jpg  \n",
            "  inflating: trainB/2012-01-29 19_24_19.jpg  \n",
            "  inflating: trainB/2012-01-30 23_43_14.jpg  \n",
            "  inflating: trainB/2012-01-31 23_12_39.jpg  \n",
            "  inflating: trainB/2012-02-05 21_29_58.jpg  \n",
            "  inflating: trainB/2012-02-06 10_43_34.jpg  \n",
            "  inflating: trainB/2012-02-09 05_02_07.jpg  \n",
            "  inflating: trainB/2012-02-13 16_51_25.jpg  \n",
            "  inflating: trainB/2012-02-19 10_49_56.jpg  \n",
            "  inflating: trainB/2012-02-20 06_06_58.jpg  \n",
            "  inflating: trainB/2012-02-20 18_30_34.jpg  \n",
            "  inflating: trainB/2012-02-26 16_32_43.jpg  \n",
            "  inflating: trainB/2012-02-27 10_26_15.jpg  \n",
            "  inflating: trainB/2012-02-27 19_18_07.jpg  \n",
            "  inflating: trainB/2012-03-02 08_34_14.jpg  \n",
            "  inflating: trainB/2012-03-16 22_47_15.jpg  \n",
            "  inflating: trainB/2012-03-18 23_19_24.jpg  \n",
            "  inflating: trainB/2012-03-21 05_28_25.jpg  \n",
            "  inflating: trainB/2012-03-24 09_22_19.jpg  \n",
            "  inflating: trainB/2012-03-28 22_03_17.jpg  \n",
            "  inflating: trainB/2012-03-29 20_44_23.jpg  \n",
            "  inflating: trainB/2012-04-01 19_07_54.jpg  \n",
            "  inflating: trainB/2012-04-04 18_53_25.jpg  \n",
            "  inflating: trainB/2012-04-04 21_53_52.jpg  \n",
            "  inflating: trainB/2012-04-09 05_52_53.jpg  \n",
            "  inflating: trainB/2012-04-10 15_13_55.jpg  \n",
            "  inflating: trainB/2012-04-23 15_02_58.jpg  \n",
            "  inflating: trainB/2012-04-30 19_51_14.jpg  \n",
            "  inflating: trainB/2012-05-04 10_36_48.jpg  \n",
            "  inflating: trainB/2012-05-08 12_36_36.jpg  \n",
            "  inflating: trainB/2012-05-09 09_19_28.jpg  \n",
            "  inflating: trainB/2012-05-29 22_17_05.jpg  \n",
            "  inflating: trainB/2012-06-05 01_13_19.jpg  \n",
            "  inflating: trainB/2012-06-10 11_00_13.jpg  \n",
            "  inflating: trainB/2012-06-23 21_38_38.jpg  \n",
            "  inflating: trainB/2012-06-28 12_48_43.jpg  \n",
            "  inflating: trainB/2012-07-06 01_19_57.jpg  \n",
            "  inflating: trainB/2012-08-25 15_52_45.jpg  \n",
            "  inflating: trainB/2012-08-26 18_37_14.jpg  \n",
            "  inflating: trainB/2012-09-26 07_30_13.jpg  \n",
            "  inflating: trainB/2012-10-23 08_36_13.jpg  \n",
            "  inflating: trainB/2012-11-02 00_08_59.jpg  \n",
            "  inflating: trainB/2012-11-13 17_53_04.jpg  \n",
            "  inflating: trainB/2012-11-15 19_18_43.jpg  \n",
            "  inflating: trainB/2012-11-26 00_02_27.jpg  \n",
            "  inflating: trainB/2012-11-28 12_54_59.jpg  \n",
            "  inflating: trainB/2012-11-29 08_55_04.jpg  \n",
            "  inflating: trainB/2012-12-02 11_17_43.jpg  \n",
            "  inflating: trainB/2012-12-02 16_10_07.jpg  \n",
            "  inflating: trainB/2012-12-04 07_19_18.jpg  \n",
            "  inflating: trainB/2012-12-07 16_14_54.jpg  \n",
            "  inflating: trainB/2012-12-08 02_19_35.jpg  \n",
            "  inflating: trainB/2012-12-08 10_27_25.jpg  \n",
            "  inflating: trainB/2012-12-09 17_11_53.jpg  \n",
            "  inflating: trainB/2012-12-09 19_20_59.jpg  \n",
            "  inflating: trainB/2012-12-11 22_14_02.jpg  \n",
            "  inflating: trainB/2012-12-12 14_27_52.jpg  \n",
            "  inflating: trainB/2012-12-13 08_28_19.jpg  \n",
            "  inflating: trainB/2012-12-13 13_35_15.jpg  \n",
            "  inflating: trainB/2012-12-13 16_07_05.jpg  \n",
            "  inflating: trainB/2012-12-14 06_02_39.jpg  \n",
            "  inflating: trainB/2012-12-14 18_57_46.jpg  \n",
            "  inflating: trainB/2012-12-15 07_10_03.jpg  \n",
            "  inflating: trainB/2012-12-16 13_46_26.jpg  \n",
            "  inflating: trainB/2012-12-16 14_32_39.jpg  \n",
            "  inflating: trainB/2012-12-23 12_16_26.jpg  \n",
            "  inflating: trainB/2012-12-23 22_44_08.jpg  \n",
            "  inflating: trainB/2012-12-24 07_18_33.jpg  \n",
            "  inflating: trainB/2012-12-24 09_31_46.jpg  \n",
            "  inflating: trainB/2012-12-24 16_27_54.jpg  \n",
            "  inflating: trainB/2012-12-24 18_56_13.jpg  \n",
            "  inflating: trainB/2012-12-24 19_12_02.jpg  \n",
            "  inflating: trainB/2012-12-25 19_10_17.jpg  \n",
            "  inflating: trainB/2012-12-25 21_07_26.jpg  \n",
            "  inflating: trainB/2012-12-25 23_05_14.jpg  \n",
            "  inflating: trainB/2012-12-26 00_20_55.jpg  \n",
            "  inflating: trainB/2012-12-27 01_36_03.jpg  \n",
            "  inflating: trainB/2012-12-27 17_31_45.jpg  \n",
            "  inflating: trainB/2012-12-27 20_01_14.jpg  \n",
            "  inflating: trainB/2012-12-28 03_56_16.jpg  \n",
            "  inflating: trainB/2012-12-28 21_04_55.jpg  \n",
            "  inflating: trainB/2012-12-28 22_38_45.jpg  \n",
            "  inflating: trainB/2012-12-29 08_20_28.jpg  \n",
            "  inflating: trainB/2012-12-29 09_38_33.jpg  \n",
            "  inflating: trainB/2012-12-29 11_04_54.jpg  \n",
            "  inflating: trainB/2012-12-29 13_12_27.jpg  \n",
            "  inflating: trainB/2012-12-29 18_50_04.jpg  \n",
            "  inflating: trainB/2012-12-30 09_02_17.jpg  \n",
            "  inflating: trainB/2012-12-30 09_31_49.jpg  \n",
            "  inflating: trainB/2012-12-30 15_43_03.jpg  \n",
            "  inflating: trainB/2012-12-31 17_02_44.jpg  \n",
            "  inflating: trainB/2012-12-31 18_58_19.jpg  \n",
            "  inflating: trainB/2012-12-31 20_39_48.jpg  \n",
            "  inflating: trainB/2013-01-01 11_32_27.jpg  \n",
            "  inflating: trainB/2013-01-01 16_58_02.jpg  \n",
            "  inflating: trainB/2013-01-01 20_16_12.jpg  \n",
            "  inflating: trainB/2013-01-02 01_58_38.jpg  \n",
            "  inflating: trainB/2013-01-02 15_23_19.jpg  \n",
            "  inflating: trainB/2013-01-04 13_20_32.jpg  \n",
            "  inflating: trainB/2013-01-05 08_49_59.jpg  \n",
            "  inflating: trainB/2013-01-06 09_20_34.jpg  \n",
            "  inflating: trainB/2013-01-06 10_44_09.jpg  \n",
            "  inflating: trainB/2013-01-07 05_55_45.jpg  \n",
            "  inflating: trainB/2013-01-08 10_40_35.jpg  \n",
            "  inflating: trainB/2013-01-10 02_44_37.jpg  \n",
            "  inflating: trainB/2013-01-10 14_25_07.jpg  \n",
            "  inflating: trainB/2013-01-12 16_35_06.jpg  \n",
            "  inflating: trainB/2013-01-13 11_31_35.jpg  \n",
            "  inflating: trainB/2013-01-14 08_33_43.jpg  \n",
            "  inflating: trainB/2013-01-14 09_23_44.jpg  \n",
            "  inflating: trainB/2013-01-14 12_08_57.jpg  \n",
            "  inflating: trainB/2013-01-14 18_06_53.jpg  \n",
            "  inflating: trainB/2013-01-14 18_37_13.jpg  \n",
            "  inflating: trainB/2013-01-14 21_55_52.jpg  \n",
            "  inflating: trainB/2013-01-16 11_46_39.jpg  \n",
            "  inflating: trainB/2013-01-18 08_14_04.jpg  \n",
            "  inflating: trainB/2013-01-20 14_46_57.jpg  \n",
            "  inflating: trainB/2013-01-22 19_54_48.jpg  \n",
            "  inflating: trainB/2013-01-25 15_12_52.jpg  \n",
            "  inflating: trainB/2013-01-25 15_21_02.jpg  \n",
            "  inflating: trainB/2013-01-26 12_12_13.jpg  \n",
            "  inflating: trainB/2013-01-26 16_26_49.jpg  \n",
            "  inflating: trainB/2013-01-27 11_46_15.jpg  \n",
            "  inflating: trainB/2013-01-27 15_14_57.jpg  \n",
            "  inflating: trainB/2013-01-27 15_17_04.jpg  \n",
            "  inflating: trainB/2013-01-27 15_35_53.jpg  \n",
            "  inflating: trainB/2013-01-27 17_15_44.jpg  \n",
            "  inflating: trainB/2013-01-27 18_03_08.jpg  \n",
            "  inflating: trainB/2013-01-29 18_31_32.jpg  \n",
            "  inflating: trainB/2013-01-30 09_15_46.jpg  \n",
            "  inflating: trainB/2013-01-30 22_03_09.jpg  \n",
            "  inflating: trainB/2013-01-31 07_10_19.jpg  \n",
            "  inflating: trainB/2013-02-02 06_36_13.jpg  \n",
            "  inflating: trainB/2013-02-06 11_43_48.jpg  \n",
            "  inflating: trainB/2013-02-07 12_07_15.jpg  \n",
            "  inflating: trainB/2013-02-10 20_44_58.jpg  \n",
            "  inflating: trainB/2013-02-11 01_27_39.jpg  \n",
            "  inflating: trainB/2013-02-13 13_41_45.jpg  \n",
            "  inflating: trainB/2013-02-17 00_05_03.jpg  \n",
            "  inflating: trainB/2013-02-20 23_26_59.jpg  \n",
            "  inflating: trainB/2013-02-22 14_02_04.jpg  \n",
            "  inflating: trainB/2013-02-24 09_23_47.jpg  \n",
            "  inflating: trainB/2013-02-24 15_06_24.jpg  \n",
            "  inflating: trainB/2013-02-24 23_08_09.jpg  \n",
            "  inflating: trainB/2013-02-25 22_22_08.jpg  \n",
            "  inflating: trainB/2013-02-27 11_07_29.jpg  \n",
            "  inflating: trainB/2013-02-27 15_19_23.jpg  \n",
            "  inflating: trainB/2013-02-28 21_42_46.jpg  \n",
            "  inflating: trainB/2013-03-02 13_38_23.jpg  \n",
            "  inflating: trainB/2013-03-02 14_33_27.jpg  \n",
            "  inflating: trainB/2013-03-03 13_10_55.jpg  \n",
            "  inflating: trainB/2013-03-07 20_49_39.jpg  \n",
            "  inflating: trainB/2013-03-08 02_15_17.jpg  \n",
            "  inflating: trainB/2013-03-08 16_26_17.jpg  \n",
            "  inflating: trainB/2013-03-10 20_04_17.jpg  \n",
            "  inflating: trainB/2013-03-11 12_18_04.jpg  \n",
            "  inflating: trainB/2013-03-12 07_35_16.jpg  \n",
            "  inflating: trainB/2013-03-13 09_32_45.jpg  \n",
            "  inflating: trainB/2013-03-13 15_05_49.jpg  \n",
            "  inflating: trainB/2013-03-18 19_55_07.jpg  \n",
            "  inflating: trainB/2013-03-21 17_02_55.jpg  \n",
            "  inflating: trainB/2013-03-23 21_49_38.jpg  \n",
            "  inflating: trainB/2013-04-03 14_59_44.jpg  \n",
            "  inflating: trainB/2013-05-06 14_01_26.jpg  \n",
            "  inflating: trainB/2013-05-06 21_43_28.jpg  \n",
            "  inflating: trainB/2013-05-10 09_33_33.jpg  \n",
            "  inflating: trainB/2013-05-13 20_58_17.jpg  \n",
            "  inflating: trainB/2013-05-22 03_31_55.jpg  \n",
            "  inflating: trainB/2013-05-28 15_25_53.jpg  \n",
            "  inflating: trainB/2013-06-03 01_16_59.jpg  \n",
            "  inflating: trainB/2013-06-25 15_07_57.jpg  \n",
            "  inflating: trainB/2013-07-05 15_54_12.jpg  \n",
            "  inflating: trainB/2013-07-11 13_20_23.jpg  \n",
            "  inflating: trainB/2013-07-15 22_59_48.jpg  \n",
            "  inflating: trainB/2013-08-29 21_39_03.jpg  \n",
            "  inflating: trainB/2013-09-06 17_59_12.jpg  \n",
            "  inflating: trainB/2013-10-10 12_30_36.jpg  \n",
            "  inflating: trainB/2013-10-11 12_51_28.jpg  \n",
            "  inflating: trainB/2013-10-15 17_02_32.jpg  \n",
            "  inflating: trainB/2013-11-12 05_58_54.jpg  \n",
            "  inflating: trainB/2013-11-14 19_57_33.jpg  \n",
            "  inflating: trainB/2013-11-23 11_09_19.jpg  \n",
            "  inflating: trainB/2013-11-29 14_57_14.jpg  \n",
            "  inflating: trainB/2013-12-01 11_03_29.jpg  \n",
            "  inflating: trainB/2013-12-03 08_41_38.jpg  \n",
            "  inflating: trainB/2013-12-03 11_49_54.jpg  \n",
            "  inflating: trainB/2013-12-04 20_45_24.jpg  \n",
            "  inflating: trainB/2013-12-05 01_22_12.jpg  \n",
            "  inflating: trainB/2013-12-07 16_54_52.jpg  \n",
            "  inflating: trainB/2013-12-08 00_17_39.jpg  \n",
            "  inflating: trainB/2013-12-08 13_28_08.jpg  \n",
            "  inflating: trainB/2013-12-08 16_29_15.jpg  \n",
            "  inflating: trainB/2013-12-09 12_08_26.jpg  \n",
            "  inflating: trainB/2013-12-10 11_51_19.jpg  \n",
            "  inflating: trainB/2013-12-11 00_15_43.jpg  \n",
            "  inflating: trainB/2013-12-11 12_55_27.jpg  \n",
            "  inflating: trainB/2013-12-13 09_24_54.jpg  \n",
            "  inflating: trainB/2013-12-14 08_13_46.jpg  \n",
            "  inflating: trainB/2013-12-15 16_33_12.jpg  \n",
            "  inflating: trainB/2013-12-16 12_18_16.jpg  \n",
            "  inflating: trainB/2013-12-17 03_33_45.jpg  \n",
            "  inflating: trainB/2013-12-17 21_37_45.jpg  \n",
            "  inflating: trainB/2013-12-18 14_15_48.jpg  \n",
            "  inflating: trainB/2013-12-18 18_40_33.jpg  \n",
            "  inflating: trainB/2013-12-19 20_19_02.jpg  \n",
            "  inflating: trainB/2013-12-21 02_17_37.jpg  \n",
            "  inflating: trainB/2013-12-23 13_32_58.jpg  \n",
            "  inflating: trainB/2013-12-23 18_52_12.jpg  \n",
            "  inflating: trainB/2013-12-23 20_34_17.jpg  \n",
            "  inflating: trainB/2013-12-23 22_47_39.jpg  \n",
            "  inflating: trainB/2013-12-24 03_44_16.jpg  \n",
            "  inflating: trainB/2013-12-24 09_42_43.jpg  \n",
            "  inflating: trainB/2013-12-24 14_03_55.jpg  \n",
            "  inflating: trainB/2013-12-24 23_59_56.jpg  \n",
            "  inflating: trainB/2013-12-25 16_45_56.jpg  \n",
            "  inflating: trainB/2013-12-25 17_26_15.jpg  \n",
            "  inflating: trainB/2013-12-26 08_50_38.jpg  \n",
            "  inflating: trainB/2013-12-26 23_17_26.jpg  \n",
            "  inflating: trainB/2013-12-27 18_29_47.jpg  \n",
            "  inflating: trainB/2013-12-28 18_04_16.jpg  \n",
            "  inflating: trainB/2013-12-29 05_16_45.jpg  \n",
            "  inflating: trainB/2013-12-29 13_30_39.jpg  \n",
            "  inflating: trainB/2013-12-29 16_51_55.jpg  \n",
            "  inflating: trainB/2013-12-30 08_43_43.jpg  \n",
            "  inflating: trainB/2013-12-30 12_27_23.jpg  \n",
            "  inflating: trainB/2013-12-30 14_18_53.jpg  \n",
            "  inflating: trainB/2013-12-30 16_58_49.jpg  \n",
            "  inflating: trainB/2013-12-30 17_56_07.jpg  \n",
            "  inflating: trainB/2014-01-01 11_35_57.jpg  \n",
            "  inflating: trainB/2014-01-01 16_56_25.jpg  \n",
            "  inflating: trainB/2014-01-02 15_02_46.jpg  \n",
            "  inflating: trainB/2014-01-03 18_37_08.jpg  \n",
            "  inflating: trainB/2014-01-04 12_56_39.jpg  \n",
            "  inflating: trainB/2014-01-05 04_46_26.jpg  \n",
            "  inflating: trainB/2014-01-05 19_20_13.jpg  \n",
            "  inflating: trainB/2014-01-06 13_24_24.jpg  \n",
            "  inflating: trainB/2014-01-06 21_26_48.jpg  \n",
            "  inflating: trainB/2014-01-06 21_46_17.jpg  \n",
            "  inflating: trainB/2014-01-06 22_36_57.jpg  \n",
            "  inflating: trainB/2014-01-07 15_20_58.jpg  \n",
            "  inflating: trainB/2014-01-09 12_22_15.jpg  \n",
            "  inflating: trainB/2014-01-09 17_05_34.jpg  \n",
            "  inflating: trainB/2014-01-09 18_18_37.jpg  \n",
            "  inflating: trainB/2014-01-10 19_18_22.jpg  \n",
            "  inflating: trainB/2014-01-11 14_32_27.jpg  \n",
            "  inflating: trainB/2014-01-11 16_27_47.jpg  \n",
            "  inflating: trainB/2014-01-12 17_29_04.jpg  \n",
            "  inflating: trainB/2014-01-12 18_01_57.jpg  \n",
            "  inflating: trainB/2014-01-14 18_17_26.jpg  \n",
            "  inflating: trainB/2014-01-16 11_03_38.jpg  \n",
            "  inflating: trainB/2014-01-16 11_38_23.jpg  \n",
            "  inflating: trainB/2014-01-18 12_22_19.jpg  \n",
            "  inflating: trainB/2014-01-18 17_52_52.jpg  \n",
            "  inflating: trainB/2014-01-20 21_21_02.jpg  \n",
            "  inflating: trainB/2014-01-24 00_18_52.jpg  \n",
            "  inflating: trainB/2014-01-24 10_11_46.jpg  \n",
            "  inflating: trainB/2014-01-25 18_15_36.jpg  \n",
            "  inflating: trainB/2014-01-26 16_41_59.jpg  \n",
            "  inflating: trainB/2014-01-26 23_36_58.jpg  \n",
            "  inflating: trainB/2014-01-30 19_00_28.jpg  \n",
            "  inflating: trainB/2014-01-31 01_59_08.jpg  \n",
            "  inflating: trainB/2014-01-31 02_02_09.jpg  \n",
            "  inflating: trainB/2014-01-31 09_54_59.jpg  \n",
            "  inflating: trainB/2014-01-31 11_59_28.jpg  \n",
            "  inflating: trainB/2014-02-02 01_53_24.jpg  \n",
            "  inflating: trainB/2014-02-05 14_41_09.jpg  \n",
            "  inflating: trainB/2014-02-11 12_41_24.jpg  \n",
            "  inflating: trainB/2014-02-12 14_47_42.jpg  \n",
            "  inflating: trainB/2014-02-13 17_42_34.jpg  \n",
            "  inflating: trainB/2014-02-14 11_13_54.jpg  \n",
            "  inflating: trainB/2014-02-17 14_42_59.jpg  \n",
            "  inflating: trainB/2014-02-17 21_04_38.jpg  \n",
            "  inflating: trainB/2014-02-18 07_04_37.jpg  \n",
            "  inflating: trainB/2014-02-18 20_32_23.jpg  \n",
            "  inflating: trainB/2014-02-18 21_24_07.jpg  \n",
            "  inflating: trainB/2014-02-22 18_19_36.jpg  \n",
            "  inflating: trainB/2014-02-23 19_52_22.jpg  \n",
            "  inflating: trainB/2014-02-23 20_36_18.jpg  \n",
            "  inflating: trainB/2014-02-23 22_43_14.jpg  \n",
            "  inflating: trainB/2014-02-25 00_58_35.jpg  \n",
            "  inflating: trainB/2014-02-27 15_55_13.jpg  \n",
            "  inflating: trainB/2014-03-07 10_28_12.jpg  \n",
            "  inflating: trainB/2014-03-12 15_29_09.jpg  \n",
            "  inflating: trainB/2014-03-15 16_54_44.jpg  \n",
            "  inflating: trainB/2014-03-18 23_45_33.jpg  \n",
            "  inflating: trainB/2014-03-26 08_19_02.jpg  \n",
            "  inflating: trainB/2014-04-03 14_03_53.jpg  \n",
            "  inflating: trainB/2014-04-10 17_30_05.jpg  \n",
            "  inflating: trainB/2014-04-11 18_23_27.jpg  \n",
            "  inflating: trainB/2014-04-14 21_01_38.jpg  \n",
            "  inflating: trainB/2014-04-17 18_55_17.jpg  \n",
            "  inflating: trainB/2014-04-20 17_47_15.jpg  \n",
            "  inflating: trainB/2014-04-22 12_45_16.jpg  \n",
            "  inflating: trainB/2014-04-30 14_56_37.jpg  \n",
            "  inflating: trainB/2014-05-03 05_18_03.jpg  \n",
            "  inflating: trainB/2014-05-18 22_36_16.jpg  \n",
            "  inflating: trainB/2014-05-28 19_31_45.jpg  \n",
            "  inflating: trainB/2014-05-30 09_18_06.jpg  \n",
            "  inflating: trainB/2014-06-10 12_07_53.jpg  \n",
            "  inflating: trainB/2014-06-18 22_01_16.jpg  \n",
            "  inflating: trainB/2014-07-07 16_21_42.jpg  \n",
            "  inflating: trainB/2014-07-13 08_04_38.jpg  \n",
            "  inflating: trainB/2014-07-16 17_57_19.jpg  \n",
            "  inflating: trainB/2014-07-18 21_27_23.jpg  \n",
            "  inflating: trainB/2014-07-22 10_53_06.jpg  \n",
            "  inflating: trainB/2014-08-04 16_44_48.jpg  \n",
            "  inflating: trainB/2014-08-27 19_51_26.jpg  \n",
            "  inflating: trainB/2014-08-29 15_05_27.jpg  \n",
            "  inflating: trainB/2014-09-07 23_47_34.jpg  \n",
            "  inflating: trainB/2014-09-13 02_25_26.jpg  \n",
            "  inflating: trainB/2014-09-24 11_27_39.jpg  \n",
            "  inflating: trainB/2014-10-22 17_01_16.jpg  \n",
            "  inflating: trainB/2014-10-29 21_03_59.jpg  \n",
            "  inflating: trainB/2014-11-04 18_33_23.jpg  \n",
            "  inflating: trainB/2014-11-17 06_49_53.jpg  \n",
            "  inflating: trainB/2014-11-17 19_55_25.jpg  \n",
            "  inflating: trainB/2014-11-26 20_20_32.jpg  \n",
            "  inflating: trainB/2014-11-30 07_44_06.jpg  \n",
            "  inflating: trainB/2014-12-08 23_10_35.jpg  \n",
            "  inflating: trainB/2014-12-20 17_05_32.jpg  \n",
            "  inflating: trainB/2014-12-21 16_17_03.jpg  \n",
            "  inflating: trainB/2014-12-22 18_02_33.jpg  \n",
            "  inflating: trainB/2014-12-24 08_11_48.jpg  \n",
            "  inflating: trainB/2014-12-27 23_32_24.jpg  \n",
            "  inflating: trainB/2014-12-30 23_51_36.jpg  \n",
            "  inflating: trainB/2014-12-31 11_38_42.jpg  \n",
            "  inflating: trainB/2014-12-31 16_53_04.jpg  \n",
            "  inflating: trainB/2015-01-02 16_38_48.jpg  \n",
            "  inflating: trainB/2015-01-03 22_28_56.jpg  \n",
            "  inflating: trainB/2015-01-09 10_00_06.jpg  \n",
            "  inflating: trainB/2015-01-11 13_27_27.jpg  \n",
            "  inflating: trainB/2015-01-13 23_56_37.jpg  \n",
            "  inflating: trainB/2015-01-25 06_13_28.jpg  \n",
            "  inflating: trainB/2015-01-25 13_20_28.jpg  \n",
            "  inflating: trainB/2015-02-12 08_22_12.jpg  \n",
            "  inflating: trainB/2015-02-18 00_02_04.jpg  \n",
            "  inflating: trainB/2015-03-04 21_41_18.jpg  \n",
            "  inflating: trainB/2015-03-10 21_48_27.jpg  \n",
            "  inflating: trainB/2015-03-13 15_03_58.jpg  \n",
            "  inflating: trainB/2015-03-15 12_44_39.jpg  \n",
            "  inflating: trainB/2015-03-17 14_30_12.jpg  \n",
            "  inflating: trainB/2015-03-30 19_01_08.jpg  \n",
            "  inflating: trainB/2015-04-09 07_49_25.jpg  \n",
            "  inflating: trainB/2015-04-18 16_49_24.jpg  \n",
            "  inflating: trainB/2015-04-19 11_46_47.jpg  \n",
            "  inflating: trainB/2015-04-26 08_54_07.jpg  \n",
            "  inflating: trainB/2015-05-28 11_58_57.jpg  \n",
            "  inflating: trainB/2015-06-23 20_22_16.jpg  \n",
            "  inflating: trainB/2015-07-05 15_04_07.jpg  \n",
            "  inflating: trainB/2015-08-05 14_25_34.jpg  \n",
            "  inflating: trainB/2015-08-11 22_24_48.jpg  \n",
            "  inflating: trainB/2015-08-21 12_04_14.jpg  \n",
            "  inflating: trainB/2015-10-20 16_32_59.jpg  \n",
            "  inflating: trainB/2015-11-07 17_11_13.jpg  \n",
            "  inflating: trainB/2015-11-15 21_03_17.jpg  \n",
            "  inflating: trainB/2015-11-18 20_22_09.jpg  \n",
            "  inflating: trainB/2015-11-21 21_00_23.jpg  \n",
            "  inflating: trainB/2015-11-25 18_10_15.jpg  \n",
            "  inflating: trainB/2015-11-28 08_50_36.jpg  \n",
            "  inflating: trainB/2015-11-28 13_45_58.jpg  \n",
            "  inflating: trainB/2015-11-29 03_48_37.jpg  \n",
            "  inflating: trainB/2015-11-29 08_50_22.jpg  \n",
            "  inflating: trainB/2015-11-29 16_03_22.jpg  \n",
            "  inflating: trainB/2015-11-29 18_00_49.jpg  \n",
            "  inflating: trainB/2015-11-29 23_48_16.jpg  \n",
            "  inflating: trainB/2015-11-30 07_50_42.jpg  \n",
            "  inflating: trainB/2015-11-30 16_48_38.jpg  \n",
            "  inflating: trainB/2015-11-30 21_45_35.jpg  \n",
            "  inflating: trainB/2015-11-30 21_59_34.jpg  \n",
            "  inflating: trainB/2015-12-07 19_12_18.jpg  \n",
            "  inflating: trainB/2015-12-12 18_59_35.jpg  \n",
            "  inflating: trainB/2015-12-13 23_46_59.jpg  \n",
            "  inflating: trainB/2015-12-14 08_58_08.jpg  \n",
            "  inflating: trainB/2015-12-15 16_57_58.jpg  \n",
            "  inflating: trainB/2015-12-15 17_49_19.jpg  \n",
            "  inflating: trainB/2015-12-16 00_47_47.jpg  \n",
            "  inflating: trainB/2015-12-16 14_22_35.jpg  \n",
            "  inflating: trainB/2015-12-16 23_01_09.jpg  \n",
            "  inflating: trainB/2015-12-17 00_06_06.jpg  \n",
            "  inflating: trainB/2015-12-17 20_44_37.jpg  \n",
            "  inflating: trainB/2015-12-19 11_48_57.jpg  \n",
            "  inflating: trainB/2015-12-20 21_55_16.jpg  \n",
            "  inflating: trainB/2015-12-21 05_22_47.jpg  \n",
            "  inflating: trainB/2015-12-21 07_52_16.jpg  \n",
            "  inflating: trainB/2015-12-24 05_49_26.jpg  \n",
            "  inflating: trainB/2015-12-24 05_50_23.jpg  \n",
            "  inflating: trainB/2015-12-25 15_48_39.jpg  \n",
            "  inflating: trainB/2015-12-25 23_31_32.jpg  \n",
            "  inflating: trainB/2015-12-27 22_03_08.jpg  \n",
            "  inflating: trainB/2015-12-28 10_04_02.jpg  \n",
            "  inflating: trainB/2015-12-28 14_14_08.jpg  \n",
            "  inflating: trainB/2015-12-28 22_36_42.jpg  \n",
            "  inflating: trainB/2015-12-29 09_17_29.jpg  \n",
            "  inflating: trainB/2015-12-29 20_03_15.jpg  \n",
            "  inflating: trainB/2015-12-30 16_46_15.jpg  \n",
            "  inflating: trainB/2015-12-30 22_13_45.jpg  \n",
            "  inflating: trainB/2015-12-31 11_21_16.jpg  \n",
            "  inflating: trainB/2015-12-31 21_59_06.jpg  \n",
            "  inflating: trainB/2015-12-31 23_29_24.jpg  \n",
            "  inflating: trainB/2016-01-01 10_04_47.jpg  \n",
            "  inflating: trainB/2016-01-01 11_05_14.jpg  \n",
            "  inflating: trainB/2016-01-01 15_10_44.jpg  \n",
            "  inflating: trainB/2016-01-01 17_34_26.jpg  \n",
            "  inflating: trainB/2016-01-02 10_02_43.jpg  \n",
            "  inflating: trainB/2016-01-02 17_41_03.jpg  \n",
            "  inflating: trainB/2016-01-02 17_44_57.jpg  \n",
            "  inflating: trainB/2016-01-02 18_34_07.jpg  \n",
            "  inflating: trainB/2016-01-02 20_02_35.jpg  \n",
            "  inflating: trainB/2016-01-02 20_41_44.jpg  \n",
            "  inflating: trainB/2016-01-02 23_55_27.jpg  \n",
            "  inflating: trainB/2016-01-03 10_14_13.jpg  \n",
            "  inflating: trainB/2016-01-03 19_24_52.jpg  \n",
            "  inflating: trainB/2016-01-03 21_23_32.jpg  \n",
            "  inflating: trainB/2016-01-03 21_25_29.jpg  \n",
            "  inflating: trainB/2016-01-04 00_30_14.jpg  \n",
            "  inflating: trainB/2016-01-04 05_43_14.jpg  \n",
            "  inflating: trainB/2016-01-04 11_56_07.jpg  \n",
            "  inflating: trainB/2016-01-04 20_19_13.jpg  \n",
            "  inflating: trainB/2016-01-04 22_12_14.jpg  \n",
            "  inflating: trainB/2016-01-05 16_10_28.jpg  \n",
            "  inflating: trainB/2016-01-05 20_55_38.jpg  \n",
            "  inflating: trainB/2016-01-06 08_18_54.jpg  \n",
            "  inflating: trainB/2016-01-06 17_58_44.jpg  \n",
            "  inflating: trainB/2016-01-06 22_47_08.jpg  \n",
            "  inflating: trainB/2016-01-06 23_56_49.jpg  \n",
            "  inflating: trainB/2016-01-07 03_23_22.jpg  \n",
            "  inflating: trainB/2016-01-07 13_26_46.jpg  \n",
            "  inflating: trainB/2016-01-07 22_21_43.jpg  \n",
            "  inflating: trainB/2016-01-08 12_38_15.jpg  \n",
            "  inflating: trainB/2016-01-09 22_24_57.jpg  \n",
            "  inflating: trainB/2016-01-11 11_14_14.jpg  \n",
            "  inflating: trainB/2016-01-11 11_32_08.jpg  \n",
            "  inflating: trainB/2016-01-11 21_31_39.jpg  \n",
            "  inflating: trainB/2016-01-12 09_34_33.jpg  \n",
            "  inflating: trainB/2016-01-12 22_10_37.jpg  \n",
            "  inflating: trainB/2016-01-12 23_55_04.jpg  \n",
            "  inflating: trainB/2016-01-15 12_03_33.jpg  \n",
            "  inflating: trainB/2016-01-16 21_04_17.jpg  \n",
            "  inflating: trainB/2016-01-17 00_42_47.jpg  \n",
            "  inflating: trainB/2016-01-17 11_23_02.jpg  \n",
            "  inflating: trainB/2016-01-17 11_50_13.jpg  \n",
            "  inflating: trainB/2016-01-18 16_49_12.jpg  \n",
            "  inflating: trainB/2016-01-18 16_59_49.jpg  \n",
            "  inflating: trainB/2016-01-19 14_55_18.jpg  \n",
            "  inflating: trainB/2016-01-19 21_21_59.jpg  \n",
            "  inflating: trainB/2016-01-19 22_40_27.jpg  \n",
            "  inflating: trainB/2016-01-20 00_19_17.jpg  \n",
            "  inflating: trainB/2016-01-20 08_46_44.jpg  \n",
            "  inflating: trainB/2016-01-20 23_07_06.jpg  \n",
            "  inflating: trainB/2016-01-21 10_05_04.jpg  \n",
            "  inflating: trainB/2016-01-23 10_56_23.jpg  \n",
            "  inflating: trainB/2016-01-23 12_03_22.jpg  \n",
            "  inflating: trainB/2016-01-24 12_40_23.jpg  \n",
            "  inflating: trainB/2016-01-25 22_43_46.jpg  \n",
            "  inflating: trainB/2016-01-26 21_15_33.jpg  \n",
            "  inflating: trainB/2016-01-26 21_39_53.jpg  \n",
            "  inflating: trainB/2016-01-26 21_56_43.jpg  \n",
            "  inflating: trainB/2016-01-27 18_40_23.jpg  \n",
            "  inflating: trainB/2016-01-28 07_07_48.jpg  \n",
            "  inflating: trainB/2016-01-28 16_08_15.jpg  \n",
            "  inflating: trainB/2016-01-28 19_01_47.jpg  \n",
            "  inflating: trainB/2016-01-29 02_53_44.jpg  \n",
            "  inflating: trainB/2016-01-30 14_01_12.jpg  \n",
            "  inflating: trainB/2016-02-02 10_21_46.jpg  \n",
            "  inflating: trainB/2016-02-03 17_20_26.jpg  \n",
            "  inflating: trainB/2016-02-04 14_56_03.jpg  \n",
            "  inflating: trainB/2016-02-05 12_04_06.jpg  \n",
            "  inflating: trainB/2016-02-05 16_11_18.jpg  \n",
            "  inflating: trainB/2016-02-05 17_35_37.jpg  \n",
            "  inflating: trainB/2016-02-06 16_37_12.jpg  \n",
            "  inflating: trainB/2016-02-06 19_54_15.jpg  \n",
            "  inflating: trainB/2016-02-06 23_32_28.jpg  \n",
            "  inflating: trainB/2016-02-07 21_19_55.jpg  \n",
            "  inflating: trainB/2016-02-09 11_22_15.jpg  \n",
            "  inflating: trainB/2016-02-10 10_18_27.jpg  \n",
            "  inflating: trainB/2016-02-10 20_36_25.jpg  \n",
            "  inflating: trainB/2016-02-13 19_17_25.jpg  \n",
            "  inflating: trainB/2016-02-15 16_35_44.jpg  \n",
            "  inflating: trainB/2016-02-17 22_53_19.jpg  \n",
            "  inflating: trainB/2016-02-18 11_16_07.jpg  \n",
            "  inflating: trainB/2016-02-18 18_25_06.jpg  \n",
            "  inflating: trainB/2016-02-19 09_14_03.jpg  \n",
            "  inflating: trainB/2016-02-20 14_54_19.jpg  \n",
            "  inflating: trainB/2016-02-21 13_33_34.jpg  \n",
            "  inflating: trainB/2016-02-22 12_24_27.jpg  \n",
            "  inflating: trainB/2016-02-22 14_22_55.jpg  \n",
            "  inflating: trainB/2016-02-22 21_55_38.jpg  \n",
            "  inflating: trainB/2016-02-24 20_55_29.jpg  \n",
            "  inflating: trainB/2016-02-25 08_21_05.jpg  \n",
            "  inflating: trainB/2016-02-25 22_17_37.jpg  \n",
            "  inflating: trainB/2016-02-27 00_35_04.jpg  \n",
            "  inflating: trainB/2016-02-27 07_39_07.jpg  \n",
            "  inflating: trainB/2016-02-27 14_12_47.jpg  \n",
            "  inflating: trainB/2016-02-28 13_57_03.jpg  \n",
            "  inflating: trainB/2016-02-28 16_45_02.jpg  \n",
            "  inflating: trainB/2016-03-03 21_09_28.jpg  \n",
            "  inflating: trainB/2016-03-05 14_40_26.jpg  \n",
            "  inflating: trainB/2016-03-05 22_29_46.jpg  \n",
            "  inflating: trainB/2016-03-07 20_57_45.jpg  \n",
            "  inflating: trainB/2016-03-12 09_07_43.jpg  \n",
            "  inflating: trainB/2016-03-22 16_19_04.jpg  \n",
            "  inflating: trainB/2016-03-23 18_04_35.jpg  \n",
            "  inflating: trainB/2016-03-24 00_14_35.jpg  \n",
            "  inflating: trainB/2016-03-24 11_32_35.jpg  \n",
            "  inflating: trainB/2016-03-31 08_44_48.jpg  \n",
            "  inflating: trainB/2016-04-01 00_20_22.jpg  \n",
            "  inflating: trainB/2016-04-03 13_44_26.jpg  \n",
            "  inflating: trainB/2016-04-03 13_54_34.jpg  \n",
            "  inflating: trainB/2016-04-06 11_11_37.jpg  \n",
            "  inflating: trainB/2016-04-08 18_26_12.jpg  \n",
            "  inflating: trainB/2016-04-08 18_56_09.jpg  \n",
            "  inflating: trainB/2016-04-10 11_42_57.jpg  \n",
            "  inflating: trainB/2016-04-18 17_51_14.jpg  \n",
            "  inflating: trainB/2016-04-21 02_35_03.jpg  \n",
            "  inflating: trainB/2016-04-21 22_34_14.jpg  \n",
            "  inflating: trainB/2016-04-26 19_36_34.jpg  \n",
            "  inflating: trainB/2016-05-05 09_36_26.jpg  \n",
            "  inflating: trainB/2016-05-05 19_39_08.jpg  \n",
            "  inflating: trainB/2016-05-06 02_43_09.jpg  \n",
            "  inflating: trainB/2016-05-06 17_42_46.jpg  \n",
            "  inflating: trainB/2016-05-09 15_31_29.jpg  \n",
            "  inflating: trainB/2016-05-12 05_33_38.jpg  \n",
            "  inflating: trainB/2016-05-24 03_36_53.jpg  \n",
            "  inflating: trainB/2016-05-24 21_31_13.jpg  \n",
            "  inflating: trainB/2016-05-26 13_02_54.jpg  \n",
            "  inflating: trainB/2016-05-27 02_32_38.jpg  \n",
            "  inflating: trainB/2016-05-30 13_17_15.jpg  \n",
            "  inflating: trainB/2016-06-01 12_17_42.jpg  \n",
            "  inflating: trainB/2016-06-03 03_10_42.jpg  \n",
            "  inflating: trainB/2016-06-10 01_20_48.jpg  \n",
            "  inflating: trainB/2016-06-14 16_55_04.jpg  \n",
            "  inflating: trainB/2016-06-16 11_28_12.jpg  \n",
            "  inflating: trainB/2016-06-16 22_55_47.jpg  \n",
            "  inflating: trainB/2016-06-20 20_50_49.jpg  \n",
            "  inflating: trainB/2016-07-01 23_15_22.jpg  \n",
            "  inflating: trainB/2016-08-14 11_22_36.jpg  \n",
            "  inflating: trainB/2016-09-13 14_13_54.jpg  \n",
            "  inflating: trainB/2016-09-24 14_35_49.jpg  \n",
            "  inflating: trainB/2016-09-30 20_39_52.jpg  \n",
            "  inflating: trainB/2016-10-20 17_53_39.jpg  \n",
            "  inflating: trainB/2016-10-23 12_53_19.jpg  \n",
            "  inflating: trainB/2016-10-26 08_34_48.jpg  \n",
            "  inflating: trainB/2016-11-17 18_42_25.jpg  \n",
            "  inflating: trainB/2016-11-17 20_13_55.jpg  \n",
            "  inflating: trainB/2016-11-28 21_24_13.jpg  \n",
            "  inflating: trainB/2016-11-29 19_28_18.jpg  \n",
            "  inflating: trainB/2016-11-29 21_07_09.jpg  \n",
            "  inflating: trainB/2016-12-02 03_25_34.jpg  \n",
            "  inflating: trainB/2016-12-03 11_40_18.jpg  \n",
            "  inflating: trainB/2016-12-03 13_37_47.jpg  \n",
            "  inflating: trainB/2016-12-03 13_50_34.jpg  \n",
            "  inflating: trainB/2016-12-04 09_30_55.jpg  \n",
            "  inflating: trainB/2016-12-06 12_53_38.jpg  \n",
            "  inflating: trainB/2016-12-07 10_12_49.jpg  \n",
            "  inflating: trainB/2016-12-09 11_01_49.jpg  \n",
            "  inflating: trainB/2016-12-09 11_04_14.jpg  \n",
            "  inflating: trainB/2016-12-10 20_45_43.jpg  \n",
            "  inflating: trainB/2016-12-13 01_18_32.jpg  \n",
            "  inflating: trainB/2016-12-14 14_56_14.jpg  \n",
            "  inflating: trainB/2016-12-14 19_51_47.jpg  \n",
            "  inflating: trainB/2016-12-16 16_36_28.jpg  \n",
            "  inflating: trainB/2016-12-16 19_27_33.jpg  \n",
            "  inflating: trainB/2016-12-17 21_57_09.jpg  \n",
            "  inflating: trainB/2016-12-19 12_32_09.jpg  \n",
            "  inflating: trainB/2016-12-19 19_14_29.jpg  \n",
            "  inflating: trainB/2016-12-21 10_50_02.jpg  \n",
            "  inflating: trainB/2016-12-21 18_45_36.jpg  \n",
            "  inflating: trainB/2016-12-21 21_55_54.jpg  \n",
            "  inflating: trainB/2016-12-22 00_07_53.jpg  \n",
            "  inflating: trainB/2016-12-22 01_50_13.jpg  \n",
            "  inflating: trainB/2016-12-22 05_50_28.jpg  \n",
            "  inflating: trainB/2016-12-22 12_10_24.jpg  \n",
            "  inflating: trainB/2016-12-22 14_02_03.jpg  \n",
            "  inflating: trainB/2016-12-22 14_58_05.jpg  \n",
            "  inflating: trainB/2016-12-22 19_30_42.jpg  \n",
            "  inflating: trainB/2016-12-22 19_34_06.jpg  \n",
            "  inflating: trainB/2016-12-23 01_48_12.jpg  \n",
            "  inflating: trainB/2016-12-24 08_04_04.jpg  \n",
            "  inflating: trainB/2016-12-24 09_13_02.jpg  \n",
            "  inflating: trainB/2016-12-24 12_28_47.jpg  \n",
            "  inflating: trainB/2016-12-24 12_28_54.jpg  \n",
            "  inflating: trainB/2016-12-24 12_33_52.jpg  \n",
            "  inflating: trainB/2016-12-24 13_52_12.jpg  \n",
            "  inflating: trainB/2016-12-25 12_45_45.jpg  \n",
            "  inflating: trainB/2016-12-25 15_15_22.jpg  \n",
            "  inflating: trainB/2016-12-26 03_09_25.jpg  \n",
            "  inflating: trainB/2016-12-26 13_54_59.jpg  \n",
            "  inflating: trainB/2016-12-27 01_10_14.jpg  \n",
            "  inflating: trainB/2016-12-28 08_34_33.jpg  \n",
            "  inflating: trainB/2016-12-28 14_59_16.jpg  \n",
            "  inflating: trainB/2016-12-29 09_48_46.jpg  \n",
            "  inflating: trainB/2016-12-29 10_08_54.jpg  \n",
            "  inflating: trainB/2016-12-29 13_53_19.jpg  \n",
            "  inflating: trainB/2016-12-29 17_49_42.jpg  \n",
            "  inflating: trainB/2016-12-29 19_25_39.jpg  \n",
            "  inflating: trainB/2016-12-30 19_41_27.jpg  \n",
            "  inflating: trainB/2016-12-31 11_56_53.jpg  \n",
            "  inflating: trainB/2017-01-02 09_53_34.jpg  \n",
            "  inflating: trainB/2017-01-02 23_38_06.jpg  \n",
            "  inflating: trainB/2017-01-04 11_36_37.jpg  \n",
            "  inflating: trainB/2017-01-06 16_01_45.jpg  \n",
            "  inflating: trainB/2017-01-07 12_43_36.jpg  \n",
            "  inflating: trainB/2017-01-08 07_51_49.jpg  \n",
            "  inflating: trainB/2017-01-09 22_07_39.jpg  \n",
            "  inflating: trainB/2017-01-11 18_12_32.jpg  \n",
            "  inflating: trainB/2017-01-12 14_34_17.jpg  \n",
            "  inflating: trainB/2017-01-13 16_58_24.jpg  \n",
            "  inflating: trainB/2017-01-14 00_09_27.jpg  \n",
            "  inflating: trainB/2017-01-14 11_14_02.jpg  \n",
            "  inflating: trainB/2017-01-15 07_38_38.jpg  \n",
            "  inflating: trainB/2017-01-15 08_11_16.jpg  \n",
            "  inflating: trainB/2017-01-15 15_11_14.jpg  \n",
            "  inflating: trainB/2017-01-16 18_10_56.jpg  \n",
            "  inflating: trainB/2017-01-16 22_12_55.jpg  \n",
            "  inflating: trainB/2017-01-17 01_21_55.jpg  \n",
            "  inflating: trainB/2017-01-17 11_35_12.jpg  \n",
            "  inflating: trainB/2017-01-17 18_17_03.jpg  \n",
            "  inflating: trainB/2017-01-17 19_29_17.jpg  \n",
            "  inflating: trainB/2017-01-17 21_09_26.jpg  \n",
            "  inflating: trainB/2017-01-21 03_32_25.jpg  \n",
            "  inflating: trainB/2017-01-21 11_02_16.jpg  \n",
            "  inflating: trainB/2017-01-21 16_26_32.jpg  \n",
            "  inflating: trainB/2017-01-22 21_54_44.jpg  \n",
            "  inflating: trainB/2017-01-23 08_27_54.jpg  \n",
            "  inflating: trainB/2017-01-23 14_47_42.jpg  \n",
            "  inflating: trainB/2017-01-23 16_32_55.jpg  \n",
            "  inflating: trainB/2017-01-23 22_24_05.jpg  \n",
            "  inflating: trainB/2017-01-25 08_12_58.jpg  \n",
            "  inflating: trainB/2017-01-25 20_33_17.jpg  \n",
            "  inflating: trainB/2017-01-27 11_34_49.jpg  \n",
            "  inflating: trainB/2017-01-27 11_57_12.jpg  \n",
            "  inflating: trainB/2017-01-27 18_22_17.jpg  \n",
            "  inflating: trainB/2017-01-28 07_54_35.jpg  \n",
            "  inflating: trainB/2017-01-28 14_46_59.jpg  \n",
            "  inflating: trainB/2017-01-29 15_17_32.jpg  \n",
            "  inflating: trainB/2017-01-31 23_14_57.jpg  \n",
            "  inflating: trainB/2017-02-05 14_29_35.jpg  \n",
            "  inflating: trainB/2017-02-07 10_24_47.jpg  \n",
            "  inflating: trainB/2017-02-10 09_04_19.jpg  \n",
            "  inflating: trainB/2017-02-12 13_12_37.jpg  \n",
            "  inflating: trainB/2017-02-14 23_44_06.jpg  \n",
            "  inflating: trainB/2017-02-16 08_21_05.jpg  \n",
            "  inflating: trainB/2017-02-16 19_33_13.jpg  \n",
            "  inflating: trainB/2017-02-20 18_46_26.jpg  \n",
            "  inflating: trainB/2017-02-21 07_08_06.jpg  \n",
            "  inflating: trainB/2017-02-22 11_15_02.jpg  \n",
            "  inflating: trainB/2017-02-22 21_39_39.jpg  \n",
            "  inflating: trainB/2017-02-24 14_58_22.jpg  \n",
            "  inflating: trainB/2017-03-05 11_48_18.jpg  \n",
            "  inflating: trainB/2017-03-06 00_53_07.jpg  \n",
            "  inflating: trainB/2017-03-08 05_53_02.jpg  \n",
            "  inflating: trainB/2017-03-10 13_34_14.jpg  \n",
            "  inflating: trainB/2017-03-13 10_43_32.jpg  \n",
            "  inflating: trainB/2017-03-13 20_42_48.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Transformation"
      ],
      "metadata": {
        "id": "f2dmc5KciQGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are defining a data augmentation pipeline using transforms.Compose(). The pipeline resizes the input image to (params.input_size, params.input_size), converts it to a tensor, and normalizes the pixel values to have a mean of (0.5, 0.5, 0.5) and a standard deviation of (0.5, 0.5, 0.5). "
      ],
      "metadata": {
        "id": "BZ8OGte0ZeTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((params.input_size,params.input_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "AA0d9JL-amXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Auxiliary Classes"
      ],
      "metadata": {
        "id": "Kfuw98WkiSL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetFromFolder(data.Dataset):\n",
        "    \"\"\"\n",
        "    A PyTorch dataset class for loading image data from a folder.\n",
        "\n",
        "    Args:\n",
        "        image_dir (str): Path to the folder containing image files.\n",
        "        subfolder (str, optional): Name of the subfolder within image_dir to use. Default is 'train'.\n",
        "        transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed version.\n",
        "        resize_scale (int, optional): Size to resize the image to. Default is None (no resizing).\n",
        "        crop_size (int, optional): Size to crop the image to. Default is None (no cropping).\n",
        "        fliplr (bool, optional): Whether or not to randomly flip the image horizontally. Default is False (no flipping).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, image_dir, subfolder='train', transform=None, resize_scale=None, crop_size=None, fliplr=False):\n",
        "        \"\"\"\n",
        "        Initialize the dataset.\n",
        "\n",
        "        Args:\n",
        "            image_dir (str): Path to the folder containing image files.\n",
        "            subfolder (str, optional): Name of the subfolder within image_dir to use. Default is 'train'.\n",
        "            transform (callable, optional): A function/transform that takes in a PIL image and returns a transformed version.\n",
        "            resize_scale (int, optional): Size to resize the image to. Default is None (no resizing).\n",
        "            crop_size (int, optional): Size to crop the image to. Default is None (no cropping).\n",
        "            fliplr (bool, optional): Whether or not to randomly flip the image horizontally. Default is False (no flipping).\n",
        "        \"\"\"\n",
        "\n",
        "        super(DatasetFromFolder, self).__init__()\n",
        "        self.input_path = os.path.join(image_dir, subfolder)\n",
        "        self.image_filenames = [x for x in sorted(os.listdir(self.input_path))]\n",
        "        self.transform = transform\n",
        "        \n",
        "        self.resize_scale = resize_scale\n",
        "        self.crop_size = crop_size\n",
        "        self.fliplr = fliplr\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Load and preprocess an image from the dataset.\n",
        "\n",
        "        Args:\n",
        "            index (int): Index of the image to load.\n",
        "\n",
        "        Returns:\n",
        "            img (PIL Image): The loaded and preprocessed image.\n",
        "        \"\"\"\n",
        "\n",
        "        # Load Image\n",
        "        img_fn = os.path.join(self.input_path, self.image_filenames[index])\n",
        "        img = Image.open(img_fn).convert('RGB')\n",
        "\n",
        "        # preprocessing\n",
        "        if self.resize_scale:\n",
        "            img = img.resize((self.resize_scale, self.resize_scale), Image.BILINEAR)\n",
        "\n",
        "        if self.crop_size:\n",
        "            x = random.randint(0, self.resize_scale - self.crop_size + 1)\n",
        "            y = random.randint(0, self.resize_scale - self.crop_size + 1)\n",
        "            img = img.crop((x, y, x + self.crop_size, y + self.crop_size))\n",
        "        if self.fliplr:\n",
        "            if random.random() < 0.5:\n",
        "                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Get the length of the dataset.\n",
        "\n",
        "        Returns:\n",
        "            length (int): The number of images in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.image_filenames)"
      ],
      "metadata": {
        "id": "m66VOOVUamyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We initialize two DatasetFromFolder objects train_data_A and train_data_B which read the image files from the directories trainA and trainB respectively. The images are then preprocessed using the transform pipeline defined earlier, with additional options for resizing, cropping and horizontal flipping. The resulting preprocessed images are then loaded into DataLoader objects train_data_loader_A and train_data_loader_B respectively, which will be used for iterating over the training data during the training process. The batch_size parameter determines how many images are loaded into memory at once, and the shuffle parameter shuffles the order of the images to ensure the model sees a different order of images during each epoch of training."
      ],
      "metadata": {
        "id": "AFCEB2erZ27U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_A = DatasetFromFolder(data_dir, subfolder='trainA', transform=transform,\n",
        "                                resize_scale=params.resize_scale, crop_size=params.crop_size, fliplr=params.fliplr)\n",
        "\n",
        "train_data_loader_A = torch.utils.data.DataLoader(dataset=train_data_A, batch_size=params.batch_size, shuffle=True)\n",
        "\n",
        "train_data_B = DatasetFromFolder(data_dir, subfolder='trainB', transform=transform,\n",
        "                                resize_scale=params.resize_scale, crop_size=params.crop_size, fliplr=params.fliplr)\n",
        "\n",
        "train_data_loader_B = torch.utils.data.DataLoader(dataset=train_data_B, batch_size=params.batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "cLjeM3Dsam1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define the data loaders for the test dataset, test_data_A_loader and test_data_B_loader, which are used to load images for testing the trained model. The specific test images, test_real_A_data and test_real_B_data, are obtained by calling the __getitem__ method on the train data loaders for train_data_A and train_data_B respectively, and then unsqueezing them to create 4D tensors."
      ],
      "metadata": {
        "id": "7cnW0QbzaKlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_A = DatasetFromFolder(data_dir, subfolder='testA', transform=transform)\n",
        "\n",
        "test_data_loader_A = torch.utils.data.DataLoader(dataset=test_data_A, batch_size=params.batch_size, shuffle=False)\n",
        "\n",
        "test_data_B = DatasetFromFolder(data_dir, subfolder='testB', transform=transform)\n",
        "\n",
        "test_data_loader_B = torch.utils.data.DataLoader(dataset=test_data_B, batch_size=params.batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "# Get specific test images\n",
        "test_real_A_data = train_data_A.__getitem__(11).unsqueeze(0) # Convert to 4d tensor (BxNxHxW)\n",
        "test_real_B_data = train_data_B.__getitem__(91).unsqueeze(0)\n",
        "print(test_real_A_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-myhhBJcEAe",
        "outputId": "7e142fa4-3c27-4726-d2e8-cffeaf780b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.4431, -0.4431, -0.4431,  ..., -0.3882, -0.3804, -0.3804],\n",
            "          [-0.3725, -0.4353, -0.4431,  ..., -0.3882, -0.3804, -0.3804],\n",
            "          [-0.3490, -0.3490, -0.3098,  ..., -0.3804, -0.3804, -0.3804],\n",
            "          ...,\n",
            "          [-0.3020, -0.3020, -0.3176,  ..., -0.2627, -0.0824, -0.0588],\n",
            "          [-0.2863, -0.2706, -0.2784,  ..., -0.4902, -0.1608, -0.0902],\n",
            "          [-0.3176, -0.2627, -0.2941,  ..., -0.3725, -0.1216, -0.1294]],\n",
            "\n",
            "         [[-0.3961, -0.3961, -0.4039,  ..., -0.1294, -0.1216, -0.1216],\n",
            "          [-0.3412, -0.3882, -0.4118,  ..., -0.1294, -0.1216, -0.1216],\n",
            "          [-0.3412, -0.3412, -0.3098,  ..., -0.1216, -0.1216, -0.1216],\n",
            "          ...,\n",
            "          [-0.2314, -0.2314, -0.2549,  ..., -0.2235, -0.0588, -0.0431],\n",
            "          [-0.1922, -0.1765, -0.1765,  ..., -0.4510, -0.1765, -0.0510],\n",
            "          [-0.2235, -0.1686, -0.1922,  ..., -0.3098, -0.0902, -0.0980]],\n",
            "\n",
            "         [[-0.3882, -0.4118, -0.4353,  ...,  0.2706,  0.2784,  0.2784],\n",
            "          [-0.3176, -0.3804, -0.4196,  ...,  0.2706,  0.2784,  0.2784],\n",
            "          [-0.2941, -0.3020, -0.2941,  ...,  0.2784,  0.2784,  0.2784],\n",
            "          ...,\n",
            "          [-0.6314, -0.6549, -0.6392,  ..., -0.6627, -0.7098, -0.6471],\n",
            "          [-0.6000, -0.6157, -0.5686,  ..., -0.6000, -0.6863, -0.6471],\n",
            "          [-0.6078, -0.5843, -0.6000,  ..., -0.7255, -0.6157, -0.6392]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Model"
      ],
      "metadata": {
        "id": "4zkpcmUDiY4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A convolutional block that consists of a convolutional layer and an optional batch normalization layer\n",
        "    followed by an activation function.\n",
        "\n",
        "    Args:\n",
        "        input_size (int): The number of input channels.\n",
        "        output_size (int): The number of output channels.\n",
        "        kernel_size (int, optional): The size of the kernel. Default is 3.\n",
        "        stride (int, optional): The stride of the convolution. Default is 2.\n",
        "        padding (int, optional): The padding added to the input. Default is 1.\n",
        "        activation (str, optional): The activation function to be applied. Can be 'relu', 'lrelu', 'tanh', or 'no_act'.\n",
        "            Default is 'relu'.\n",
        "        batch_norm (bool, optional): Whether to apply batch normalization. Default is True.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_size, kernel_size=3, stride=2, padding=1, activation='relu', batch_norm=True):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = torch.nn.Conv2d(input_size, output_size, kernel_size, stride, padding)\n",
        "        self.batch_norm = batch_norm\n",
        "        self.bn = torch.nn.InstanceNorm2d(output_size)\n",
        "        self.activation = activation\n",
        "        self.relu = torch.nn.ReLU(True)\n",
        "        self.lrelu = torch.nn.LeakyReLU(0.2, True)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Applies the convolutional block to the input.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): The input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The output tensor after applying the convolutional block.\n",
        "        \"\"\"\n",
        "        if self.batch_norm:\n",
        "            out = self.bn(self.conv(x))\n",
        "        else:\n",
        "            out = self.conv(x)\n",
        "\n",
        "        if self.activation == 'relu':\n",
        "            return self.relu(out)\n",
        "        elif self.activation == 'lrelu':\n",
        "            return self.lrelu(out)\n",
        "        elif self.activation == 'tanh':\n",
        "            return self.tanh(out)\n",
        "        elif self.activation == 'no_act':\n",
        "            return out\n",
        "\n",
        "\n",
        "class DeconvBlock(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A deconvolutional block that consists of a deconvolutional layer and an optional batch normalization layer\n",
        "    followed by an activation function.\n",
        "\n",
        "    Args:\n",
        "        input_size (int): The number of input channels.\n",
        "        output_size (int): The number of output channels.\n",
        "        kernel_size (int, optional): The size of the kernel. Default is 3.\n",
        "        stride (int, optional): The stride of the deconvolution. Default is 2.\n",
        "        padding (int, optional): The padding added to the input. Default is 1.\n",
        "        output_padding (int, optional): The additional size added to one side of the output shape. Default is 1.\n",
        "        activation (str, optional): The activation function to be applied. Default is 'relu'.\n",
        "        batch_norm (bool, optional): Whether to apply batch normalization. Default is True.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_size, kernel_size=3, stride=2, padding=1, output_padding=1, activation='relu', batch_norm=True):\n",
        "        super(DeconvBlock, self).__init__()\n",
        "        self.deconv = torch.nn.ConvTranspose2d(input_size, output_size, kernel_size, stride, padding, output_padding)\n",
        "        self.batch_norm = batch_norm\n",
        "        self.bn = torch.nn.InstanceNorm2d(output_size)\n",
        "        self.activation = activation\n",
        "        self.relu = torch.nn.ReLU(True)\n",
        "\n",
        "    def forward(self, x):\n",
        "    \"\"\"\n",
        "    Performs a forward pass of the DeconvBlock.\n",
        "\n",
        "    Args:\n",
        "        x (torch.Tensor): The input tensor.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The output tensor.\n",
        "    \"\"\"\n",
        "        if self.batch_norm:\n",
        "            out = self.bn(self.deconv(x))\n",
        "        else:\n",
        "            out = self.deconv(x)\n",
        "\n",
        "        if self.activation == 'relu':\n",
        "            return self.relu(out)\n",
        "        elif self.activation == 'lrelu':\n",
        "            return self.lrelu(out)\n",
        "        elif self.activation == 'tanh':\n",
        "            return self.tanh(out)\n",
        "        elif self.activation == 'no_act':\n",
        "            return out\n",
        "\n",
        "\n",
        "class ResnetBlock(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A residual block that consists of two convolutional layers, each followed by batch normalization and ReLU activation,\n",
        "    and an additional reflection padding layer. It adds the input tensor to the output tensor of the block to create a\n",
        "    residual connection.\n",
        "    \n",
        "    Args:\n",
        "        num_filter (int): The number of filters in the convolutional layers.\n",
        "        kernel_size (int, optional): The size of the kernel in the convolutional layers. Default is 3.\n",
        "        stride (int, optional): The stride of the convolutional layers. Default is 1.\n",
        "        padding (int, optional): The padding added to the input by the reflection padding layer. Default is 0.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_filter, kernel_size=3, stride=1, padding=0):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        conv1 = torch.nn.Conv2d(num_filter, num_filter, kernel_size, stride, padding)\n",
        "        conv2 = torch.nn.Conv2d(num_filter, num_filter, kernel_size, stride, padding)\n",
        "        bn = torch.nn.InstanceNorm2d(num_filter)\n",
        "        relu = torch.nn.ReLU(True)\n",
        "        pad = torch.nn.ReflectionPad2d(1)\n",
        "\n",
        "        self.resnet_block = torch.nn.Sequential(\n",
        "            pad,\n",
        "            conv1,\n",
        "            bn,\n",
        "            relu,\n",
        "            pad,\n",
        "            conv2,\n",
        "            bn\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Apply forward pass of the residual block on the input tensor x and return the output tensor.\n",
        "        \n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, num_filter, height, width).\n",
        "        \n",
        "        Returns:\n",
        "            out (torch.Tensor): Output tensor of shape (batch_size, num_filter, height, width).\n",
        "        \"\"\"\n",
        "        out = self.resnet_block(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Generator(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A generator neural network model for image-to-image translation tasks.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): The number of channels in the input image.\n",
        "        num_filter (int): The number of filters in the first convolutional layer of the encoder.\n",
        "        output_dim (int): The number of channels in the output image.\n",
        "        num_resnet (int): The number of residual blocks in the generator.\n",
        "\n",
        "    Attributes:\n",
        "        pad (torch.nn.ReflectionPad2d): The reflection padding layer.\n",
        "        conv1 (ConvBlock): The first convolutional block of the encoder.\n",
        "        conv2 (ConvBlock): The second convolutional block of the encoder.\n",
        "        conv3 (ConvBlock): The third convolutional block of the encoder.\n",
        "        resnet_blocks (torch.nn.Sequential): The sequence of residual blocks in the generator.\n",
        "        deconv1 (DeconvBlock): The first deconvolutional block of the decoder.\n",
        "        deconv2 (DeconvBlock): The second deconvolutional block of the decoder.\n",
        "        deconv3 (ConvBlock): The third convolutional block of the decoder.\n",
        "\n",
        "    Methods:\n",
        "        forward(x): Performs a forward pass through the generator.\n",
        "        normal_weight_init(mean, std): Initializes the weights of the generator with normally distributed random values.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, num_filter, output_dim, num_resnet):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Reflection padding\n",
        "        self.pad = torch.nn.ReflectionPad2d(3)\n",
        "        # Encoder\n",
        "        self.conv1 = ConvBlock(input_dim, num_filter, kernel_size=7, stride=1, padding=0)\n",
        "        self.conv2 = ConvBlock(num_filter, num_filter * 2)\n",
        "        self.conv3 = ConvBlock(num_filter * 2, num_filter * 4)\n",
        "        # Resnet blocks\n",
        "        self.resnet_blocks = []\n",
        "        for i in range(num_resnet):\n",
        "            self.resnet_blocks.append(ResnetBlock(num_filter * 4))\n",
        "        self.resnet_blocks = torch.nn.Sequential(*self.resnet_blocks)\n",
        "        # Decoder\n",
        "        self.deconv1 = DeconvBlock(num_filter * 4, num_filter * 2)\n",
        "        self.deconv2 = DeconvBlock(num_filter * 2, num_filter)\n",
        "        self.deconv3 = ConvBlock(num_filter, output_dim, kernel_size=7, stride=1, padding=0, activation='tanh', batch_norm=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Performs a forward pass through the generator.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): The input image tensor.\n",
        "\n",
        "        Returns:\n",
        "            The output image tensor generated by the generator.\n",
        "        \"\"\"\n",
        "        # Encoder\n",
        "        enc1 = self.conv1(self.pad(x))\n",
        "        enc2 = self.conv2(enc1)\n",
        "        enc3 = self.conv3(enc2)\n",
        "        # Resnet blocks\n",
        "        res = self.resnet_blocks(enc3)\n",
        "        # Decoder\n",
        "        dec1 = self.deconv1(res)\n",
        "        dec2 = self.deconv2(dec1)\n",
        "        out = self.deconv3(self.pad(dec2))\n",
        "        return out\n",
        "\n",
        "    def normal_weight_init(self, mean=0.0, std=0.02):\n",
        "        \"\"\"\n",
        "        Initializes the weights of the generator with normally distributed random values.\n",
        "\n",
        "        Args:\n",
        "            mean (float): The mean of the normal distribution.\n",
        "            std (float): The standard deviation of the normal distribution.\n",
        "        \"\"\"\n",
        "        for m in self.children():\n",
        "            if isinstance(m, ConvBlock):\n",
        "                torch.nn.init.normal(m.conv.weight, mean, std)\n",
        "            if isinstance(m, DeconvBlock):\n",
        "                torch.nn.init.normal(m.deconv.weight, mean, std)\n",
        "            if isinstance(m, ResnetBlock):\n",
        "                torch.nn.init.normal(m.conv.weight, mean, std)\n",
        "                torch.nn.init.constant(m.conv.bias, 0)\n",
        "\n",
        "\n",
        "class Discriminator(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A convolutional neural network that is used as a discriminator in a Generative Adversarial Network (GAN).\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): the number of input channels for the first convolutional layer.\n",
        "        num_filter (int): the number of filters in the first convolutional layer.\n",
        "        output_dim (int): the number of output channels for the last convolutional layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, num_filter, output_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        conv1 = ConvBlock(input_dim, num_filter, kernel_size=4, stride=2, padding=1, activation='lrelu', batch_norm=False)\n",
        "        conv2 = ConvBlock(num_filter, num_filter * 2, kernel_size=4, stride=2, padding=1, activation='lrelu')\n",
        "        conv3 = ConvBlock(num_filter * 2, num_filter * 4, kernel_size=4, stride=2, padding=1, activation='lrelu')\n",
        "        conv4 = ConvBlock(num_filter * 4, num_filter * 8, kernel_size=4, stride=1, padding=1, activation='lrelu')\n",
        "        conv5 = ConvBlock(num_filter * 8, output_dim, kernel_size=4, stride=1, padding=1, activation='no_act', batch_norm=False)\n",
        "\n",
        "        self.conv_blocks = torch.nn.Sequential(\n",
        "            conv1,\n",
        "            conv2,\n",
        "            conv3,\n",
        "            conv4,\n",
        "            conv5\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Feeds the input tensor through the discriminator network.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): the input tensor.\n",
        "\n",
        "        Returns:\n",
        "            The output tensor after it has passed through the discriminator network.\n",
        "        \"\"\"\n",
        "        out = self.conv_blocks(x)\n",
        "        return out\n",
        "\n",
        "    def normal_weight_init(self, mean=0.0, std=0.02):\n",
        "        \"\"\"\n",
        "        Initializes the weights of the convolutional layers using a normal distribution with the given mean and standard deviation.\n",
        "\n",
        "        Args:\n",
        "            mean (float): the mean of the normal distribution (default=0.0).\n",
        "            std (float): the standard deviation of the normal distribution (default=0.02).\n",
        "        \"\"\"\n",
        "        for m in self.children():\n",
        "            if isinstance(m, ConvBlock):\n",
        "                torch.nn.init.normal(m.conv.weight, mean, std)"
      ],
      "metadata": {
        "id": "OWNfFWvFY1I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generators G_A and G_B are defined with 3 input channels, 'params.ngf' number of filters in the first layer, 3 output channels, and 'params.num_resnet' number of residual blocks. The discriminators D_A and D_B are defined with 3 input channels, 'params.ndf' number of filters in the first layer, and 1 output channel. The normal_weight_init method is called on each of the generators and discriminators to initialize their weights. Lastly, the models are moved to the GPU by calling the 'cuda()' method on each of them."
      ],
      "metadata": {
        "id": "DeMRscCydP4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G_A = Generator(3, params.ngf, 3, params.num_resnet) # input_dim, num_filter, output_dim, num_resnet\n",
        "G_B = Generator(3, params.ngf, 3, params.num_resnet)\n",
        "\n",
        "D_A = Discriminator(3, params.ndf, 1) # input_dim, num_filter, output_dim\n",
        "D_B = Discriminator(3, params.ndf, 1)\n",
        "\n",
        "G_A.normal_weight_init(mean=0.0, std=0.02)\n",
        "G_B.normal_weight_init(mean=0.0, std=0.02)\n",
        "D_A.normal_weight_init(mean=0.0, std=0.02)\n",
        "D_B.normal_weight_init(mean=0.0, std=0.02)\n",
        "\n",
        "print(G_A.cuda())\n",
        "print(G_B.cuda())\n",
        "print(D_A.cuda())\n",
        "print(D_B.cuda())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2gTLSsicIcZ",
        "outputId": "119e96e7-8ada-4c07-92bf-46c942c58e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-22f1c05eee54>:115: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  torch.nn.init.normal(m.conv.weight, mean, std)\n",
            "<ipython-input-10-22f1c05eee54>:117: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  torch.nn.init.normal(m.deconv.weight, mean, std)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (pad): ReflectionPad2d((3, 3, 3, 3))\n",
            "  (conv1): ConvBlock(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (bn): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (tanh): Tanh()\n",
            "  )\n",
            "  (conv2): ConvBlock(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (bn): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (tanh): Tanh()\n",
            "  )\n",
            "  (conv3): ConvBlock(\n",
            "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (bn): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (tanh): Tanh()\n",
            "  )\n",
            "  (resnet_blocks): Sequential(\n",
            "    (0): ResnetBlock(\n",
            "      (resnet_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (1): ResnetBlock(\n",
            "      (resnet_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (2): ResnetBlock(\n",
            "      (resnet_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (3): ResnetBlock(\n",
            "      (resnet_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (4): ResnetBlock(\n",
            "      (resnet_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (5): ResnetBlock(\n",
            "      (resnet_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (deconv1): DeconvBlock(\n",
            "    (deconv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (bn): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (deconv2): DeconvBlock(\n",
            "    (deconv): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (bn): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (deconv3): ConvBlock(\n",
            "    (conv): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (bn): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (tanh): Tanh()\n",
            "  )\n",
            ")\n",
            "Generator(\n",
            "  (pad): ReflectionPad2d((3, 3, 3, 3))\n",
            "  (conv1): ConvBlock(\n",
            "    (conv): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (bn): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (tanh): Tanh()\n",
            "  )\n",
            "  (conv2): ConvBlock(\n",
            "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (bn): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (tanh): Tanh()\n",
            "  )\n",
            "  (conv3): ConvBlock(\n",
            "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (bn): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (tanh): Tanh()\n",
            "  )\n",
            "  (resnet_blocks): Sequential(\n",
            "    (0): ResnetBlock(\n",
            "      (resnet_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (1): ResnetBlock(\n",
            "      (resnet_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (2): ResnetBlock(\n",
            "      (resnet_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (3): ResnetBlock(\n",
            "      (resnet_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (4): ResnetBlock(\n",
            "      (resnet_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (5): ResnetBlock(\n",
            "      (resnet_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (deconv1): DeconvBlock(\n",
            "    (deconv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (bn): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (deconv2): DeconvBlock(\n",
            "    (deconv): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (bn): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (deconv3): ConvBlock(\n",
            "    (conv): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (bn): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (tanh): Tanh()\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (conv_blocks): Sequential(\n",
            "    (0): ConvBlock(\n",
            "      (conv): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (bn): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (tanh): Tanh()\n",
            "    )\n",
            "    (1): ConvBlock(\n",
            "      (conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (bn): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (tanh): Tanh()\n",
            "    )\n",
            "    (2): ConvBlock(\n",
            "      (conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (bn): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (tanh): Tanh()\n",
            "    )\n",
            "    (3): ConvBlock(\n",
            "      (conv): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "      (bn): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (tanh): Tanh()\n",
            "    )\n",
            "    (4): ConvBlock(\n",
            "      (conv): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "      (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (tanh): Tanh()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (conv_blocks): Sequential(\n",
            "    (0): ConvBlock(\n",
            "      (conv): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (bn): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (tanh): Tanh()\n",
            "    )\n",
            "    (1): ConvBlock(\n",
            "      (conv): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (bn): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (tanh): Tanh()\n",
            "    )\n",
            "    (2): ConvBlock(\n",
            "      (conv): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (bn): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (tanh): Tanh()\n",
            "    )\n",
            "    (3): ConvBlock(\n",
            "      (conv): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "      (bn): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (tanh): Tanh()\n",
            "    )\n",
            "    (4): ConvBlock(\n",
            "      (conv): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "      (bn): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (tanh): Tanh()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing the three optimizers:\n",
        "\n",
        "1. G_optimizer for optimizing the generators G_A and G_B with the Adam optimizer\n",
        "2. D_A_optimizer for optimizing the discriminator D_A with the Adam optimizer\n",
        "3. D_B_optimizer for optimizing the discriminator D_B with the Adam optimizer"
      ],
      "metadata": {
        "id": "uutXfLnudai9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G_optimizer = torch.optim.Adam(itertools.chain(G_A.parameters(), G_B.parameters()), lr=params.lrG, betas=(params.beta1, params.beta2))\n",
        "D_A_optimizer = torch.optim.Adam(D_A.parameters(), lr=params.lrD, betas=(params.beta1, params.beta2))\n",
        "D_B_optimizer = torch.optim.Adam(D_B.parameters(), lr=params.lrD, betas=(params.beta1, params.beta2))"
      ],
      "metadata": {
        "id": "6mzBFZb0cOMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Auxiliary Functions"
      ],
      "metadata": {
        "id": "kWbOvG0liHLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_np(x):\n",
        "    \"\"\"\n",
        "    Converts a PyTorch tensor to a NumPy array on the CPU.\n",
        "\n",
        "    Args:\n",
        "    x: A PyTorch tensor.\n",
        "\n",
        "    Returns:\n",
        "    A NumPy array on the CPU.\n",
        "    \"\"\"\n",
        "    return x.data.cpu().numpy()\n",
        "\n",
        "\n",
        "def to_var(x):\n",
        "    \"\"\"\n",
        "    Converts a tensor to a PyTorch Variable and moves it to the GPU if CUDA is available.\n",
        "\n",
        "    Args:\n",
        "    x: The tensor to be converted.\n",
        "\n",
        "    Returns:\n",
        "    A PyTorch Variable containing the input tensor, moved to the GPU if available.\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return Variable(x)\n",
        "\n",
        "\n",
        "# De-normalization\n",
        "def denorm(x):\n",
        "    \"\"\"\n",
        "    De-normalizes the input tensor by scaling it from the range [-1, 1] to [0, 1].\n",
        "\n",
        "    Args:\n",
        "    x (torch.Tensor): Input tensor to be de-normalized.\n",
        "\n",
        "    Returns:\n",
        "    torch.Tensor: De-normalized tensor.\n",
        "    \"\"\"\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)\n",
        "\n",
        "\n",
        "# Plot losses\n",
        "def plot_loss(avg_losses, num_epochs, save=False, save_dir='results/', show=False):\n",
        "    \"\"\"\n",
        "    Plots the losses of a GAN model.\n",
        "\n",
        "    Args:\n",
        "        avg_losses (list): A list of average loss values for each model (D_A, D_B, G_A, G_B, cycle_A, cycle_B) at different epochs.\n",
        "        num_epochs (int): The total number of epochs.\n",
        "        save (bool, optional): If True, saves the plot to a file. Defaults to False.\n",
        "        save_dir (str, optional): The directory where the plot should be saved. Defaults to 'results/'.\n",
        "        show (bool, optional): If True, displays the plot. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_xlim(0, num_epochs)\n",
        "    temp = 0.0\n",
        "    for i in range(len(avg_losses)):\n",
        "        temp = max(np.max(avg_losses[i]), temp)\n",
        "    ax.set_ylim(0, temp*1.1)\n",
        "    plt.xlabel('# of Epochs')\n",
        "    plt.ylabel('Loss values')\n",
        "\n",
        "    plt.plot(avg_losses[0], label='D_A')\n",
        "    plt.plot(avg_losses[1], label='D_B')\n",
        "    plt.plot(avg_losses[2], label='G_A')\n",
        "    plt.plot(avg_losses[3], label='G_B')\n",
        "    plt.plot(avg_losses[4], label='cycle_A')\n",
        "    plt.plot(avg_losses[5], label='cycle_B')\n",
        "    plt.legend()\n",
        "\n",
        "    # save figure\n",
        "    if save:\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.mkdir(save_dir)\n",
        "        save_fn = save_dir + 'Loss_values_epoch_{:d}'.format(num_epochs) + '.png'\n",
        "        plt.savefig(save_fn)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "def plot_train_result(real_image, gen_image, recon_image, epoch, save=False, save_dir='results/', show=False, fig_size=(5, 5)):\n",
        "    \"\"\"\n",
        "    Plots a grid of real images, generated images, and reconstructed images produced by a GAN model at a given epoch.\n",
        "\n",
        "    Args:\n",
        "        real_image (torch.Tensor): A tensor of real images.\n",
        "        gen_image (torch.Tensor): A tensor of generated images.\n",
        "        recon_image (torch.Tensor): A tensor of reconstructed images.\n",
        "        epoch (int): The epoch number.\n",
        "        save (bool, optional): If True, saves the plot to a file. Defaults to False.\n",
        "        save_dir (str, optional): The directory where the plot should be saved. Defaults to 'results/'.\n",
        "        show (bool, optional): If True, displays the plot. Defaults to False.\n",
        "        fig_size (tuple, optional): The size of the figure. Defaults to (5, 5).\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=fig_size)\n",
        "\n",
        "    imgs = [to_np(real_image[0]), to_np(gen_image[0]), to_np(recon_image[0]),\n",
        "            to_np(real_image[1]), to_np(gen_image[1]), to_np(recon_image[1])]\n",
        "    for ax, img in zip(axes.flatten(), imgs):\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box')\n",
        "        # Scale to 0-255\n",
        "        img = img.squeeze()\n",
        "        img = (((img - img.min()) * 255) / (img.max() - img.min())).transpose(1, 2, 0).astype(np.uint8)\n",
        "        ax.imshow(img, cmap=None, aspect='equal')\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "    title = 'Epoch {0}'.format(epoch + 1)\n",
        "    fig.text(0.5, 0.04, title, ha='center')\n",
        "\n",
        "    # save figure\n",
        "    if save:\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.mkdir(save_dir)\n",
        "\n",
        "        save_fn = save_dir + 'Result_epoch_{:d}'.format(epoch+1) + '.png'\n",
        "        plt.savefig(save_fn)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "def plot_test_result(real_image, gen_image, recon_image, index, save=False, save_dir='results/', show=False):\n",
        "    \"\"\"\n",
        "    Plots the real image, generated image, and reconstructed image for a single test sample.\n",
        "\n",
        "    Args:\n",
        "    - real_image: torch.Tensor of shape (batch_size, channels, height, width) representing the real image.\n",
        "    - gen_image: torch.Tensor of shape (batch_size, channels, height, width) representing the generated image.\n",
        "    - recon_image: torch.Tensor of shape (batch_size, channels, height, width) representing the reconstructed image.\n",
        "    - index: int representing the index of the test sample.\n",
        "    - save: bool flag indicating whether to save the plot to a file.\n",
        "    - save_dir: str representing the directory where the plot will be saved.\n",
        "    - show: bool flag indicating whether to display the plot.\n",
        "    \n",
        "    Returns: None.\n",
        "    \"\"\"\n",
        "    fig_size = (real_image.size(2) * 3 / 100, real_image.size(3) / 100)\n",
        "    fig, axes = plt.subplots(1, 3, figsize=fig_size)\n",
        "\n",
        "    imgs = [to_np(real_image), to_np(gen_image), to_np(recon_image)]\n",
        "    for ax, img in zip(axes.flatten(), imgs):\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box')\n",
        "        # Scale to 0-255\n",
        "        img = img.squeeze()\n",
        "        img = (((img - img.min()) * 255) / (img.max() - img.min())).transpose(1, 2, 0).astype(np.uint8)\n",
        "        ax.imshow(img, cmap=None, aspect='equal')\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "    # save figure\n",
        "    if save:\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.mkdir(save_dir)\n",
        "\n",
        "        save_fn = save_dir + 'Test_result_{:d}'.format(index + 1) + '.png'\n",
        "        fig.subplots_adjust(bottom=0)\n",
        "        fig.subplots_adjust(top=1)\n",
        "        fig.subplots_adjust(right=1)\n",
        "        fig.subplots_adjust(left=0)\n",
        "        plt.savefig(save_fn)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()\n",
        "\n",
        "# Make gif\n",
        "def make_gif(dataset, num_epochs, save_dir='results/', source_dir='results/'):\n",
        "    \"\"\"\n",
        "    Create a GIF by combining all the image plots saved during the training of a CycleGAN model.\n",
        "\n",
        "    Args:\n",
        "        dataset (str): Name of the dataset.\n",
        "        num_epochs (int): Number of epochs for which the image plots have been saved.\n",
        "        save_dir (str, optional): Directory to save the generated GIF. Defaults to 'results/'.\n",
        "        source_dir (str, optional): Directory where the image plots are saved. Defaults to 'results/'.\n",
        "    \"\"\"\n",
        "    gen_image_plots = []\n",
        "    for epoch in range(num_epochs):\n",
        "        # plot for generating gif\n",
        "        save_fn = source_dir + 'Result_epoch_{:d}'.format(epoch + 1) + '.png'\n",
        "        gen_image_plots.append(imageio.imread(save_fn))\n",
        "\n",
        "    imageio.mimsave(save_dir + dataset + '_CycleGAN_epochs_{:d}'.format(num_epochs) + '.gif', gen_image_plots, fps=5)\n",
        "\n",
        "\n",
        "class ImagePool():\n",
        "    \"\"\"\n",
        "    Class for implementing an image pool for CycleGAN training.\n",
        "\n",
        "    Args:\n",
        "        pool_size (int): The maximum number of images to store in the pool.\n",
        "\n",
        "    Attributes:\n",
        "        pool_size (int): The maximum number of images to store in the pool.\n",
        "        num_imgs (int): The current number of images in the pool.\n",
        "        images (list): A list of images currently in the pool.\n",
        "    \"\"\"\n",
        "    def __init__(self, pool_size):\n",
        "        self.pool_size = pool_size\n",
        "        if self.pool_size > 0:\n",
        "            self.num_imgs = 0\n",
        "            self.images = []\n",
        "\n",
        "    def query(self, images):\n",
        "        \"\"\"\n",
        "        Query the image pool to retrieve a set of images.\n",
        "\n",
        "        If the pool is not full, the input images are added to the pool and returned\n",
        "        without modification. Otherwise, each input image is either added to the pool\n",
        "        with a probability of 0.5, or a random image from the pool is returned instead.\n",
        "\n",
        "        Args:\n",
        "            images (torch.Tensor): A tensor of input images to retrieve from the pool.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: A tensor of output images, either the original input images or\n",
        "            images retrieved from the pool.\n",
        "        \"\"\"\n",
        "        if self.pool_size == 0:\n",
        "            return images\n",
        "        return_images = []\n",
        "        for image in images.data:\n",
        "            image = torch.unsqueeze(image, 0)\n",
        "            if self.num_imgs < self.pool_size:\n",
        "                self.num_imgs = self.num_imgs + 1\n",
        "                self.images.append(image)\n",
        "                return_images.append(image)\n",
        "            else:\n",
        "                p = random.uniform(0, 1)\n",
        "                if p > 0.5:\n",
        "                    random_id = random.randint(0, self.pool_size-1)\n",
        "                    tmp = self.images[random_id].clone()\n",
        "                    self.images[random_id] = image\n",
        "                    return_images.append(tmp)\n",
        "                else:\n",
        "                    return_images.append(image)\n",
        "        return_images = Variable(torch.cat(return_images, 0))\n",
        "        return return_images"
      ],
      "metadata": {
        "id": "PohkGgUWcWBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the loss functions to be used during training and initializes some lists to store the average losses during training. Also initialize image pools to store generated images for use in training the generators."
      ],
      "metadata": {
        "id": "SGj40uYGfaz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MSE_Loss = torch.nn.MSELoss().cuda()\n",
        "L1_Loss = torch.nn.L1Loss().cuda()\n",
        "\n",
        "# # Training GAN\n",
        "D_A_avg_losses = []\n",
        "D_B_avg_losses = []\n",
        "G_A_avg_losses = []\n",
        "G_B_avg_losses = []\n",
        "cycle_A_avg_losses = []\n",
        "cycle_B_avg_losses = []\n",
        "\n",
        "# Generated image pool\n",
        "num_pool = 50\n",
        "fake_A_pool = ImagePool(num_pool)\n",
        "fake_B_pool = ImagePool(num_pool)"
      ],
      "metadata": {
        "id": "YIa7VMoMcQ2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "BgsZ8dOvfzvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "step = 0\n",
        "for epoch in range(params.num_epochs):\n",
        "    D_A_losses = []\n",
        "    D_B_losses = []\n",
        "    G_A_losses = []\n",
        "    G_B_losses = []\n",
        "    cycle_A_losses = []\n",
        "    cycle_B_losses = []\n",
        "    \n",
        "    # Learing rate decay\n",
        "    if(epoch + 1) > params.decay_epoch:\n",
        "        D_A_optimizer.param_groups[0]['lr'] -= params.lrD / (params.num_epochs - params.decay_epoch)\n",
        "        D_B_optimizer.param_groups[0]['lr'] -= params.lrD / (params.num_epochs - params.decay_epoch)\n",
        "        G_optimizer.param_groups[0]['lr'] -= params.lrG / (params.num_epochs - params.decay_epoch)\n",
        "        \n",
        "    \n",
        "    # training\n",
        "    for i, (real_A, real_B) in enumerate(zip(train_data_loader_A, train_data_loader_B)):\n",
        "        \n",
        "        # input image data\n",
        "        real_A = Variable(real_A.cuda())\n",
        "        real_B = Variable(real_B.cuda())\n",
        "        \n",
        "        # -------------------------- train generator G --------------------------\n",
        "        # A --> B\n",
        "        fake_B = G_A(real_A)\n",
        "        D_B_fake_decision = D_B(fake_B)\n",
        "        G_A_loss = MSE_Loss(D_B_fake_decision, Variable(torch.ones(D_B_fake_decision.size()).cuda()))\n",
        "        \n",
        "        # forward cycle loss\n",
        "        recon_A = G_B(fake_B)\n",
        "        cycle_A_loss = L1_Loss(recon_A, real_A) * params.lambdaA\n",
        "        \n",
        "        # B --> A\n",
        "        fake_A = G_B(real_B)\n",
        "        D_A_fake_decision = D_A(fake_A)\n",
        "        G_B_loss = MSE_Loss(D_A_fake_decision, Variable(torch.ones(D_A_fake_decision.size()).cuda()))\n",
        "        \n",
        "        # backward cycle loss\n",
        "        recon_B = G_A(fake_A)\n",
        "        cycle_B_loss = L1_Loss(recon_B, real_B) * params.lambdaB\n",
        "        \n",
        "        # Back propagation\n",
        "        G_loss = G_A_loss + G_B_loss + cycle_A_loss + cycle_B_loss\n",
        "        G_optimizer.zero_grad()\n",
        "        G_loss.backward()\n",
        "        G_optimizer.step()\n",
        "        \n",
        "        \n",
        "        # -------------------------- train discriminator D_A --------------------------\n",
        "        D_A_real_decision = D_A(real_A)\n",
        "        D_A_real_loss = MSE_Loss(D_A_real_decision, Variable(torch.ones(D_A_real_decision.size()).cuda()))\n",
        "        \n",
        "        fake_A = fake_A_pool.query(fake_A)\n",
        "        \n",
        "        D_A_fake_decision = D_A(fake_A)\n",
        "        D_A_fake_loss = MSE_Loss(D_A_fake_decision, Variable(torch.zeros(D_A_fake_decision.size()).cuda()))\n",
        "        \n",
        "        # Back propagation\n",
        "        D_A_loss = (D_A_real_loss + D_A_fake_loss) * 0.5\n",
        "        D_A_optimizer.zero_grad()\n",
        "        D_A_loss.backward()\n",
        "        D_A_optimizer.step()\n",
        "        \n",
        "        # -------------------------- train discriminator D_B --------------------------\n",
        "        D_B_real_decision = D_B(real_B)\n",
        "        D_B_real_loss = MSE_Loss(D_B_real_decision, Variable(torch.ones(D_B_fake_decision.size()).cuda()))\n",
        "        \n",
        "        fake_B = fake_B_pool.query(fake_B)\n",
        "        \n",
        "        D_B_fake_decision = D_B(fake_B)\n",
        "        D_B_fake_loss = MSE_Loss(D_B_fake_decision, Variable(torch.zeros(D_B_fake_decision.size()).cuda()))\n",
        "        \n",
        "        # Back propagation\n",
        "        D_B_loss = (D_B_real_loss + D_B_fake_loss) * 0.5\n",
        "        D_B_optimizer.zero_grad()\n",
        "        D_B_loss.backward()\n",
        "        D_B_optimizer.step()\n",
        "        \n",
        "        # ------------------------ Print -----------------------------\n",
        "        # loss values\n",
        "        D_A_losses.append(D_A_loss.data)\n",
        "        D_B_losses.append(D_B_loss.data)\n",
        "        G_A_losses.append(G_A_loss.data)\n",
        "        G_B_losses.append(G_B_loss.data)\n",
        "        cycle_A_losses.append(cycle_A_loss.data)\n",
        "        cycle_B_losses.append(cycle_B_loss.data)\n",
        "\n",
        "        if i%10 == 0:\n",
        "            print('Epoch [%d/%d], Step [%d/%d], D_A_loss: %.4f, D_B_loss: %.4f, G_A_loss: %.4f, G_B_loss: %.4f'\n",
        "                  % (epoch+1, params.num_epochs, i+1, len(train_data_loader_A), D_A_loss.data, D_B_loss.data, G_A_loss.data, G_B_loss.data))\n",
        "        step += 1\n",
        "        \n",
        "    D_A_avg_loss = torch.mean(torch.FloatTensor(D_A_losses))\n",
        "    D_B_avg_loss = torch.mean(torch.FloatTensor(D_B_losses))\n",
        "    G_A_avg_loss = torch.mean(torch.FloatTensor(G_A_losses))\n",
        "    G_B_avg_loss = torch.mean(torch.FloatTensor(G_B_losses))\n",
        "    cycle_A_avg_loss = torch.mean(torch.FloatTensor(cycle_A_losses))\n",
        "    cycle_B_avg_loss = torch.mean(torch.FloatTensor(cycle_B_losses))\n",
        "\n",
        "    # avg loss values for plot\n",
        "    D_A_avg_losses.append(D_A_avg_loss)\n",
        "    D_B_avg_losses.append(D_B_avg_loss)\n",
        "    G_A_avg_losses.append(G_A_avg_loss)\n",
        "    G_B_avg_losses.append(G_B_avg_loss)\n",
        "    cycle_A_avg_losses.append(cycle_A_avg_loss)\n",
        "    cycle_B_avg_losses.append(cycle_B_avg_loss)\n",
        "\n",
        "    # Show result for test image\n",
        "    test_real_A = Variable(test_real_A_data.cuda())\n",
        "    test_fake_B = G_A(test_real_A)\n",
        "    test_recon_A = G_B(test_fake_B)\n",
        "\n",
        "    test_real_B = Variable(test_real_B_data.cuda())\n",
        "    test_fake_A = G_B(test_real_B)\n",
        "    test_recon_B = G_A(test_fake_A)\n",
        "\n",
        "    plot_train_result([test_real_A, test_real_B], [test_fake_B, test_fake_A], [test_recon_A, test_recon_B],\n",
        "                            epoch, save=True, save_dir=save_dir)\n",
        "\n",
        "    # log the images\n",
        "    result_AtoB = np.concatenate((to_np(test_real_A), to_np(test_fake_B), to_np(test_recon_A)), axis=3)\n",
        "    result_BtoA = np.concatenate((to_np(test_real_B), to_np(test_fake_A), to_np(test_recon_B)), axis=3)\n",
        "\n",
        "    info = { 'result_AtoB': result_AtoB.transpose(0, 2, 3, 1),  # convert to BxHxWxC\n",
        "             'result_BtoA': result_BtoA.transpose(0, 2, 3, 1) }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3NAP_2TceWp",
        "outputId": "a8c4c4cd-a6a5-4124-b102-65717f6aedde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/70], Step [1/1231], D_A_loss: 0.9004, D_B_loss: 0.4739, G_A_loss: 0.7661, G_B_loss: 1.6461\n",
            "Epoch [1/70], Step [11/1231], D_A_loss: 0.3759, D_B_loss: 0.2603, G_A_loss: 0.3970, G_B_loss: 0.4130\n",
            "Epoch [1/70], Step [21/1231], D_A_loss: 0.2525, D_B_loss: 0.2814, G_A_loss: 0.3459, G_B_loss: 0.3882\n",
            "Epoch [1/70], Step [31/1231], D_A_loss: 0.1928, D_B_loss: 0.2898, G_A_loss: 0.3215, G_B_loss: 0.3438\n",
            "Epoch [1/70], Step [41/1231], D_A_loss: 0.2498, D_B_loss: 0.2496, G_A_loss: 0.3088, G_B_loss: 0.4098\n",
            "Epoch [1/70], Step [51/1231], D_A_loss: 0.2251, D_B_loss: 0.1930, G_A_loss: 0.4088, G_B_loss: 0.3963\n",
            "Epoch [1/70], Step [61/1231], D_A_loss: 0.2801, D_B_loss: 0.1386, G_A_loss: 0.4704, G_B_loss: 0.3859\n",
            "Epoch [1/70], Step [71/1231], D_A_loss: 0.2683, D_B_loss: 0.2249, G_A_loss: 0.4105, G_B_loss: 0.2886\n",
            "Epoch [1/70], Step [81/1231], D_A_loss: 0.1987, D_B_loss: 0.1831, G_A_loss: 0.3772, G_B_loss: 0.4262\n",
            "Epoch [1/70], Step [91/1231], D_A_loss: 0.1454, D_B_loss: 0.1863, G_A_loss: 0.3858, G_B_loss: 0.4949\n",
            "Epoch [1/70], Step [101/1231], D_A_loss: 0.2091, D_B_loss: 0.2137, G_A_loss: 0.2074, G_B_loss: 0.6725\n",
            "Epoch [1/70], Step [111/1231], D_A_loss: 0.2008, D_B_loss: 0.1742, G_A_loss: 0.4370, G_B_loss: 0.3828\n",
            "Epoch [1/70], Step [121/1231], D_A_loss: 0.1903, D_B_loss: 0.2683, G_A_loss: 0.2366, G_B_loss: 0.3221\n",
            "Epoch [1/70], Step [131/1231], D_A_loss: 0.1774, D_B_loss: 0.1896, G_A_loss: 0.1722, G_B_loss: 0.5419\n",
            "Epoch [1/70], Step [141/1231], D_A_loss: 0.1398, D_B_loss: 0.2977, G_A_loss: 0.2339, G_B_loss: 0.4770\n",
            "Epoch [1/70], Step [151/1231], D_A_loss: 0.1069, D_B_loss: 0.1093, G_A_loss: 0.2470, G_B_loss: 0.3541\n",
            "Epoch [1/70], Step [161/1231], D_A_loss: 0.2226, D_B_loss: 0.2009, G_A_loss: 0.2268, G_B_loss: 0.6340\n",
            "Epoch [1/70], Step [171/1231], D_A_loss: 0.1497, D_B_loss: 0.3021, G_A_loss: 0.1110, G_B_loss: 0.3306\n",
            "Epoch [1/70], Step [181/1231], D_A_loss: 0.3630, D_B_loss: 0.2255, G_A_loss: 0.3010, G_B_loss: 0.1940\n",
            "Epoch [1/70], Step [191/1231], D_A_loss: 0.1216, D_B_loss: 0.2618, G_A_loss: 0.4466, G_B_loss: 0.2846\n",
            "Epoch [1/70], Step [201/1231], D_A_loss: 0.1098, D_B_loss: 0.2136, G_A_loss: 0.3550, G_B_loss: 0.5485\n",
            "Epoch [1/70], Step [211/1231], D_A_loss: 0.1809, D_B_loss: 0.2326, G_A_loss: 0.2570, G_B_loss: 0.1331\n",
            "Epoch [1/70], Step [221/1231], D_A_loss: 0.1289, D_B_loss: 0.1963, G_A_loss: 0.3485, G_B_loss: 0.4742\n",
            "Epoch [1/70], Step [231/1231], D_A_loss: 0.2305, D_B_loss: 0.2230, G_A_loss: 0.3208, G_B_loss: 0.2527\n",
            "Epoch [1/70], Step [241/1231], D_A_loss: 0.1540, D_B_loss: 0.1781, G_A_loss: 0.2640, G_B_loss: 0.3925\n",
            "Epoch [1/70], Step [251/1231], D_A_loss: 0.3680, D_B_loss: 0.2370, G_A_loss: 0.2667, G_B_loss: 0.2985\n",
            "Epoch [1/70], Step [261/1231], D_A_loss: 0.0850, D_B_loss: 0.1742, G_A_loss: 0.3844, G_B_loss: 0.4131\n",
            "Epoch [1/70], Step [271/1231], D_A_loss: 0.1164, D_B_loss: 0.2796, G_A_loss: 0.1577, G_B_loss: 0.5284\n",
            "Epoch [1/70], Step [281/1231], D_A_loss: 0.1775, D_B_loss: 0.1942, G_A_loss: 0.3017, G_B_loss: 0.0617\n",
            "Epoch [1/70], Step [291/1231], D_A_loss: 0.0887, D_B_loss: 0.2510, G_A_loss: 0.3455, G_B_loss: 0.4677\n",
            "Epoch [1/70], Step [301/1231], D_A_loss: 0.2100, D_B_loss: 0.2206, G_A_loss: 0.3234, G_B_loss: 0.2360\n",
            "Epoch [1/70], Step [311/1231], D_A_loss: 0.1934, D_B_loss: 0.2108, G_A_loss: 0.3819, G_B_loss: 0.4038\n",
            "Epoch [1/70], Step [321/1231], D_A_loss: 0.1466, D_B_loss: 0.2725, G_A_loss: 0.2674, G_B_loss: 0.1991\n",
            "Epoch [1/70], Step [331/1231], D_A_loss: 0.2372, D_B_loss: 0.2155, G_A_loss: 0.3121, G_B_loss: 0.5905\n",
            "Epoch [1/70], Step [341/1231], D_A_loss: 0.1946, D_B_loss: 0.1930, G_A_loss: 0.3513, G_B_loss: 0.4691\n",
            "Epoch [1/70], Step [351/1231], D_A_loss: 0.2705, D_B_loss: 0.2591, G_A_loss: 0.3116, G_B_loss: 0.2821\n",
            "Epoch [1/70], Step [361/1231], D_A_loss: 0.1622, D_B_loss: 0.1363, G_A_loss: 0.4361, G_B_loss: 0.3364\n",
            "Epoch [1/70], Step [371/1231], D_A_loss: 0.3380, D_B_loss: 0.1781, G_A_loss: 0.3694, G_B_loss: 0.2123\n",
            "Epoch [1/70], Step [381/1231], D_A_loss: 0.2132, D_B_loss: 0.2710, G_A_loss: 0.3835, G_B_loss: 0.4119\n",
            "Epoch [1/70], Step [391/1231], D_A_loss: 0.2859, D_B_loss: 0.2685, G_A_loss: 0.2410, G_B_loss: 0.2434\n",
            "Epoch [1/70], Step [401/1231], D_A_loss: 0.2353, D_B_loss: 0.1089, G_A_loss: 0.2828, G_B_loss: 0.3302\n",
            "Epoch [1/70], Step [411/1231], D_A_loss: 0.3443, D_B_loss: 0.2509, G_A_loss: 0.3896, G_B_loss: 0.3359\n",
            "Epoch [1/70], Step [421/1231], D_A_loss: 0.1661, D_B_loss: 0.1644, G_A_loss: 0.3458, G_B_loss: 0.4685\n",
            "Epoch [1/70], Step [431/1231], D_A_loss: 0.2774, D_B_loss: 0.1692, G_A_loss: 0.1493, G_B_loss: 0.1523\n",
            "Epoch [1/70], Step [441/1231], D_A_loss: 0.2213, D_B_loss: 0.1685, G_A_loss: 0.4756, G_B_loss: 0.3171\n",
            "Epoch [1/70], Step [451/1231], D_A_loss: 0.1499, D_B_loss: 0.3234, G_A_loss: 0.5449, G_B_loss: 0.1684\n",
            "Epoch [1/70], Step [461/1231], D_A_loss: 0.1449, D_B_loss: 0.3011, G_A_loss: 0.7396, G_B_loss: 0.4270\n",
            "Epoch [1/70], Step [471/1231], D_A_loss: 0.1785, D_B_loss: 0.1975, G_A_loss: 0.4622, G_B_loss: 0.4614\n",
            "Epoch [1/70], Step [481/1231], D_A_loss: 0.2205, D_B_loss: 0.2046, G_A_loss: 0.1970, G_B_loss: 0.2071\n",
            "Epoch [1/70], Step [491/1231], D_A_loss: 0.2586, D_B_loss: 0.2207, G_A_loss: 0.3590, G_B_loss: 0.2080\n",
            "Epoch [1/70], Step [501/1231], D_A_loss: 0.1368, D_B_loss: 0.1661, G_A_loss: 0.4183, G_B_loss: 0.2633\n",
            "Epoch [1/70], Step [511/1231], D_A_loss: 0.0839, D_B_loss: 0.1596, G_A_loss: 0.3942, G_B_loss: 0.4856\n",
            "Epoch [1/70], Step [521/1231], D_A_loss: 0.2451, D_B_loss: 0.1796, G_A_loss: 0.3552, G_B_loss: 0.3230\n",
            "Epoch [1/70], Step [531/1231], D_A_loss: 0.1543, D_B_loss: 0.1598, G_A_loss: 0.3699, G_B_loss: 0.3159\n",
            "Epoch [1/70], Step [541/1231], D_A_loss: 0.1228, D_B_loss: 0.1213, G_A_loss: 0.4593, G_B_loss: 0.7840\n",
            "Epoch [1/70], Step [551/1231], D_A_loss: 0.2520, D_B_loss: 0.2129, G_A_loss: 0.2715, G_B_loss: 0.2037\n",
            "Epoch [1/70], Step [561/1231], D_A_loss: 0.1301, D_B_loss: 0.1442, G_A_loss: 0.1578, G_B_loss: 0.5604\n",
            "Epoch [1/70], Step [571/1231], D_A_loss: 0.0796, D_B_loss: 0.1290, G_A_loss: 0.6951, G_B_loss: 0.2466\n",
            "Epoch [1/70], Step [581/1231], D_A_loss: 0.1590, D_B_loss: 0.3655, G_A_loss: 0.6314, G_B_loss: 0.3579\n",
            "Epoch [1/70], Step [591/1231], D_A_loss: 0.1651, D_B_loss: 0.1985, G_A_loss: 0.4701, G_B_loss: 0.3596\n",
            "Epoch [1/70], Step [601/1231], D_A_loss: 0.1342, D_B_loss: 0.1532, G_A_loss: 0.4796, G_B_loss: 0.4364\n",
            "Epoch [1/70], Step [611/1231], D_A_loss: 0.1228, D_B_loss: 0.1079, G_A_loss: 0.3073, G_B_loss: 0.3977\n",
            "Epoch [1/70], Step [621/1231], D_A_loss: 0.1567, D_B_loss: 0.1579, G_A_loss: 0.3520, G_B_loss: 0.2801\n",
            "Epoch [1/70], Step [631/1231], D_A_loss: 0.0617, D_B_loss: 0.3362, G_A_loss: 0.1135, G_B_loss: 0.3842\n",
            "Epoch [1/70], Step [641/1231], D_A_loss: 0.1906, D_B_loss: 0.2342, G_A_loss: 0.5070, G_B_loss: 0.5707\n",
            "Epoch [1/70], Step [651/1231], D_A_loss: 0.1495, D_B_loss: 0.2047, G_A_loss: 0.7076, G_B_loss: 0.5646\n",
            "Epoch [1/70], Step [661/1231], D_A_loss: 0.1889, D_B_loss: 0.1100, G_A_loss: 0.6711, G_B_loss: 0.6418\n",
            "Epoch [1/70], Step [671/1231], D_A_loss: 0.1636, D_B_loss: 0.1853, G_A_loss: 0.2351, G_B_loss: 0.6357\n",
            "Epoch [1/70], Step [681/1231], D_A_loss: 0.2457, D_B_loss: 0.2672, G_A_loss: 0.2596, G_B_loss: 0.3468\n",
            "Epoch [1/70], Step [691/1231], D_A_loss: 0.1350, D_B_loss: 0.1676, G_A_loss: 0.2666, G_B_loss: 0.7144\n",
            "Epoch [1/70], Step [701/1231], D_A_loss: 0.3242, D_B_loss: 0.1564, G_A_loss: 0.3352, G_B_loss: 0.9106\n",
            "Epoch [1/70], Step [711/1231], D_A_loss: 0.0612, D_B_loss: 0.2718, G_A_loss: 0.3700, G_B_loss: 0.4779\n",
            "Epoch [1/70], Step [721/1231], D_A_loss: 0.1697, D_B_loss: 0.1570, G_A_loss: 0.4497, G_B_loss: 0.6056\n",
            "Epoch [1/70], Step [731/1231], D_A_loss: 0.2518, D_B_loss: 0.0994, G_A_loss: 0.6458, G_B_loss: 0.1543\n",
            "Epoch [1/70], Step [741/1231], D_A_loss: 0.2456, D_B_loss: 0.1231, G_A_loss: 0.3233, G_B_loss: 0.2396\n",
            "Epoch [1/70], Step [751/1231], D_A_loss: 0.1694, D_B_loss: 0.1028, G_A_loss: 0.3502, G_B_loss: 0.5791\n",
            "Epoch [1/70], Step [761/1231], D_A_loss: 0.0892, D_B_loss: 0.1064, G_A_loss: 0.5344, G_B_loss: 0.5703\n",
            "Epoch [1/70], Step [771/1231], D_A_loss: 0.0613, D_B_loss: 0.0672, G_A_loss: 0.2059, G_B_loss: 0.5289\n",
            "Epoch [1/70], Step [781/1231], D_A_loss: 0.1926, D_B_loss: 0.0633, G_A_loss: 0.1775, G_B_loss: 0.3317\n",
            "Epoch [1/70], Step [791/1231], D_A_loss: 0.1398, D_B_loss: 0.1404, G_A_loss: 0.6615, G_B_loss: 0.4284\n",
            "Epoch [1/70], Step [801/1231], D_A_loss: 0.0989, D_B_loss: 0.1355, G_A_loss: 0.3375, G_B_loss: 0.4578\n",
            "Epoch [1/70], Step [811/1231], D_A_loss: 0.1967, D_B_loss: 0.2209, G_A_loss: 0.2231, G_B_loss: 0.4659\n",
            "Epoch [1/70], Step [821/1231], D_A_loss: 0.1696, D_B_loss: 0.2544, G_A_loss: 0.4553, G_B_loss: 0.2332\n",
            "Epoch [1/70], Step [831/1231], D_A_loss: 0.2282, D_B_loss: 0.1029, G_A_loss: 0.2622, G_B_loss: 0.3296\n",
            "Epoch [1/70], Step [841/1231], D_A_loss: 0.2609, D_B_loss: 0.1098, G_A_loss: 0.3197, G_B_loss: 0.1520\n",
            "Epoch [1/70], Step [851/1231], D_A_loss: 0.2353, D_B_loss: 0.1383, G_A_loss: 0.3272, G_B_loss: 0.2181\n",
            "Epoch [1/70], Step [861/1231], D_A_loss: 0.1409, D_B_loss: 0.4121, G_A_loss: 0.6152, G_B_loss: 0.6162\n",
            "Epoch [1/70], Step [871/1231], D_A_loss: 0.1031, D_B_loss: 0.3348, G_A_loss: 0.6890, G_B_loss: 0.0587\n",
            "Epoch [1/70], Step [881/1231], D_A_loss: 0.3060, D_B_loss: 0.0965, G_A_loss: 0.5288, G_B_loss: 0.1961\n",
            "Epoch [1/70], Step [891/1231], D_A_loss: 0.1325, D_B_loss: 0.0499, G_A_loss: 0.2184, G_B_loss: 0.1822\n",
            "Epoch [1/70], Step [901/1231], D_A_loss: 0.2218, D_B_loss: 0.2337, G_A_loss: 0.5320, G_B_loss: 0.3684\n",
            "Epoch [1/70], Step [911/1231], D_A_loss: 0.2456, D_B_loss: 0.2575, G_A_loss: 0.7589, G_B_loss: 0.5935\n",
            "Epoch [1/70], Step [921/1231], D_A_loss: 0.2129, D_B_loss: 0.1188, G_A_loss: 0.4045, G_B_loss: 0.4754\n",
            "Epoch [1/70], Step [931/1231], D_A_loss: 0.2182, D_B_loss: 0.1599, G_A_loss: 0.6500, G_B_loss: 0.1622\n",
            "Epoch [1/70], Step [941/1231], D_A_loss: 0.2668, D_B_loss: 0.3106, G_A_loss: 0.6104, G_B_loss: 0.2120\n",
            "Epoch [1/70], Step [951/1231], D_A_loss: 0.1343, D_B_loss: 0.0841, G_A_loss: 0.7489, G_B_loss: 0.4914\n",
            "Epoch [1/70], Step [961/1231], D_A_loss: 0.0776, D_B_loss: 0.2229, G_A_loss: 0.3068, G_B_loss: 0.6387\n",
            "Epoch [2/70], Step [1/1231], D_A_loss: 0.0775, D_B_loss: 0.2866, G_A_loss: 0.1034, G_B_loss: 0.3543\n",
            "Epoch [2/70], Step [11/1231], D_A_loss: 0.1030, D_B_loss: 0.3059, G_A_loss: 0.3518, G_B_loss: 0.5018\n",
            "Epoch [2/70], Step [21/1231], D_A_loss: 0.1132, D_B_loss: 0.2242, G_A_loss: 0.4156, G_B_loss: 0.4881\n",
            "Epoch [2/70], Step [31/1231], D_A_loss: 0.2357, D_B_loss: 0.2303, G_A_loss: 0.2906, G_B_loss: 0.7453\n",
            "Epoch [2/70], Step [41/1231], D_A_loss: 0.1619, D_B_loss: 0.2717, G_A_loss: 0.9620, G_B_loss: 0.5169\n",
            "Epoch [2/70], Step [51/1231], D_A_loss: 0.3531, D_B_loss: 0.2474, G_A_loss: 0.2779, G_B_loss: 0.5025\n",
            "Epoch [2/70], Step [61/1231], D_A_loss: 0.0536, D_B_loss: 0.2937, G_A_loss: 0.1018, G_B_loss: 0.4236\n",
            "Epoch [2/70], Step [71/1231], D_A_loss: 0.1263, D_B_loss: 0.1489, G_A_loss: 0.4837, G_B_loss: 0.3929\n",
            "Epoch [2/70], Step [81/1231], D_A_loss: 0.4459, D_B_loss: 0.3629, G_A_loss: 0.8453, G_B_loss: 0.0359\n",
            "Epoch [2/70], Step [91/1231], D_A_loss: 0.0858, D_B_loss: 0.0981, G_A_loss: 0.4535, G_B_loss: 0.1786\n",
            "Epoch [2/70], Step [101/1231], D_A_loss: 0.0657, D_B_loss: 0.1372, G_A_loss: 0.1824, G_B_loss: 0.3866\n",
            "Epoch [2/70], Step [111/1231], D_A_loss: 0.0862, D_B_loss: 0.2290, G_A_loss: 0.3302, G_B_loss: 0.2144\n",
            "Epoch [2/70], Step [121/1231], D_A_loss: 0.1362, D_B_loss: 0.0757, G_A_loss: 0.5939, G_B_loss: 0.5120\n",
            "Epoch [2/70], Step [131/1231], D_A_loss: 0.1236, D_B_loss: 0.0442, G_A_loss: 0.1277, G_B_loss: 0.4249\n",
            "Epoch [2/70], Step [141/1231], D_A_loss: 0.2923, D_B_loss: 0.0539, G_A_loss: 0.0804, G_B_loss: 0.2397\n",
            "Epoch [2/70], Step [151/1231], D_A_loss: 0.1338, D_B_loss: 0.1186, G_A_loss: 0.3372, G_B_loss: 0.0481\n",
            "Epoch [2/70], Step [161/1231], D_A_loss: 0.1921, D_B_loss: 0.2050, G_A_loss: 0.3359, G_B_loss: 0.1990\n",
            "Epoch [2/70], Step [171/1231], D_A_loss: 0.0398, D_B_loss: 0.1335, G_A_loss: 0.3249, G_B_loss: 1.0141\n",
            "Epoch [2/70], Step [181/1231], D_A_loss: 0.1410, D_B_loss: 0.1364, G_A_loss: 0.4115, G_B_loss: 0.2295\n",
            "Epoch [2/70], Step [191/1231], D_A_loss: 0.1815, D_B_loss: 0.1187, G_A_loss: 0.3990, G_B_loss: 0.5706\n",
            "Epoch [2/70], Step [201/1231], D_A_loss: 0.2875, D_B_loss: 0.1510, G_A_loss: 0.5151, G_B_loss: 0.0941\n",
            "Epoch [2/70], Step [211/1231], D_A_loss: 0.3423, D_B_loss: 0.1842, G_A_loss: 0.2813, G_B_loss: 0.0653\n",
            "Epoch [2/70], Step [221/1231], D_A_loss: 0.1729, D_B_loss: 0.0893, G_A_loss: 0.4170, G_B_loss: 0.2636\n",
            "Epoch [2/70], Step [231/1231], D_A_loss: 0.2132, D_B_loss: 0.1783, G_A_loss: 0.3325, G_B_loss: 0.1745\n",
            "Epoch [2/70], Step [241/1231], D_A_loss: 0.1341, D_B_loss: 0.1482, G_A_loss: 0.5639, G_B_loss: 0.7026\n",
            "Epoch [2/70], Step [251/1231], D_A_loss: 0.0484, D_B_loss: 0.1151, G_A_loss: 0.3633, G_B_loss: 0.3903\n",
            "Epoch [2/70], Step [261/1231], D_A_loss: 0.0956, D_B_loss: 0.2222, G_A_loss: 0.2904, G_B_loss: 0.4758\n",
            "Epoch [2/70], Step [271/1231], D_A_loss: 0.1614, D_B_loss: 0.1213, G_A_loss: 0.3446, G_B_loss: 0.2505\n",
            "Epoch [2/70], Step [281/1231], D_A_loss: 0.1202, D_B_loss: 0.1215, G_A_loss: 0.0530, G_B_loss: 0.3839\n",
            "Epoch [2/70], Step [291/1231], D_A_loss: 0.0397, D_B_loss: 0.1586, G_A_loss: 0.6933, G_B_loss: 0.6549\n",
            "Epoch [2/70], Step [301/1231], D_A_loss: 0.1135, D_B_loss: 0.2734, G_A_loss: 0.6247, G_B_loss: 0.5476\n",
            "Epoch [2/70], Step [311/1231], D_A_loss: 0.2748, D_B_loss: 0.3102, G_A_loss: 0.6748, G_B_loss: 0.1021\n",
            "Epoch [2/70], Step [321/1231], D_A_loss: 0.0333, D_B_loss: 0.1887, G_A_loss: 0.6814, G_B_loss: 0.4058\n",
            "Epoch [2/70], Step [331/1231], D_A_loss: 0.2038, D_B_loss: 0.1896, G_A_loss: 0.2354, G_B_loss: 0.4737\n",
            "Epoch [2/70], Step [341/1231], D_A_loss: 0.1177, D_B_loss: 0.2318, G_A_loss: 0.3783, G_B_loss: 0.2354\n",
            "Epoch [2/70], Step [351/1231], D_A_loss: 0.3163, D_B_loss: 0.0645, G_A_loss: 0.2564, G_B_loss: 0.6740\n",
            "Epoch [2/70], Step [361/1231], D_A_loss: 0.1085, D_B_loss: 0.2832, G_A_loss: 0.1100, G_B_loss: 0.2757\n",
            "Epoch [2/70], Step [371/1231], D_A_loss: 0.0409, D_B_loss: 0.0891, G_A_loss: 0.4074, G_B_loss: 0.6534\n",
            "Epoch [2/70], Step [381/1231], D_A_loss: 0.2180, D_B_loss: 0.2181, G_A_loss: 0.6063, G_B_loss: 0.7215\n",
            "Epoch [2/70], Step [391/1231], D_A_loss: 0.1123, D_B_loss: 0.1226, G_A_loss: 0.2290, G_B_loss: 0.3568\n",
            "Epoch [2/70], Step [401/1231], D_A_loss: 0.1686, D_B_loss: 0.0389, G_A_loss: 0.3698, G_B_loss: 0.4842\n",
            "Epoch [2/70], Step [411/1231], D_A_loss: 0.1347, D_B_loss: 0.3395, G_A_loss: 0.1529, G_B_loss: 0.3651\n",
            "Epoch [2/70], Step [421/1231], D_A_loss: 0.1151, D_B_loss: 0.1125, G_A_loss: 0.4631, G_B_loss: 0.1948\n",
            "Epoch [2/70], Step [431/1231], D_A_loss: 0.3781, D_B_loss: 0.2237, G_A_loss: 0.5733, G_B_loss: 0.1199\n",
            "Epoch [2/70], Step [441/1231], D_A_loss: 0.0840, D_B_loss: 0.3366, G_A_loss: 0.4696, G_B_loss: 0.5275\n",
            "Epoch [2/70], Step [451/1231], D_A_loss: 0.2071, D_B_loss: 0.2355, G_A_loss: 0.0765, G_B_loss: 0.4007\n",
            "Epoch [2/70], Step [461/1231], D_A_loss: 0.0905, D_B_loss: 0.2505, G_A_loss: 0.2771, G_B_loss: 0.6956\n",
            "Epoch [2/70], Step [471/1231], D_A_loss: 0.1056, D_B_loss: 0.2475, G_A_loss: 0.4878, G_B_loss: 0.0803\n",
            "Epoch [2/70], Step [481/1231], D_A_loss: 0.2386, D_B_loss: 0.1875, G_A_loss: 0.2331, G_B_loss: 0.7006\n",
            "Epoch [2/70], Step [491/1231], D_A_loss: 0.1094, D_B_loss: 0.1928, G_A_loss: 0.2043, G_B_loss: 0.2328\n",
            "Epoch [2/70], Step [501/1231], D_A_loss: 0.0812, D_B_loss: 0.2436, G_A_loss: 0.3635, G_B_loss: 0.7344\n",
            "Epoch [2/70], Step [511/1231], D_A_loss: 0.2970, D_B_loss: 0.0933, G_A_loss: 0.3996, G_B_loss: 0.1015\n",
            "Epoch [2/70], Step [521/1231], D_A_loss: 0.3187, D_B_loss: 0.1067, G_A_loss: 0.1557, G_B_loss: 0.7771\n",
            "Epoch [2/70], Step [531/1231], D_A_loss: 0.1369, D_B_loss: 0.0695, G_A_loss: 0.5063, G_B_loss: 0.5376\n",
            "Epoch [2/70], Step [541/1231], D_A_loss: 0.4301, D_B_loss: 0.2513, G_A_loss: 0.1968, G_B_loss: 1.2110\n",
            "Epoch [2/70], Step [551/1231], D_A_loss: 0.0664, D_B_loss: 0.0384, G_A_loss: 0.3249, G_B_loss: 0.5314\n",
            "Epoch [2/70], Step [561/1231], D_A_loss: 0.0427, D_B_loss: 0.1715, G_A_loss: 0.3916, G_B_loss: 0.1881\n",
            "Epoch [2/70], Step [571/1231], D_A_loss: 0.2337, D_B_loss: 0.4728, G_A_loss: 0.1003, G_B_loss: 0.4927\n",
            "Epoch [2/70], Step [581/1231], D_A_loss: 0.0456, D_B_loss: 0.0945, G_A_loss: 0.3665, G_B_loss: 0.3022\n",
            "Epoch [2/70], Step [591/1231], D_A_loss: 0.0443, D_B_loss: 0.1165, G_A_loss: 0.2434, G_B_loss: 0.4264\n",
            "Epoch [2/70], Step [601/1231], D_A_loss: 0.1221, D_B_loss: 0.1168, G_A_loss: 0.5965, G_B_loss: 0.4794\n",
            "Epoch [2/70], Step [611/1231], D_A_loss: 0.2212, D_B_loss: 0.2649, G_A_loss: 0.1617, G_B_loss: 0.4071\n",
            "Epoch [2/70], Step [621/1231], D_A_loss: 0.2652, D_B_loss: 0.2605, G_A_loss: 0.1485, G_B_loss: 0.5777\n",
            "Epoch [2/70], Step [631/1231], D_A_loss: 0.4297, D_B_loss: 0.1660, G_A_loss: 0.2467, G_B_loss: 0.6289\n",
            "Epoch [2/70], Step [641/1231], D_A_loss: 0.0582, D_B_loss: 0.3149, G_A_loss: 0.3098, G_B_loss: 0.1480\n",
            "Epoch [2/70], Step [651/1231], D_A_loss: 0.0773, D_B_loss: 0.0749, G_A_loss: 0.3682, G_B_loss: 0.2754\n",
            "Epoch [2/70], Step [661/1231], D_A_loss: 0.0436, D_B_loss: 0.2634, G_A_loss: 0.1521, G_B_loss: 0.0756\n",
            "Epoch [2/70], Step [671/1231], D_A_loss: 0.1505, D_B_loss: 0.1383, G_A_loss: 0.0757, G_B_loss: 0.5838\n",
            "Epoch [2/70], Step [681/1231], D_A_loss: 0.2384, D_B_loss: 0.0325, G_A_loss: 0.3002, G_B_loss: 0.2202\n",
            "Epoch [2/70], Step [691/1231], D_A_loss: 0.3287, D_B_loss: 0.1233, G_A_loss: 0.4073, G_B_loss: 0.4651\n",
            "Epoch [2/70], Step [701/1231], D_A_loss: 0.1572, D_B_loss: 0.2088, G_A_loss: 0.3978, G_B_loss: 0.2313\n",
            "Epoch [2/70], Step [711/1231], D_A_loss: 0.0962, D_B_loss: 0.2449, G_A_loss: 0.1954, G_B_loss: 0.4687\n",
            "Epoch [2/70], Step [721/1231], D_A_loss: 0.1516, D_B_loss: 0.1375, G_A_loss: 0.6484, G_B_loss: 0.1150\n",
            "Epoch [2/70], Step [731/1231], D_A_loss: 0.1215, D_B_loss: 0.1227, G_A_loss: 0.7585, G_B_loss: 0.6333\n",
            "Epoch [2/70], Step [741/1231], D_A_loss: 0.1508, D_B_loss: 0.1827, G_A_loss: 0.3532, G_B_loss: 0.2592\n",
            "Epoch [2/70], Step [751/1231], D_A_loss: 0.0967, D_B_loss: 0.1650, G_A_loss: 0.7065, G_B_loss: 0.4162\n",
            "Epoch [2/70], Step [761/1231], D_A_loss: 0.1033, D_B_loss: 0.3112, G_A_loss: 0.0839, G_B_loss: 0.4500\n",
            "Epoch [2/70], Step [771/1231], D_A_loss: 0.2042, D_B_loss: 0.1843, G_A_loss: 0.2364, G_B_loss: 0.5396\n",
            "Epoch [2/70], Step [781/1231], D_A_loss: 0.1538, D_B_loss: 0.1726, G_A_loss: 0.4227, G_B_loss: 0.2975\n",
            "Epoch [2/70], Step [791/1231], D_A_loss: 0.0583, D_B_loss: 0.1911, G_A_loss: 0.3234, G_B_loss: 0.1650\n",
            "Epoch [2/70], Step [801/1231], D_A_loss: 0.0696, D_B_loss: 0.0760, G_A_loss: 0.2174, G_B_loss: 0.4040\n",
            "Epoch [2/70], Step [811/1231], D_A_loss: 0.2615, D_B_loss: 0.2491, G_A_loss: 0.2284, G_B_loss: 0.1759\n",
            "Epoch [2/70], Step [821/1231], D_A_loss: 0.1053, D_B_loss: 0.1384, G_A_loss: 0.4874, G_B_loss: 1.1340\n",
            "Epoch [2/70], Step [831/1231], D_A_loss: 0.1112, D_B_loss: 0.1435, G_A_loss: 0.5318, G_B_loss: 0.2748\n",
            "Epoch [2/70], Step [841/1231], D_A_loss: 0.2426, D_B_loss: 0.2079, G_A_loss: 0.2600, G_B_loss: 0.2382\n",
            "Epoch [2/70], Step [851/1231], D_A_loss: 0.0800, D_B_loss: 0.0325, G_A_loss: 0.5860, G_B_loss: 0.4688\n",
            "Epoch [2/70], Step [861/1231], D_A_loss: 0.2240, D_B_loss: 0.4091, G_A_loss: 0.0359, G_B_loss: 0.6315\n",
            "Epoch [2/70], Step [871/1231], D_A_loss: 0.1382, D_B_loss: 0.1286, G_A_loss: 0.1220, G_B_loss: 0.3740\n",
            "Epoch [2/70], Step [881/1231], D_A_loss: 0.1798, D_B_loss: 0.2657, G_A_loss: 0.5210, G_B_loss: 0.2974\n",
            "Epoch [2/70], Step [891/1231], D_A_loss: 0.1385, D_B_loss: 0.1011, G_A_loss: 0.4239, G_B_loss: 0.3021\n",
            "Epoch [2/70], Step [901/1231], D_A_loss: 0.5515, D_B_loss: 0.0537, G_A_loss: 0.3282, G_B_loss: 1.2363\n",
            "Epoch [2/70], Step [911/1231], D_A_loss: 0.1426, D_B_loss: 0.3030, G_A_loss: 0.4818, G_B_loss: 0.4866\n",
            "Epoch [2/70], Step [921/1231], D_A_loss: 0.1274, D_B_loss: 0.0809, G_A_loss: 0.1491, G_B_loss: 0.3491\n",
            "Epoch [2/70], Step [931/1231], D_A_loss: 0.2040, D_B_loss: 0.2701, G_A_loss: 0.0990, G_B_loss: 0.4332\n",
            "Epoch [2/70], Step [941/1231], D_A_loss: 0.2559, D_B_loss: 0.1486, G_A_loss: 0.0957, G_B_loss: 0.3968\n",
            "Epoch [2/70], Step [951/1231], D_A_loss: 0.1652, D_B_loss: 0.3756, G_A_loss: 0.0554, G_B_loss: 0.2842\n",
            "Epoch [2/70], Step [961/1231], D_A_loss: 0.0920, D_B_loss: 0.0893, G_A_loss: 0.2997, G_B_loss: 0.2852\n",
            "Epoch [3/70], Step [1/1231], D_A_loss: 0.1663, D_B_loss: 0.1384, G_A_loss: 0.2868, G_B_loss: 0.3450\n",
            "Epoch [3/70], Step [11/1231], D_A_loss: 0.2005, D_B_loss: 0.2129, G_A_loss: 0.6694, G_B_loss: 0.2695\n",
            "Epoch [3/70], Step [21/1231], D_A_loss: 0.1389, D_B_loss: 0.1707, G_A_loss: 0.5936, G_B_loss: 0.3524\n",
            "Epoch [3/70], Step [31/1231], D_A_loss: 0.3271, D_B_loss: 0.1170, G_A_loss: 0.4256, G_B_loss: 0.2597\n",
            "Epoch [3/70], Step [41/1231], D_A_loss: 0.1933, D_B_loss: 0.0295, G_A_loss: 0.3875, G_B_loss: 0.1698\n",
            "Epoch [3/70], Step [51/1231], D_A_loss: 0.0194, D_B_loss: 0.3485, G_A_loss: 0.1919, G_B_loss: 0.3658\n",
            "Epoch [3/70], Step [61/1231], D_A_loss: 0.1529, D_B_loss: 0.2337, G_A_loss: 0.1313, G_B_loss: 0.2290\n",
            "Epoch [3/70], Step [71/1231], D_A_loss: 0.0604, D_B_loss: 0.1710, G_A_loss: 0.2851, G_B_loss: 0.3237\n",
            "Epoch [3/70], Step [81/1231], D_A_loss: 0.1507, D_B_loss: 0.0257, G_A_loss: 0.2136, G_B_loss: 0.4105\n",
            "Epoch [3/70], Step [91/1231], D_A_loss: 0.0706, D_B_loss: 0.2046, G_A_loss: 0.3921, G_B_loss: 0.6480\n",
            "Epoch [3/70], Step [101/1231], D_A_loss: 0.0804, D_B_loss: 0.0763, G_A_loss: 0.4742, G_B_loss: 0.4241\n",
            "Epoch [3/70], Step [111/1231], D_A_loss: 0.2802, D_B_loss: 0.1893, G_A_loss: 0.2232, G_B_loss: 0.1052\n",
            "Epoch [3/70], Step [121/1231], D_A_loss: 0.0839, D_B_loss: 0.1385, G_A_loss: 0.4627, G_B_loss: 0.2604\n",
            "Epoch [3/70], Step [131/1231], D_A_loss: 0.0913, D_B_loss: 0.1664, G_A_loss: 0.2515, G_B_loss: 0.2570\n",
            "Epoch [3/70], Step [141/1231], D_A_loss: 0.1212, D_B_loss: 0.3304, G_A_loss: 0.3847, G_B_loss: 0.1506\n",
            "Epoch [3/70], Step [151/1231], D_A_loss: 0.1391, D_B_loss: 0.2287, G_A_loss: 0.1826, G_B_loss: 0.6069\n",
            "Epoch [3/70], Step [161/1231], D_A_loss: 0.1702, D_B_loss: 0.2035, G_A_loss: 0.4141, G_B_loss: 0.3908\n",
            "Epoch [3/70], Step [171/1231], D_A_loss: 0.1275, D_B_loss: 0.0913, G_A_loss: 0.1047, G_B_loss: 0.5969\n",
            "Epoch [3/70], Step [181/1231], D_A_loss: 0.2736, D_B_loss: 0.2621, G_A_loss: 0.1479, G_B_loss: 0.1461\n",
            "Epoch [3/70], Step [191/1231], D_A_loss: 0.1718, D_B_loss: 0.2867, G_A_loss: 0.5987, G_B_loss: 0.5746\n",
            "Epoch [3/70], Step [201/1231], D_A_loss: 0.1464, D_B_loss: 0.4085, G_A_loss: 0.0386, G_B_loss: 0.4688\n",
            "Epoch [3/70], Step [211/1231], D_A_loss: 0.1085, D_B_loss: 0.0381, G_A_loss: 0.1400, G_B_loss: 0.2216\n",
            "Epoch [3/70], Step [221/1231], D_A_loss: 0.1668, D_B_loss: 0.1865, G_A_loss: 0.3947, G_B_loss: 0.5138\n",
            "Epoch [3/70], Step [231/1231], D_A_loss: 0.1566, D_B_loss: 0.0275, G_A_loss: 0.2963, G_B_loss: 0.2781\n",
            "Epoch [3/70], Step [241/1231], D_A_loss: 0.2663, D_B_loss: 0.0949, G_A_loss: 0.6619, G_B_loss: 0.6877\n",
            "Epoch [3/70], Step [251/1231], D_A_loss: 0.1440, D_B_loss: 0.0775, G_A_loss: 0.1416, G_B_loss: 0.3394\n",
            "Epoch [3/70], Step [261/1231], D_A_loss: 0.2105, D_B_loss: 0.0782, G_A_loss: 0.3814, G_B_loss: 0.4892\n",
            "Epoch [3/70], Step [271/1231], D_A_loss: 0.1230, D_B_loss: 0.2122, G_A_loss: 0.3017, G_B_loss: 0.7774\n",
            "Epoch [3/70], Step [281/1231], D_A_loss: 0.0834, D_B_loss: 0.0775, G_A_loss: 0.5385, G_B_loss: 0.3777\n",
            "Epoch [3/70], Step [291/1231], D_A_loss: 0.1186, D_B_loss: 0.0280, G_A_loss: 0.2227, G_B_loss: 0.2707\n",
            "Epoch [3/70], Step [301/1231], D_A_loss: 0.2390, D_B_loss: 0.3389, G_A_loss: 0.0924, G_B_loss: 0.7183\n",
            "Epoch [3/70], Step [311/1231], D_A_loss: 0.0507, D_B_loss: 0.0943, G_A_loss: 0.3624, G_B_loss: 0.3408\n",
            "Epoch [3/70], Step [321/1231], D_A_loss: 0.3079, D_B_loss: 0.3375, G_A_loss: 0.0863, G_B_loss: 0.1888\n",
            "Epoch [3/70], Step [331/1231], D_A_loss: 0.1618, D_B_loss: 0.2375, G_A_loss: 0.0757, G_B_loss: 1.1770\n",
            "Epoch [3/70], Step [341/1231], D_A_loss: 0.2871, D_B_loss: 0.1088, G_A_loss: 0.4225, G_B_loss: 0.1212\n",
            "Epoch [3/70], Step [351/1231], D_A_loss: 0.0861, D_B_loss: 0.1928, G_A_loss: 0.2711, G_B_loss: 0.4248\n",
            "Epoch [3/70], Step [361/1231], D_A_loss: 0.2424, D_B_loss: 0.2426, G_A_loss: 0.9236, G_B_loss: 0.1496\n",
            "Epoch [3/70], Step [371/1231], D_A_loss: 0.3483, D_B_loss: 0.1867, G_A_loss: 0.3630, G_B_loss: 0.6471\n",
            "Epoch [3/70], Step [381/1231], D_A_loss: 0.1727, D_B_loss: 0.2125, G_A_loss: 0.1626, G_B_loss: 0.2386\n",
            "Epoch [3/70], Step [391/1231], D_A_loss: 0.4071, D_B_loss: 0.1324, G_A_loss: 0.4335, G_B_loss: 0.0316\n",
            "Epoch [3/70], Step [401/1231], D_A_loss: 0.1347, D_B_loss: 0.2046, G_A_loss: 0.4043, G_B_loss: 0.5867\n",
            "Epoch [3/70], Step [411/1231], D_A_loss: 0.1347, D_B_loss: 0.0828, G_A_loss: 0.1225, G_B_loss: 0.6369\n",
            "Epoch [3/70], Step [421/1231], D_A_loss: 0.1906, D_B_loss: 0.1147, G_A_loss: 0.5962, G_B_loss: 0.1176\n",
            "Epoch [3/70], Step [431/1231], D_A_loss: 0.1566, D_B_loss: 0.3083, G_A_loss: 0.1021, G_B_loss: 0.5024\n",
            "Epoch [3/70], Step [441/1231], D_A_loss: 0.1357, D_B_loss: 0.1497, G_A_loss: 0.3558, G_B_loss: 0.3384\n",
            "Epoch [3/70], Step [451/1231], D_A_loss: 0.0425, D_B_loss: 0.0609, G_A_loss: 0.0815, G_B_loss: 0.2896\n",
            "Epoch [3/70], Step [461/1231], D_A_loss: 0.1724, D_B_loss: 0.1818, G_A_loss: 0.5064, G_B_loss: 0.7099\n",
            "Epoch [3/70], Step [471/1231], D_A_loss: 0.1271, D_B_loss: 0.0756, G_A_loss: 0.2555, G_B_loss: 0.4568\n",
            "Epoch [3/70], Step [481/1231], D_A_loss: 0.0909, D_B_loss: 0.1091, G_A_loss: 0.4177, G_B_loss: 0.7798\n",
            "Epoch [3/70], Step [491/1231], D_A_loss: 0.1799, D_B_loss: 0.1822, G_A_loss: 0.3284, G_B_loss: 0.2796\n",
            "Epoch [3/70], Step [501/1231], D_A_loss: 0.1983, D_B_loss: 0.3323, G_A_loss: 0.0769, G_B_loss: 0.2579\n",
            "Epoch [3/70], Step [511/1231], D_A_loss: 0.1497, D_B_loss: 0.2267, G_A_loss: 0.7979, G_B_loss: 0.2740\n",
            "Epoch [3/70], Step [521/1231], D_A_loss: 0.1769, D_B_loss: 0.1993, G_A_loss: 0.3883, G_B_loss: 0.4564\n",
            "Epoch [3/70], Step [531/1231], D_A_loss: 0.0832, D_B_loss: 0.1606, G_A_loss: 0.5269, G_B_loss: 0.3975\n",
            "Epoch [3/70], Step [541/1231], D_A_loss: 0.2013, D_B_loss: 0.2485, G_A_loss: 0.4796, G_B_loss: 0.3583\n",
            "Epoch [3/70], Step [551/1231], D_A_loss: 0.3018, D_B_loss: 0.2364, G_A_loss: 0.2651, G_B_loss: 0.0802\n",
            "Epoch [3/70], Step [561/1231], D_A_loss: 0.2367, D_B_loss: 0.1098, G_A_loss: 0.3068, G_B_loss: 0.1922\n",
            "Epoch [3/70], Step [571/1231], D_A_loss: 0.2627, D_B_loss: 0.1317, G_A_loss: 0.9072, G_B_loss: 0.3461\n",
            "Epoch [3/70], Step [581/1231], D_A_loss: 0.0849, D_B_loss: 0.0516, G_A_loss: 0.7846, G_B_loss: 0.1434\n",
            "Epoch [3/70], Step [591/1231], D_A_loss: 0.0536, D_B_loss: 0.4226, G_A_loss: 0.1399, G_B_loss: 0.0718\n",
            "Epoch [3/70], Step [601/1231], D_A_loss: 0.1015, D_B_loss: 0.2472, G_A_loss: 0.2221, G_B_loss: 0.8349\n",
            "Epoch [3/70], Step [611/1231], D_A_loss: 0.1348, D_B_loss: 0.0960, G_A_loss: 0.2510, G_B_loss: 0.4877\n",
            "Epoch [3/70], Step [621/1231], D_A_loss: 0.1529, D_B_loss: 0.0367, G_A_loss: 0.1931, G_B_loss: 0.5606\n",
            "Epoch [3/70], Step [631/1231], D_A_loss: 0.2122, D_B_loss: 0.1296, G_A_loss: 0.2915, G_B_loss: 0.5733\n",
            "Epoch [3/70], Step [641/1231], D_A_loss: 0.0649, D_B_loss: 0.2124, G_A_loss: 0.2169, G_B_loss: 0.1418\n",
            "Epoch [3/70], Step [651/1231], D_A_loss: 0.4218, D_B_loss: 0.2428, G_A_loss: 0.3155, G_B_loss: 0.9400\n",
            "Epoch [3/70], Step [661/1231], D_A_loss: 0.1011, D_B_loss: 0.1324, G_A_loss: 0.2937, G_B_loss: 0.5723\n",
            "Epoch [3/70], Step [671/1231], D_A_loss: 0.2397, D_B_loss: 0.2216, G_A_loss: 0.4043, G_B_loss: 0.2310\n",
            "Epoch [3/70], Step [681/1231], D_A_loss: 0.1511, D_B_loss: 0.2265, G_A_loss: 0.2188, G_B_loss: 0.2719\n",
            "Epoch [3/70], Step [691/1231], D_A_loss: 0.0483, D_B_loss: 0.0383, G_A_loss: 0.2252, G_B_loss: 0.3300\n",
            "Epoch [3/70], Step [701/1231], D_A_loss: 0.2354, D_B_loss: 0.0873, G_A_loss: 0.9516, G_B_loss: 0.1382\n",
            "Epoch [3/70], Step [711/1231], D_A_loss: 0.1053, D_B_loss: 0.1206, G_A_loss: 0.5665, G_B_loss: 0.2651\n",
            "Epoch [3/70], Step [721/1231], D_A_loss: 0.2439, D_B_loss: 0.1836, G_A_loss: 0.6564, G_B_loss: 0.1300\n",
            "Epoch [3/70], Step [731/1231], D_A_loss: 0.2326, D_B_loss: 0.1839, G_A_loss: 0.1698, G_B_loss: 0.6315\n",
            "Epoch [3/70], Step [741/1231], D_A_loss: 0.2222, D_B_loss: 0.1276, G_A_loss: 0.4260, G_B_loss: 0.4235\n",
            "Epoch [3/70], Step [751/1231], D_A_loss: 0.0391, D_B_loss: 0.0960, G_A_loss: 0.4348, G_B_loss: 0.4184\n",
            "Epoch [3/70], Step [761/1231], D_A_loss: 0.1821, D_B_loss: 0.0629, G_A_loss: 0.7474, G_B_loss: 0.3086\n",
            "Epoch [3/70], Step [771/1231], D_A_loss: 0.1343, D_B_loss: 0.1128, G_A_loss: 0.4502, G_B_loss: 0.5481\n",
            "Epoch [3/70], Step [781/1231], D_A_loss: 0.0721, D_B_loss: 0.1903, G_A_loss: 0.9475, G_B_loss: 0.3706\n",
            "Epoch [3/70], Step [791/1231], D_A_loss: 0.2285, D_B_loss: 0.0678, G_A_loss: 0.3570, G_B_loss: 1.0549\n",
            "Epoch [3/70], Step [801/1231], D_A_loss: 0.0719, D_B_loss: 0.4303, G_A_loss: 0.2654, G_B_loss: 0.2763\n",
            "Epoch [3/70], Step [811/1231], D_A_loss: 0.0877, D_B_loss: 0.3107, G_A_loss: 0.5906, G_B_loss: 0.3644\n",
            "Epoch [3/70], Step [821/1231], D_A_loss: 0.3375, D_B_loss: 0.2708, G_A_loss: 0.3775, G_B_loss: 0.0599\n",
            "Epoch [3/70], Step [831/1231], D_A_loss: 0.1663, D_B_loss: 0.1070, G_A_loss: 0.3423, G_B_loss: 0.5567\n",
            "Epoch [3/70], Step [841/1231], D_A_loss: 0.1375, D_B_loss: 0.1222, G_A_loss: 0.2443, G_B_loss: 0.4626\n",
            "Epoch [3/70], Step [851/1231], D_A_loss: 0.2082, D_B_loss: 0.2069, G_A_loss: 0.1614, G_B_loss: 0.4892\n",
            "Epoch [3/70], Step [861/1231], D_A_loss: 0.1267, D_B_loss: 0.1839, G_A_loss: 0.3504, G_B_loss: 0.4872\n",
            "Epoch [3/70], Step [871/1231], D_A_loss: 0.3242, D_B_loss: 0.0279, G_A_loss: 0.5744, G_B_loss: 0.9180\n",
            "Epoch [3/70], Step [881/1231], D_A_loss: 0.1767, D_B_loss: 0.3041, G_A_loss: 0.1037, G_B_loss: 0.3185\n",
            "Epoch [3/70], Step [891/1231], D_A_loss: 0.0956, D_B_loss: 0.1721, G_A_loss: 0.2085, G_B_loss: 0.5678\n",
            "Epoch [3/70], Step [901/1231], D_A_loss: 0.0653, D_B_loss: 0.1978, G_A_loss: 0.1983, G_B_loss: 0.5384\n",
            "Epoch [3/70], Step [911/1231], D_A_loss: 0.1127, D_B_loss: 0.1336, G_A_loss: 0.3309, G_B_loss: 0.1448\n",
            "Epoch [3/70], Step [921/1231], D_A_loss: 0.2503, D_B_loss: 0.0543, G_A_loss: 0.7636, G_B_loss: 0.2439\n",
            "Epoch [3/70], Step [931/1231], D_A_loss: 0.1602, D_B_loss: 0.2325, G_A_loss: 0.1796, G_B_loss: 0.2267\n",
            "Epoch [3/70], Step [941/1231], D_A_loss: 0.2083, D_B_loss: 0.2279, G_A_loss: 0.5862, G_B_loss: 0.4862\n",
            "Epoch [3/70], Step [951/1231], D_A_loss: 0.1975, D_B_loss: 0.0523, G_A_loss: 0.1361, G_B_loss: 0.5696\n",
            "Epoch [3/70], Step [961/1231], D_A_loss: 0.1317, D_B_loss: 0.1847, G_A_loss: 0.3438, G_B_loss: 0.5940\n",
            "Epoch [4/70], Step [1/1231], D_A_loss: 0.1058, D_B_loss: 0.2042, G_A_loss: 0.1647, G_B_loss: 0.6761\n",
            "Epoch [4/70], Step [11/1231], D_A_loss: 0.0375, D_B_loss: 0.2456, G_A_loss: 0.1373, G_B_loss: 0.2333\n",
            "Epoch [4/70], Step [21/1231], D_A_loss: 0.1104, D_B_loss: 0.0367, G_A_loss: 0.6581, G_B_loss: 0.3269\n",
            "Epoch [4/70], Step [31/1231], D_A_loss: 0.1096, D_B_loss: 0.2389, G_A_loss: 0.1348, G_B_loss: 0.3825\n",
            "Epoch [4/70], Step [41/1231], D_A_loss: 0.2407, D_B_loss: 0.1558, G_A_loss: 0.2389, G_B_loss: 0.5831\n",
            "Epoch [4/70], Step [51/1231], D_A_loss: 0.0479, D_B_loss: 0.3605, G_A_loss: 0.1816, G_B_loss: 0.1153\n",
            "Epoch [4/70], Step [61/1231], D_A_loss: 0.2328, D_B_loss: 0.1537, G_A_loss: 0.4002, G_B_loss: 0.5110\n",
            "Epoch [4/70], Step [71/1231], D_A_loss: 0.0943, D_B_loss: 0.1324, G_A_loss: 0.3986, G_B_loss: 0.5614\n",
            "Epoch [4/70], Step [81/1231], D_A_loss: 0.0331, D_B_loss: 0.1544, G_A_loss: 0.2519, G_B_loss: 0.3082\n",
            "Epoch [4/70], Step [91/1231], D_A_loss: 0.3333, D_B_loss: 0.2952, G_A_loss: 0.3736, G_B_loss: 0.0702\n",
            "Epoch [4/70], Step [101/1231], D_A_loss: 0.0771, D_B_loss: 0.2137, G_A_loss: 0.1088, G_B_loss: 0.2101\n",
            "Epoch [4/70], Step [111/1231], D_A_loss: 0.1623, D_B_loss: 0.0863, G_A_loss: 0.2729, G_B_loss: 0.4203\n",
            "Epoch [4/70], Step [121/1231], D_A_loss: 0.0659, D_B_loss: 0.2296, G_A_loss: 0.4479, G_B_loss: 0.5305\n",
            "Epoch [4/70], Step [131/1231], D_A_loss: 0.1667, D_B_loss: 0.1622, G_A_loss: 0.2421, G_B_loss: 0.2712\n",
            "Epoch [4/70], Step [141/1231], D_A_loss: 0.0900, D_B_loss: 0.0683, G_A_loss: 0.4852, G_B_loss: 0.3693\n",
            "Epoch [4/70], Step [151/1231], D_A_loss: 0.2474, D_B_loss: 0.2078, G_A_loss: 0.1884, G_B_loss: 0.1323\n",
            "Epoch [4/70], Step [161/1231], D_A_loss: 0.2208, D_B_loss: 0.1014, G_A_loss: 0.1146, G_B_loss: 0.3386\n",
            "Epoch [4/70], Step [171/1231], D_A_loss: 0.0661, D_B_loss: 0.1766, G_A_loss: 0.2900, G_B_loss: 0.4816\n",
            "Epoch [4/70], Step [181/1231], D_A_loss: 0.3066, D_B_loss: 0.1604, G_A_loss: 0.1274, G_B_loss: 0.5717\n",
            "Epoch [4/70], Step [191/1231], D_A_loss: 0.2618, D_B_loss: 0.2146, G_A_loss: 0.1776, G_B_loss: 0.2908\n",
            "Epoch [4/70], Step [201/1231], D_A_loss: 0.1843, D_B_loss: 0.0556, G_A_loss: 0.3526, G_B_loss: 0.3253\n",
            "Epoch [4/70], Step [211/1231], D_A_loss: 0.0969, D_B_loss: 0.1112, G_A_loss: 0.6063, G_B_loss: 0.8049\n",
            "Epoch [4/70], Step [221/1231], D_A_loss: 0.2272, D_B_loss: 0.2604, G_A_loss: 0.1095, G_B_loss: 0.3972\n",
            "Epoch [4/70], Step [231/1231], D_A_loss: 0.2113, D_B_loss: 0.1379, G_A_loss: 0.7222, G_B_loss: 0.2497\n",
            "Epoch [4/70], Step [241/1231], D_A_loss: 0.0883, D_B_loss: 0.1376, G_A_loss: 0.4794, G_B_loss: 0.6268\n",
            "Epoch [4/70], Step [251/1231], D_A_loss: 0.1903, D_B_loss: 0.1256, G_A_loss: 0.2374, G_B_loss: 0.7896\n",
            "Epoch [4/70], Step [261/1231], D_A_loss: 0.1625, D_B_loss: 0.2006, G_A_loss: 0.6422, G_B_loss: 0.1021\n",
            "Epoch [4/70], Step [271/1231], D_A_loss: 0.0917, D_B_loss: 0.0387, G_A_loss: 0.6015, G_B_loss: 0.4081\n",
            "Epoch [4/70], Step [281/1231], D_A_loss: 0.0496, D_B_loss: 0.1002, G_A_loss: 0.5770, G_B_loss: 0.6008\n",
            "Epoch [4/70], Step [291/1231], D_A_loss: 0.1442, D_B_loss: 0.0901, G_A_loss: 0.4358, G_B_loss: 0.4444\n",
            "Epoch [4/70], Step [301/1231], D_A_loss: 0.1187, D_B_loss: 0.3647, G_A_loss: 0.2259, G_B_loss: 0.0874\n",
            "Epoch [4/70], Step [311/1231], D_A_loss: 0.2105, D_B_loss: 0.3593, G_A_loss: 0.0518, G_B_loss: 0.4662\n",
            "Epoch [4/70], Step [321/1231], D_A_loss: 0.1142, D_B_loss: 0.1577, G_A_loss: 0.2863, G_B_loss: 0.1448\n",
            "Epoch [4/70], Step [331/1231], D_A_loss: 0.1349, D_B_loss: 0.2549, G_A_loss: 0.5262, G_B_loss: 0.2931\n",
            "Epoch [4/70], Step [341/1231], D_A_loss: 0.0370, D_B_loss: 0.1079, G_A_loss: 0.3911, G_B_loss: 0.2249\n",
            "Epoch [4/70], Step [351/1231], D_A_loss: 0.1227, D_B_loss: 0.0539, G_A_loss: 0.5417, G_B_loss: 0.2746\n",
            "Epoch [4/70], Step [361/1231], D_A_loss: 0.1115, D_B_loss: 0.0545, G_A_loss: 0.4195, G_B_loss: 0.5398\n",
            "Epoch [4/70], Step [371/1231], D_A_loss: 0.0505, D_B_loss: 0.1790, G_A_loss: 0.2133, G_B_loss: 0.4553\n",
            "Epoch [4/70], Step [381/1231], D_A_loss: 0.0784, D_B_loss: 0.1118, G_A_loss: 0.4766, G_B_loss: 0.1246\n",
            "Epoch [4/70], Step [391/1231], D_A_loss: 0.1514, D_B_loss: 0.0673, G_A_loss: 0.3594, G_B_loss: 0.0651\n",
            "Epoch [4/70], Step [401/1231], D_A_loss: 0.1494, D_B_loss: 0.2448, G_A_loss: 0.4648, G_B_loss: 0.2359\n",
            "Epoch [4/70], Step [411/1231], D_A_loss: 0.3221, D_B_loss: 0.1112, G_A_loss: 0.2354, G_B_loss: 0.4646\n",
            "Epoch [4/70], Step [421/1231], D_A_loss: 0.2407, D_B_loss: 0.2869, G_A_loss: 0.1533, G_B_loss: 0.2306\n",
            "Epoch [4/70], Step [431/1231], D_A_loss: 0.1854, D_B_loss: 0.1075, G_A_loss: 0.3682, G_B_loss: 0.2508\n",
            "Epoch [4/70], Step [441/1231], D_A_loss: 0.0809, D_B_loss: 0.2346, G_A_loss: 0.5165, G_B_loss: 0.5824\n",
            "Epoch [4/70], Step [451/1231], D_A_loss: 0.1347, D_B_loss: 0.0585, G_A_loss: 0.2313, G_B_loss: 0.3020\n",
            "Epoch [4/70], Step [461/1231], D_A_loss: 0.1291, D_B_loss: 0.2621, G_A_loss: 0.4665, G_B_loss: 0.1262\n",
            "Epoch [4/70], Step [471/1231], D_A_loss: 0.1440, D_B_loss: 0.1606, G_A_loss: 0.2331, G_B_loss: 0.5311\n",
            "Epoch [4/70], Step [481/1231], D_A_loss: 0.2728, D_B_loss: 0.0199, G_A_loss: 0.6639, G_B_loss: 0.6179\n",
            "Epoch [4/70], Step [491/1231], D_A_loss: 0.2966, D_B_loss: 0.0333, G_A_loss: 0.5293, G_B_loss: 0.2617\n",
            "Epoch [4/70], Step [501/1231], D_A_loss: 0.0374, D_B_loss: 0.1918, G_A_loss: 0.3718, G_B_loss: 0.6732\n",
            "Epoch [4/70], Step [511/1231], D_A_loss: 0.0576, D_B_loss: 0.1269, G_A_loss: 0.3592, G_B_loss: 0.1805\n",
            "Epoch [4/70], Step [521/1231], D_A_loss: 0.2657, D_B_loss: 0.0686, G_A_loss: 0.5377, G_B_loss: 0.2385\n",
            "Epoch [4/70], Step [531/1231], D_A_loss: 0.0156, D_B_loss: 0.1596, G_A_loss: 0.2430, G_B_loss: 0.5131\n",
            "Epoch [4/70], Step [541/1231], D_A_loss: 0.0980, D_B_loss: 0.1905, G_A_loss: 0.5292, G_B_loss: 0.3504\n",
            "Epoch [4/70], Step [551/1231], D_A_loss: 0.4506, D_B_loss: 0.0967, G_A_loss: 0.3512, G_B_loss: 0.2698\n",
            "Epoch [4/70], Step [561/1231], D_A_loss: 0.3283, D_B_loss: 0.0663, G_A_loss: 0.7580, G_B_loss: 0.1427\n",
            "Epoch [4/70], Step [571/1231], D_A_loss: 0.1971, D_B_loss: 0.1303, G_A_loss: 0.5127, G_B_loss: 0.3041\n",
            "Epoch [4/70], Step [581/1231], D_A_loss: 0.2278, D_B_loss: 0.1002, G_A_loss: 0.4531, G_B_loss: 0.1224\n",
            "Epoch [4/70], Step [591/1231], D_A_loss: 0.2396, D_B_loss: 0.0760, G_A_loss: 0.5646, G_B_loss: 0.1383\n",
            "Epoch [4/70], Step [601/1231], D_A_loss: 0.1295, D_B_loss: 0.3192, G_A_loss: 0.5939, G_B_loss: 0.5796\n",
            "Epoch [4/70], Step [611/1231], D_A_loss: 0.4548, D_B_loss: 0.2807, G_A_loss: 0.1742, G_B_loss: 0.9335\n",
            "Epoch [4/70], Step [621/1231], D_A_loss: 0.2718, D_B_loss: 0.2521, G_A_loss: 0.2024, G_B_loss: 0.2162\n",
            "Epoch [4/70], Step [631/1231], D_A_loss: 0.0993, D_B_loss: 0.1691, G_A_loss: 0.5489, G_B_loss: 0.3493\n",
            "Epoch [4/70], Step [641/1231], D_A_loss: 0.0510, D_B_loss: 0.2510, G_A_loss: 0.1158, G_B_loss: 0.3334\n",
            "Epoch [4/70], Step [651/1231], D_A_loss: 0.1927, D_B_loss: 0.1264, G_A_loss: 0.1505, G_B_loss: 0.2497\n",
            "Epoch [4/70], Step [661/1231], D_A_loss: 0.0249, D_B_loss: 0.2581, G_A_loss: 0.1080, G_B_loss: 0.2789\n",
            "Epoch [4/70], Step [671/1231], D_A_loss: 0.0791, D_B_loss: 0.3650, G_A_loss: 0.0415, G_B_loss: 0.4394\n",
            "Epoch [4/70], Step [681/1231], D_A_loss: 0.4017, D_B_loss: 0.0589, G_A_loss: 0.2601, G_B_loss: 0.0554\n",
            "Epoch [4/70], Step [691/1231], D_A_loss: 0.0581, D_B_loss: 0.0500, G_A_loss: 0.1498, G_B_loss: 0.5495\n",
            "Epoch [4/70], Step [701/1231], D_A_loss: 0.1782, D_B_loss: 0.0284, G_A_loss: 0.4761, G_B_loss: 0.9470\n",
            "Epoch [4/70], Step [711/1231], D_A_loss: 0.0834, D_B_loss: 0.1618, G_A_loss: 0.2840, G_B_loss: 0.6558\n",
            "Epoch [4/70], Step [721/1231], D_A_loss: 0.0844, D_B_loss: 0.1122, G_A_loss: 0.1687, G_B_loss: 0.4111\n",
            "Epoch [4/70], Step [731/1231], D_A_loss: 0.1871, D_B_loss: 0.3001, G_A_loss: 0.1065, G_B_loss: 0.7599\n",
            "Epoch [4/70], Step [741/1231], D_A_loss: 0.0773, D_B_loss: 0.1032, G_A_loss: 0.3497, G_B_loss: 0.4515\n",
            "Epoch [4/70], Step [751/1231], D_A_loss: 0.1702, D_B_loss: 0.2326, G_A_loss: 0.1617, G_B_loss: 0.2290\n",
            "Epoch [4/70], Step [761/1231], D_A_loss: 0.0748, D_B_loss: 0.0936, G_A_loss: 0.5720, G_B_loss: 0.2391\n",
            "Epoch [4/70], Step [771/1231], D_A_loss: 0.1018, D_B_loss: 0.1429, G_A_loss: 0.4649, G_B_loss: 0.3354\n",
            "Epoch [4/70], Step [781/1231], D_A_loss: 0.0568, D_B_loss: 0.0826, G_A_loss: 0.2013, G_B_loss: 0.4051\n",
            "Epoch [4/70], Step [791/1231], D_A_loss: 0.1559, D_B_loss: 0.0613, G_A_loss: 0.7906, G_B_loss: 0.4070\n",
            "Epoch [4/70], Step [801/1231], D_A_loss: 0.1681, D_B_loss: 0.0477, G_A_loss: 0.5581, G_B_loss: 0.2311\n",
            "Epoch [4/70], Step [811/1231], D_A_loss: 0.1317, D_B_loss: 0.0760, G_A_loss: 0.0802, G_B_loss: 0.3187\n",
            "Epoch [4/70], Step [821/1231], D_A_loss: 0.0261, D_B_loss: 0.3495, G_A_loss: 0.0640, G_B_loss: 0.0487\n",
            "Epoch [4/70], Step [831/1231], D_A_loss: 0.3916, D_B_loss: 0.2132, G_A_loss: 0.2997, G_B_loss: 0.0392\n",
            "Epoch [4/70], Step [841/1231], D_A_loss: 0.0228, D_B_loss: 0.0523, G_A_loss: 0.3957, G_B_loss: 0.7620\n",
            "Epoch [4/70], Step [851/1231], D_A_loss: 0.0206, D_B_loss: 0.1388, G_A_loss: 0.5490, G_B_loss: 0.1593\n",
            "Epoch [4/70], Step [861/1231], D_A_loss: 0.2488, D_B_loss: 0.2416, G_A_loss: 0.7314, G_B_loss: 0.3232\n",
            "Epoch [4/70], Step [871/1231], D_A_loss: 0.2483, D_B_loss: 0.0343, G_A_loss: 0.3411, G_B_loss: 0.1425\n",
            "Epoch [4/70], Step [881/1231], D_A_loss: 0.2713, D_B_loss: 0.3031, G_A_loss: 0.0665, G_B_loss: 0.0998\n",
            "Epoch [4/70], Step [891/1231], D_A_loss: 0.1688, D_B_loss: 0.2191, G_A_loss: 0.2197, G_B_loss: 1.1336\n",
            "Epoch [4/70], Step [901/1231], D_A_loss: 0.4590, D_B_loss: 0.0719, G_A_loss: 0.0596, G_B_loss: 0.0643\n",
            "Epoch [4/70], Step [911/1231], D_A_loss: 0.1139, D_B_loss: 0.5364, G_A_loss: 0.0156, G_B_loss: 0.3524\n",
            "Epoch [4/70], Step [921/1231], D_A_loss: 0.1995, D_B_loss: 0.3264, G_A_loss: 0.2360, G_B_loss: 0.6649\n",
            "Epoch [4/70], Step [931/1231], D_A_loss: 0.3231, D_B_loss: 0.1948, G_A_loss: 0.4620, G_B_loss: 0.0939\n",
            "Epoch [4/70], Step [941/1231], D_A_loss: 0.1828, D_B_loss: 0.2323, G_A_loss: 0.4033, G_B_loss: 0.5458\n",
            "Epoch [4/70], Step [951/1231], D_A_loss: 0.1235, D_B_loss: 0.0297, G_A_loss: 0.1332, G_B_loss: 0.5217\n",
            "Epoch [4/70], Step [961/1231], D_A_loss: 0.0920, D_B_loss: 0.0891, G_A_loss: 0.6740, G_B_loss: 0.3839\n",
            "Epoch [5/70], Step [1/1231], D_A_loss: 0.0415, D_B_loss: 0.1214, G_A_loss: 0.4675, G_B_loss: 0.4082\n",
            "Epoch [5/70], Step [11/1231], D_A_loss: 0.1558, D_B_loss: 0.1098, G_A_loss: 0.3883, G_B_loss: 0.3519\n",
            "Epoch [5/70], Step [21/1231], D_A_loss: 0.1217, D_B_loss: 0.1537, G_A_loss: 0.3328, G_B_loss: 0.4133\n",
            "Epoch [5/70], Step [31/1231], D_A_loss: 0.2508, D_B_loss: 0.0329, G_A_loss: 0.3883, G_B_loss: 0.1351\n",
            "Epoch [5/70], Step [41/1231], D_A_loss: 0.1232, D_B_loss: 0.2251, G_A_loss: 0.3904, G_B_loss: 0.2678\n",
            "Epoch [5/70], Step [51/1231], D_A_loss: 0.1886, D_B_loss: 0.2200, G_A_loss: 0.7812, G_B_loss: 0.2847\n",
            "Epoch [5/70], Step [61/1231], D_A_loss: 0.1807, D_B_loss: 0.0331, G_A_loss: 0.1998, G_B_loss: 0.2211\n",
            "Epoch [5/70], Step [71/1231], D_A_loss: 0.3630, D_B_loss: 0.0470, G_A_loss: 0.4169, G_B_loss: 0.1010\n",
            "Epoch [5/70], Step [81/1231], D_A_loss: 0.0172, D_B_loss: 0.3548, G_A_loss: 0.6865, G_B_loss: 0.1965\n",
            "Epoch [5/70], Step [91/1231], D_A_loss: 0.1205, D_B_loss: 0.0239, G_A_loss: 0.3639, G_B_loss: 0.0588\n",
            "Epoch [5/70], Step [101/1231], D_A_loss: 0.0986, D_B_loss: 0.1232, G_A_loss: 0.0826, G_B_loss: 0.2944\n",
            "Epoch [5/70], Step [111/1231], D_A_loss: 0.3751, D_B_loss: 0.1320, G_A_loss: 0.1438, G_B_loss: 0.7582\n",
            "Epoch [5/70], Step [121/1231], D_A_loss: 0.1424, D_B_loss: 0.1249, G_A_loss: 0.4871, G_B_loss: 0.4941\n",
            "Epoch [5/70], Step [131/1231], D_A_loss: 0.1067, D_B_loss: 0.0613, G_A_loss: 0.2901, G_B_loss: 0.8006\n",
            "Epoch [5/70], Step [141/1231], D_A_loss: 0.2030, D_B_loss: 0.0963, G_A_loss: 0.4290, G_B_loss: 0.1748\n",
            "Epoch [5/70], Step [151/1231], D_A_loss: 0.0460, D_B_loss: 0.0357, G_A_loss: 0.3891, G_B_loss: 0.6646\n",
            "Epoch [5/70], Step [161/1231], D_A_loss: 0.3530, D_B_loss: 0.1649, G_A_loss: 0.2097, G_B_loss: 0.4874\n",
            "Epoch [5/70], Step [171/1231], D_A_loss: 0.0949, D_B_loss: 0.0964, G_A_loss: 0.2902, G_B_loss: 0.2544\n",
            "Epoch [5/70], Step [181/1231], D_A_loss: 0.1576, D_B_loss: 0.0185, G_A_loss: 0.2344, G_B_loss: 0.3083\n",
            "Epoch [5/70], Step [191/1231], D_A_loss: 0.1792, D_B_loss: 0.1358, G_A_loss: 0.3579, G_B_loss: 0.5025\n",
            "Epoch [5/70], Step [201/1231], D_A_loss: 0.1872, D_B_loss: 0.3131, G_A_loss: 0.3484, G_B_loss: 0.3292\n",
            "Epoch [5/70], Step [211/1231], D_A_loss: 0.0825, D_B_loss: 0.2847, G_A_loss: 0.2236, G_B_loss: 0.7217\n",
            "Epoch [5/70], Step [221/1231], D_A_loss: 0.2711, D_B_loss: 0.0669, G_A_loss: 0.1010, G_B_loss: 0.1763\n",
            "Epoch [5/70], Step [231/1231], D_A_loss: 0.1541, D_B_loss: 0.0758, G_A_loss: 0.4368, G_B_loss: 0.6986\n",
            "Epoch [5/70], Step [241/1231], D_A_loss: 0.0624, D_B_loss: 0.0621, G_A_loss: 0.3564, G_B_loss: 0.3008\n",
            "Epoch [5/70], Step [251/1231], D_A_loss: 0.3138, D_B_loss: 0.3180, G_A_loss: 0.2124, G_B_loss: 0.0632\n",
            "Epoch [5/70], Step [261/1231], D_A_loss: 0.2758, D_B_loss: 0.1798, G_A_loss: 0.2052, G_B_loss: 0.0946\n",
            "Epoch [5/70], Step [271/1231], D_A_loss: 0.2465, D_B_loss: 0.0770, G_A_loss: 0.3462, G_B_loss: 0.1921\n",
            "Epoch [5/70], Step [281/1231], D_A_loss: 0.1345, D_B_loss: 0.0240, G_A_loss: 0.3661, G_B_loss: 0.2974\n",
            "Epoch [5/70], Step [291/1231], D_A_loss: 0.0770, D_B_loss: 0.1229, G_A_loss: 0.3822, G_B_loss: 0.3314\n",
            "Epoch [5/70], Step [301/1231], D_A_loss: 0.0340, D_B_loss: 0.1625, G_A_loss: 0.0870, G_B_loss: 0.6434\n",
            "Epoch [5/70], Step [311/1231], D_A_loss: 0.1956, D_B_loss: 0.0598, G_A_loss: 0.5051, G_B_loss: 0.3060\n",
            "Epoch [5/70], Step [321/1231], D_A_loss: 0.0397, D_B_loss: 0.1384, G_A_loss: 0.4987, G_B_loss: 0.2510\n",
            "Epoch [5/70], Step [331/1231], D_A_loss: 0.0199, D_B_loss: 0.0861, G_A_loss: 0.3966, G_B_loss: 0.3638\n",
            "Epoch [5/70], Step [341/1231], D_A_loss: 0.0913, D_B_loss: 0.0932, G_A_loss: 0.3621, G_B_loss: 0.2681\n",
            "Epoch [5/70], Step [351/1231], D_A_loss: 0.2355, D_B_loss: 0.1574, G_A_loss: 0.0624, G_B_loss: 0.0657\n",
            "Epoch [5/70], Step [361/1231], D_A_loss: 0.2916, D_B_loss: 0.2754, G_A_loss: 0.9800, G_B_loss: 0.0829\n",
            "Epoch [5/70], Step [371/1231], D_A_loss: 0.0285, D_B_loss: 0.0767, G_A_loss: 0.6684, G_B_loss: 0.5089\n",
            "Epoch [5/70], Step [381/1231], D_A_loss: 0.1870, D_B_loss: 0.1877, G_A_loss: 0.2359, G_B_loss: 0.3172\n",
            "Epoch [5/70], Step [391/1231], D_A_loss: 0.1560, D_B_loss: 0.1333, G_A_loss: 1.4466, G_B_loss: 0.2684\n",
            "Epoch [5/70], Step [401/1231], D_A_loss: 0.1633, D_B_loss: 0.3423, G_A_loss: 0.1259, G_B_loss: 0.4468\n",
            "Epoch [5/70], Step [411/1231], D_A_loss: 0.1278, D_B_loss: 0.2915, G_A_loss: 0.1091, G_B_loss: 0.1748\n",
            "Epoch [5/70], Step [421/1231], D_A_loss: 0.2384, D_B_loss: 0.2069, G_A_loss: 0.1658, G_B_loss: 0.1385\n",
            "Epoch [5/70], Step [431/1231], D_A_loss: 0.7321, D_B_loss: 0.3103, G_A_loss: 0.0694, G_B_loss: 0.7544\n",
            "Epoch [5/70], Step [441/1231], D_A_loss: 0.2296, D_B_loss: 0.1025, G_A_loss: 0.5950, G_B_loss: 0.2711\n",
            "Epoch [5/70], Step [451/1231], D_A_loss: 0.2434, D_B_loss: 0.3162, G_A_loss: 0.3286, G_B_loss: 0.2302\n",
            "Epoch [5/70], Step [461/1231], D_A_loss: 0.0171, D_B_loss: 0.2037, G_A_loss: 0.2203, G_B_loss: 0.4464\n",
            "Epoch [5/70], Step [471/1231], D_A_loss: 0.4551, D_B_loss: 0.3386, G_A_loss: 1.0142, G_B_loss: 0.0236\n",
            "Epoch [5/70], Step [481/1231], D_A_loss: 0.1712, D_B_loss: 0.3026, G_A_loss: 0.6225, G_B_loss: 0.3714\n",
            "Epoch [5/70], Step [491/1231], D_A_loss: 0.0717, D_B_loss: 0.1257, G_A_loss: 0.3631, G_B_loss: 0.6017\n",
            "Epoch [5/70], Step [501/1231], D_A_loss: 0.2413, D_B_loss: 0.2839, G_A_loss: 0.0490, G_B_loss: 0.3600\n",
            "Epoch [5/70], Step [511/1231], D_A_loss: 0.1985, D_B_loss: 0.2611, G_A_loss: 0.6872, G_B_loss: 0.1980\n",
            "Epoch [5/70], Step [521/1231], D_A_loss: 0.0481, D_B_loss: 0.2158, G_A_loss: 0.4867, G_B_loss: 0.1300\n",
            "Epoch [5/70], Step [531/1231], D_A_loss: 0.1389, D_B_loss: 0.2122, G_A_loss: 0.5761, G_B_loss: 0.3534\n",
            "Epoch [5/70], Step [541/1231], D_A_loss: 0.2043, D_B_loss: 0.0921, G_A_loss: 0.5349, G_B_loss: 0.3769\n",
            "Epoch [5/70], Step [551/1231], D_A_loss: 0.0339, D_B_loss: 0.0631, G_A_loss: 0.5044, G_B_loss: 0.4278\n",
            "Epoch [5/70], Step [561/1231], D_A_loss: 0.1867, D_B_loss: 0.1408, G_A_loss: 1.0455, G_B_loss: 0.0929\n",
            "Epoch [5/70], Step [571/1231], D_A_loss: 0.2068, D_B_loss: 0.1835, G_A_loss: 0.6652, G_B_loss: 0.3559\n",
            "Epoch [5/70], Step [581/1231], D_A_loss: 0.0840, D_B_loss: 0.0672, G_A_loss: 0.6544, G_B_loss: 0.6311\n",
            "Epoch [5/70], Step [591/1231], D_A_loss: 0.0793, D_B_loss: 0.0887, G_A_loss: 0.9331, G_B_loss: 0.6144\n",
            "Epoch [5/70], Step [601/1231], D_A_loss: 0.0462, D_B_loss: 0.1449, G_A_loss: 0.2914, G_B_loss: 0.1876\n",
            "Epoch [5/70], Step [611/1231], D_A_loss: 0.0776, D_B_loss: 0.1133, G_A_loss: 0.5851, G_B_loss: 0.3189\n",
            "Epoch [5/70], Step [621/1231], D_A_loss: 0.0263, D_B_loss: 0.1487, G_A_loss: 0.3258, G_B_loss: 1.2051\n",
            "Epoch [5/70], Step [631/1231], D_A_loss: 0.0950, D_B_loss: 0.0624, G_A_loss: 0.3865, G_B_loss: 1.0138\n",
            "Epoch [5/70], Step [641/1231], D_A_loss: 0.2573, D_B_loss: 0.1624, G_A_loss: 0.4822, G_B_loss: 0.2094\n",
            "Epoch [5/70], Step [651/1231], D_A_loss: 0.1181, D_B_loss: 0.3460, G_A_loss: 0.1721, G_B_loss: 0.6550\n",
            "Epoch [5/70], Step [661/1231], D_A_loss: 0.2514, D_B_loss: 0.3458, G_A_loss: 0.0414, G_B_loss: 0.4087\n",
            "Epoch [5/70], Step [671/1231], D_A_loss: 0.0926, D_B_loss: 0.0850, G_A_loss: 0.4941, G_B_loss: 0.2524\n",
            "Epoch [5/70], Step [681/1231], D_A_loss: 0.1799, D_B_loss: 0.0678, G_A_loss: 0.5994, G_B_loss: 0.2196\n",
            "Epoch [5/70], Step [691/1231], D_A_loss: 0.1851, D_B_loss: 0.2453, G_A_loss: 0.2485, G_B_loss: 0.3376\n",
            "Epoch [5/70], Step [701/1231], D_A_loss: 0.0846, D_B_loss: 0.3069, G_A_loss: 0.0841, G_B_loss: 0.4052\n",
            "Epoch [5/70], Step [711/1231], D_A_loss: 0.2555, D_B_loss: 0.1267, G_A_loss: 0.3098, G_B_loss: 0.7111\n",
            "Epoch [5/70], Step [721/1231], D_A_loss: 0.1511, D_B_loss: 0.0381, G_A_loss: 0.3486, G_B_loss: 0.4653\n",
            "Epoch [5/70], Step [731/1231], D_A_loss: 0.2410, D_B_loss: 0.1686, G_A_loss: 0.3223, G_B_loss: 0.5945\n",
            "Epoch [5/70], Step [741/1231], D_A_loss: 0.1042, D_B_loss: 0.2086, G_A_loss: 0.5892, G_B_loss: 0.3766\n",
            "Epoch [5/70], Step [751/1231], D_A_loss: 0.2354, D_B_loss: 0.2726, G_A_loss: 0.5030, G_B_loss: 0.6449\n",
            "Epoch [5/70], Step [761/1231], D_A_loss: 0.2799, D_B_loss: 0.1855, G_A_loss: 0.4743, G_B_loss: 0.0954\n",
            "Epoch [5/70], Step [771/1231], D_A_loss: 0.0174, D_B_loss: 0.2705, G_A_loss: 0.2991, G_B_loss: 0.2817\n",
            "Epoch [5/70], Step [781/1231], D_A_loss: 0.2108, D_B_loss: 0.1435, G_A_loss: 0.4078, G_B_loss: 0.2584\n",
            "Epoch [5/70], Step [791/1231], D_A_loss: 0.1314, D_B_loss: 0.0759, G_A_loss: 0.4809, G_B_loss: 0.5410\n",
            "Epoch [5/70], Step [801/1231], D_A_loss: 0.2985, D_B_loss: 0.2118, G_A_loss: 0.2814, G_B_loss: 0.0825\n",
            "Epoch [5/70], Step [811/1231], D_A_loss: 0.2202, D_B_loss: 0.1282, G_A_loss: 0.9998, G_B_loss: 0.1411\n",
            "Epoch [5/70], Step [821/1231], D_A_loss: 0.1036, D_B_loss: 0.2883, G_A_loss: 0.1289, G_B_loss: 0.4331\n",
            "Epoch [5/70], Step [831/1231], D_A_loss: 0.1196, D_B_loss: 0.0878, G_A_loss: 0.3985, G_B_loss: 0.2549\n",
            "Epoch [5/70], Step [841/1231], D_A_loss: 0.1044, D_B_loss: 0.1072, G_A_loss: 0.3505, G_B_loss: 0.0496\n",
            "Epoch [5/70], Step [851/1231], D_A_loss: 0.1470, D_B_loss: 0.2983, G_A_loss: 0.3317, G_B_loss: 0.0597\n",
            "Epoch [5/70], Step [861/1231], D_A_loss: 0.0865, D_B_loss: 0.0462, G_A_loss: 0.1441, G_B_loss: 0.3711\n",
            "Epoch [5/70], Step [871/1231], D_A_loss: 0.0911, D_B_loss: 0.0949, G_A_loss: 0.3278, G_B_loss: 0.5102\n",
            "Epoch [5/70], Step [881/1231], D_A_loss: 0.2665, D_B_loss: 0.1796, G_A_loss: 0.3698, G_B_loss: 0.5635\n",
            "Epoch [5/70], Step [891/1231], D_A_loss: 0.6476, D_B_loss: 0.1095, G_A_loss: 0.3657, G_B_loss: 0.4481\n",
            "Epoch [5/70], Step [901/1231], D_A_loss: 0.1261, D_B_loss: 0.2809, G_A_loss: 0.1418, G_B_loss: 1.2685\n",
            "Epoch [5/70], Step [911/1231], D_A_loss: 0.1423, D_B_loss: 0.2687, G_A_loss: 0.2090, G_B_loss: 0.1226\n",
            "Epoch [5/70], Step [921/1231], D_A_loss: 0.1718, D_B_loss: 0.1844, G_A_loss: 0.2236, G_B_loss: 0.3943\n",
            "Epoch [5/70], Step [931/1231], D_A_loss: 0.2850, D_B_loss: 0.1661, G_A_loss: 0.4477, G_B_loss: 0.0835\n",
            "Epoch [5/70], Step [941/1231], D_A_loss: 0.0944, D_B_loss: 0.1658, G_A_loss: 0.5369, G_B_loss: 0.3153\n",
            "Epoch [5/70], Step [951/1231], D_A_loss: 0.0293, D_B_loss: 0.2232, G_A_loss: 0.3683, G_B_loss: 0.2223\n",
            "Epoch [5/70], Step [961/1231], D_A_loss: 0.0927, D_B_loss: 0.1375, G_A_loss: 0.2599, G_B_loss: 0.2912\n",
            "Epoch [6/70], Step [1/1231], D_A_loss: 0.1450, D_B_loss: 0.3403, G_A_loss: 0.4705, G_B_loss: 0.2571\n",
            "Epoch [6/70], Step [11/1231], D_A_loss: 0.0740, D_B_loss: 0.2969, G_A_loss: 0.1011, G_B_loss: 0.1881\n",
            "Epoch [6/70], Step [21/1231], D_A_loss: 0.3403, D_B_loss: 0.2532, G_A_loss: 0.5704, G_B_loss: 0.0502\n",
            "Epoch [6/70], Step [31/1231], D_A_loss: 0.1428, D_B_loss: 0.1485, G_A_loss: 0.2606, G_B_loss: 0.4136\n",
            "Epoch [6/70], Step [41/1231], D_A_loss: 0.0595, D_B_loss: 0.0660, G_A_loss: 0.5317, G_B_loss: 0.3234\n",
            "Epoch [6/70], Step [51/1231], D_A_loss: 0.0998, D_B_loss: 0.1843, G_A_loss: 0.5137, G_B_loss: 0.1726\n",
            "Epoch [6/70], Step [61/1231], D_A_loss: 0.0972, D_B_loss: 0.2943, G_A_loss: 0.4316, G_B_loss: 0.5257\n",
            "Epoch [6/70], Step [71/1231], D_A_loss: 0.1775, D_B_loss: 0.0969, G_A_loss: 0.6151, G_B_loss: 0.3345\n",
            "Epoch [6/70], Step [81/1231], D_A_loss: 0.0353, D_B_loss: 0.2437, G_A_loss: 0.2672, G_B_loss: 0.4989\n",
            "Epoch [6/70], Step [91/1231], D_A_loss: 0.1257, D_B_loss: 0.1526, G_A_loss: 0.3436, G_B_loss: 0.4906\n",
            "Epoch [6/70], Step [101/1231], D_A_loss: 0.2176, D_B_loss: 0.3384, G_A_loss: 0.0619, G_B_loss: 0.2336\n",
            "Epoch [6/70], Step [111/1231], D_A_loss: 0.2077, D_B_loss: 0.2277, G_A_loss: 0.7601, G_B_loss: 0.7284\n",
            "Epoch [6/70], Step [121/1231], D_A_loss: 0.1415, D_B_loss: 0.0824, G_A_loss: 0.1592, G_B_loss: 0.5228\n",
            "Epoch [6/70], Step [131/1231], D_A_loss: 0.1381, D_B_loss: 0.3993, G_A_loss: 0.5337, G_B_loss: 0.5970\n",
            "Epoch [6/70], Step [141/1231], D_A_loss: 0.2039, D_B_loss: 0.1071, G_A_loss: 0.4115, G_B_loss: 0.2278\n",
            "Epoch [6/70], Step [151/1231], D_A_loss: 0.1153, D_B_loss: 0.1671, G_A_loss: 0.2579, G_B_loss: 0.5539\n",
            "Epoch [6/70], Step [161/1231], D_A_loss: 0.0236, D_B_loss: 0.0697, G_A_loss: 0.0915, G_B_loss: 0.0240\n",
            "Epoch [6/70], Step [171/1231], D_A_loss: 0.4387, D_B_loss: 0.1188, G_A_loss: 0.3980, G_B_loss: 0.0189\n",
            "Epoch [6/70], Step [181/1231], D_A_loss: 0.1963, D_B_loss: 0.2148, G_A_loss: 0.6074, G_B_loss: 0.2173\n",
            "Epoch [6/70], Step [191/1231], D_A_loss: 0.0254, D_B_loss: 0.0874, G_A_loss: 0.7748, G_B_loss: 0.2280\n",
            "Epoch [6/70], Step [201/1231], D_A_loss: 0.1622, D_B_loss: 0.0573, G_A_loss: 0.3532, G_B_loss: 0.4464\n",
            "Epoch [6/70], Step [211/1231], D_A_loss: 0.1203, D_B_loss: 0.1653, G_A_loss: 0.2580, G_B_loss: 1.1745\n",
            "Epoch [6/70], Step [221/1231], D_A_loss: 0.1267, D_B_loss: 0.1998, G_A_loss: 0.2319, G_B_loss: 0.3255\n",
            "Epoch [6/70], Step [231/1231], D_A_loss: 0.1331, D_B_loss: 0.0430, G_A_loss: 0.3060, G_B_loss: 0.1540\n",
            "Epoch [6/70], Step [241/1231], D_A_loss: 0.0351, D_B_loss: 0.0717, G_A_loss: 0.3672, G_B_loss: 0.6135\n",
            "Epoch [6/70], Step [251/1231], D_A_loss: 0.1697, D_B_loss: 0.2849, G_A_loss: 0.0917, G_B_loss: 0.2954\n",
            "Epoch [6/70], Step [261/1231], D_A_loss: 0.3249, D_B_loss: 0.1254, G_A_loss: 0.2843, G_B_loss: 0.0898\n",
            "Epoch [6/70], Step [271/1231], D_A_loss: 0.0128, D_B_loss: 0.0524, G_A_loss: 0.4288, G_B_loss: 0.9187\n",
            "Epoch [6/70], Step [281/1231], D_A_loss: 0.2039, D_B_loss: 0.2180, G_A_loss: 0.2800, G_B_loss: 0.2320\n",
            "Epoch [6/70], Step [291/1231], D_A_loss: 0.2424, D_B_loss: 0.2014, G_A_loss: 0.2701, G_B_loss: 0.2873\n",
            "Epoch [6/70], Step [301/1231], D_A_loss: 0.0418, D_B_loss: 0.1562, G_A_loss: 0.2337, G_B_loss: 0.1099\n",
            "Epoch [6/70], Step [311/1231], D_A_loss: 0.0857, D_B_loss: 0.0852, G_A_loss: 0.4723, G_B_loss: 0.3606\n",
            "Epoch [6/70], Step [321/1231], D_A_loss: 0.2115, D_B_loss: 0.2200, G_A_loss: 0.2084, G_B_loss: 0.2914\n",
            "Epoch [6/70], Step [331/1231], D_A_loss: 0.1683, D_B_loss: 0.1775, G_A_loss: 0.4828, G_B_loss: 0.3770\n",
            "Epoch [6/70], Step [341/1231], D_A_loss: 0.2339, D_B_loss: 0.0571, G_A_loss: 0.3579, G_B_loss: 0.1585\n",
            "Epoch [6/70], Step [351/1231], D_A_loss: 0.0749, D_B_loss: 0.1420, G_A_loss: 0.2872, G_B_loss: 0.3340\n",
            "Epoch [6/70], Step [361/1231], D_A_loss: 0.2680, D_B_loss: 0.0790, G_A_loss: 0.3970, G_B_loss: 0.5848\n",
            "Epoch [6/70], Step [371/1231], D_A_loss: 0.2245, D_B_loss: 0.2153, G_A_loss: 0.3102, G_B_loss: 0.5701\n",
            "Epoch [6/70], Step [381/1231], D_A_loss: 0.0387, D_B_loss: 0.2989, G_A_loss: 0.0935, G_B_loss: 0.3955\n",
            "Epoch [6/70], Step [391/1231], D_A_loss: 0.0851, D_B_loss: 0.0392, G_A_loss: 0.3889, G_B_loss: 0.2171\n",
            "Epoch [6/70], Step [401/1231], D_A_loss: 0.0548, D_B_loss: 0.0559, G_A_loss: 0.2554, G_B_loss: 0.5417\n",
            "Epoch [6/70], Step [411/1231], D_A_loss: 0.0632, D_B_loss: 0.2561, G_A_loss: 0.5334, G_B_loss: 0.3959\n",
            "Epoch [6/70], Step [421/1231], D_A_loss: 0.0550, D_B_loss: 0.1429, G_A_loss: 0.3960, G_B_loss: 0.5215\n",
            "Epoch [6/70], Step [431/1231], D_A_loss: 0.5623, D_B_loss: 0.0993, G_A_loss: 0.4683, G_B_loss: 0.1425\n",
            "Epoch [6/70], Step [441/1231], D_A_loss: 0.0967, D_B_loss: 0.0307, G_A_loss: 0.3660, G_B_loss: 0.7160\n",
            "Epoch [6/70], Step [451/1231], D_A_loss: 0.2091, D_B_loss: 0.1695, G_A_loss: 0.2104, G_B_loss: 0.3029\n",
            "Epoch [6/70], Step [461/1231], D_A_loss: 0.1593, D_B_loss: 0.0701, G_A_loss: 0.2998, G_B_loss: 0.2242\n",
            "Epoch [6/70], Step [471/1231], D_A_loss: 0.2163, D_B_loss: 0.1622, G_A_loss: 0.4106, G_B_loss: 0.1913\n",
            "Epoch [6/70], Step [481/1231], D_A_loss: 0.2831, D_B_loss: 0.0478, G_A_loss: 0.0687, G_B_loss: 0.0744\n",
            "Epoch [6/70], Step [491/1231], D_A_loss: 0.3741, D_B_loss: 0.2469, G_A_loss: 0.1329, G_B_loss: 0.0372\n",
            "Epoch [6/70], Step [501/1231], D_A_loss: 0.0616, D_B_loss: 0.3433, G_A_loss: 0.0816, G_B_loss: 0.3664\n",
            "Epoch [6/70], Step [511/1231], D_A_loss: 0.0768, D_B_loss: 0.1004, G_A_loss: 0.5039, G_B_loss: 0.4934\n",
            "Epoch [6/70], Step [521/1231], D_A_loss: 0.1287, D_B_loss: 0.2107, G_A_loss: 0.3599, G_B_loss: 0.1542\n",
            "Epoch [6/70], Step [531/1231], D_A_loss: 0.1636, D_B_loss: 0.1270, G_A_loss: 0.7858, G_B_loss: 0.6490\n",
            "Epoch [6/70], Step [541/1231], D_A_loss: 0.0734, D_B_loss: 0.2419, G_A_loss: 0.1616, G_B_loss: 0.2307\n",
            "Epoch [6/70], Step [551/1231], D_A_loss: 0.2748, D_B_loss: 0.4239, G_A_loss: 0.5597, G_B_loss: 0.5668\n",
            "Epoch [6/70], Step [561/1231], D_A_loss: 0.1071, D_B_loss: 0.1479, G_A_loss: 0.3310, G_B_loss: 0.3310\n",
            "Epoch [6/70], Step [571/1231], D_A_loss: 0.1584, D_B_loss: 0.2694, G_A_loss: 0.1228, G_B_loss: 0.1055\n",
            "Epoch [6/70], Step [581/1231], D_A_loss: 0.0542, D_B_loss: 0.1039, G_A_loss: 0.1250, G_B_loss: 0.1437\n",
            "Epoch [6/70], Step [591/1231], D_A_loss: 0.1368, D_B_loss: 0.1553, G_A_loss: 0.4512, G_B_loss: 0.2449\n",
            "Epoch [6/70], Step [601/1231], D_A_loss: 0.0934, D_B_loss: 0.2485, G_A_loss: 0.1220, G_B_loss: 0.5319\n",
            "Epoch [6/70], Step [611/1231], D_A_loss: 0.1055, D_B_loss: 0.1946, G_A_loss: 0.7024, G_B_loss: 0.3203\n",
            "Epoch [6/70], Step [621/1231], D_A_loss: 0.0660, D_B_loss: 0.2036, G_A_loss: 0.3183, G_B_loss: 0.1555\n",
            "Epoch [6/70], Step [631/1231], D_A_loss: 0.2053, D_B_loss: 0.2563, G_A_loss: 0.4564, G_B_loss: 0.3229\n",
            "Epoch [6/70], Step [641/1231], D_A_loss: 0.0790, D_B_loss: 0.0272, G_A_loss: 0.6988, G_B_loss: 0.3047\n",
            "Epoch [6/70], Step [651/1231], D_A_loss: 0.1777, D_B_loss: 0.0433, G_A_loss: 0.4065, G_B_loss: 0.2012\n",
            "Epoch [6/70], Step [661/1231], D_A_loss: 0.2190, D_B_loss: 0.1616, G_A_loss: 0.5307, G_B_loss: 0.6297\n",
            "Epoch [6/70], Step [671/1231], D_A_loss: 0.2172, D_B_loss: 0.1507, G_A_loss: 0.2969, G_B_loss: 0.2673\n",
            "Epoch [6/70], Step [681/1231], D_A_loss: 0.1552, D_B_loss: 0.3000, G_A_loss: 0.0946, G_B_loss: 0.5541\n",
            "Epoch [6/70], Step [691/1231], D_A_loss: 0.1397, D_B_loss: 0.0728, G_A_loss: 0.1987, G_B_loss: 0.3542\n",
            "Epoch [6/70], Step [701/1231], D_A_loss: 0.1736, D_B_loss: 0.0927, G_A_loss: 0.5623, G_B_loss: 0.3614\n",
            "Epoch [6/70], Step [711/1231], D_A_loss: 0.0752, D_B_loss: 0.1150, G_A_loss: 0.3905, G_B_loss: 0.5063\n",
            "Epoch [6/70], Step [721/1231], D_A_loss: 0.4304, D_B_loss: 0.2062, G_A_loss: 0.1507, G_B_loss: 0.3438\n",
            "Epoch [6/70], Step [731/1231], D_A_loss: 0.1767, D_B_loss: 0.1219, G_A_loss: 0.3165, G_B_loss: 0.4573\n",
            "Epoch [6/70], Step [741/1231], D_A_loss: 0.1726, D_B_loss: 0.1727, G_A_loss: 0.2132, G_B_loss: 0.5858\n",
            "Epoch [6/70], Step [751/1231], D_A_loss: 0.2868, D_B_loss: 0.1759, G_A_loss: 0.1704, G_B_loss: 0.3927\n",
            "Epoch [6/70], Step [761/1231], D_A_loss: 0.4040, D_B_loss: 0.1948, G_A_loss: 0.2352, G_B_loss: 0.1575\n",
            "Epoch [6/70], Step [771/1231], D_A_loss: 0.2059, D_B_loss: 0.2651, G_A_loss: 0.1601, G_B_loss: 0.1709\n",
            "Epoch [6/70], Step [781/1231], D_A_loss: 0.2972, D_B_loss: 0.0230, G_A_loss: 0.3834, G_B_loss: 0.5511\n",
            "Epoch [6/70], Step [791/1231], D_A_loss: 0.1674, D_B_loss: 0.2433, G_A_loss: 0.7393, G_B_loss: 0.2761\n",
            "Epoch [6/70], Step [801/1231], D_A_loss: 0.0845, D_B_loss: 0.2233, G_A_loss: 0.3963, G_B_loss: 0.3821\n",
            "Epoch [6/70], Step [811/1231], D_A_loss: 0.1846, D_B_loss: 0.1837, G_A_loss: 0.7205, G_B_loss: 0.2495\n",
            "Epoch [6/70], Step [821/1231], D_A_loss: 0.1255, D_B_loss: 0.2013, G_A_loss: 0.0957, G_B_loss: 0.2343\n",
            "Epoch [6/70], Step [831/1231], D_A_loss: 0.1334, D_B_loss: 0.1516, G_A_loss: 0.4070, G_B_loss: 0.5278\n",
            "Epoch [6/70], Step [841/1231], D_A_loss: 0.1471, D_B_loss: 0.2742, G_A_loss: 0.4821, G_B_loss: 0.2481\n",
            "Epoch [6/70], Step [851/1231], D_A_loss: 0.0896, D_B_loss: 0.0988, G_A_loss: 0.4347, G_B_loss: 0.0955\n",
            "Epoch [6/70], Step [861/1231], D_A_loss: 0.0575, D_B_loss: 0.2983, G_A_loss: 0.1866, G_B_loss: 0.2698\n",
            "Epoch [6/70], Step [871/1231], D_A_loss: 0.0838, D_B_loss: 0.0535, G_A_loss: 0.5462, G_B_loss: 0.6700\n",
            "Epoch [6/70], Step [881/1231], D_A_loss: 0.0253, D_B_loss: 0.5751, G_A_loss: 1.2414, G_B_loss: 0.2296\n",
            "Epoch [6/70], Step [891/1231], D_A_loss: 0.2199, D_B_loss: 0.1734, G_A_loss: 0.3405, G_B_loss: 0.1895\n",
            "Epoch [6/70], Step [901/1231], D_A_loss: 0.1866, D_B_loss: 0.0491, G_A_loss: 0.3254, G_B_loss: 0.3191\n",
            "Epoch [6/70], Step [911/1231], D_A_loss: 0.1738, D_B_loss: 0.0612, G_A_loss: 0.5420, G_B_loss: 0.7627\n",
            "Epoch [6/70], Step [921/1231], D_A_loss: 0.0674, D_B_loss: 0.2262, G_A_loss: 0.1273, G_B_loss: 0.1564\n",
            "Epoch [6/70], Step [931/1231], D_A_loss: 0.0541, D_B_loss: 0.0766, G_A_loss: 0.3078, G_B_loss: 0.2619\n",
            "Epoch [6/70], Step [941/1231], D_A_loss: 0.0937, D_B_loss: 0.1029, G_A_loss: 0.5545, G_B_loss: 0.1392\n",
            "Epoch [6/70], Step [951/1231], D_A_loss: 0.1947, D_B_loss: 0.1675, G_A_loss: 0.6516, G_B_loss: 0.2070\n",
            "Epoch [6/70], Step [961/1231], D_A_loss: 0.1642, D_B_loss: 0.2552, G_A_loss: 0.4437, G_B_loss: 0.2378\n",
            "Epoch [7/70], Step [1/1231], D_A_loss: 0.0224, D_B_loss: 0.0932, G_A_loss: 0.4502, G_B_loss: 0.5710\n",
            "Epoch [7/70], Step [11/1231], D_A_loss: 0.2050, D_B_loss: 0.1508, G_A_loss: 0.4850, G_B_loss: 0.2680\n",
            "Epoch [7/70], Step [21/1231], D_A_loss: 0.2590, D_B_loss: 0.0202, G_A_loss: 0.6901, G_B_loss: 0.0951\n",
            "Epoch [7/70], Step [31/1231], D_A_loss: 0.2156, D_B_loss: 0.1871, G_A_loss: 0.2255, G_B_loss: 0.1885\n",
            "Epoch [7/70], Step [41/1231], D_A_loss: 0.0910, D_B_loss: 0.0910, G_A_loss: 0.4210, G_B_loss: 0.2295\n",
            "Epoch [7/70], Step [51/1231], D_A_loss: 0.3245, D_B_loss: 0.0391, G_A_loss: 0.6786, G_B_loss: 0.1015\n",
            "Epoch [7/70], Step [61/1231], D_A_loss: 0.2411, D_B_loss: 0.0489, G_A_loss: 0.1635, G_B_loss: 0.3621\n",
            "Epoch [7/70], Step [71/1231], D_A_loss: 0.2761, D_B_loss: 0.1065, G_A_loss: 0.6265, G_B_loss: 0.6906\n",
            "Epoch [7/70], Step [81/1231], D_A_loss: 0.0453, D_B_loss: 0.1807, G_A_loss: 0.3642, G_B_loss: 0.4003\n",
            "Epoch [7/70], Step [91/1231], D_A_loss: 0.1667, D_B_loss: 0.2332, G_A_loss: 0.3280, G_B_loss: 0.8651\n",
            "Epoch [7/70], Step [101/1231], D_A_loss: 0.1751, D_B_loss: 0.3245, G_A_loss: 0.4369, G_B_loss: 0.5851\n",
            "Epoch [7/70], Step [111/1231], D_A_loss: 0.1894, D_B_loss: 0.1582, G_A_loss: 0.2798, G_B_loss: 0.5820\n",
            "Epoch [7/70], Step [121/1231], D_A_loss: 0.0791, D_B_loss: 0.2082, G_A_loss: 0.4702, G_B_loss: 0.3622\n",
            "Epoch [7/70], Step [131/1231], D_A_loss: 0.1849, D_B_loss: 0.1474, G_A_loss: 0.4116, G_B_loss: 0.2515\n",
            "Epoch [7/70], Step [141/1231], D_A_loss: 0.1156, D_B_loss: 0.1528, G_A_loss: 0.3388, G_B_loss: 0.3713\n",
            "Epoch [7/70], Step [151/1231], D_A_loss: 0.1820, D_B_loss: 0.1419, G_A_loss: 0.5450, G_B_loss: 0.3490\n",
            "Epoch [7/70], Step [161/1231], D_A_loss: 0.0969, D_B_loss: 0.2851, G_A_loss: 0.5452, G_B_loss: 0.5930\n",
            "Epoch [7/70], Step [171/1231], D_A_loss: 0.3355, D_B_loss: 0.1430, G_A_loss: 0.4696, G_B_loss: 0.7928\n",
            "Epoch [7/70], Step [181/1231], D_A_loss: 0.1152, D_B_loss: 0.1204, G_A_loss: 0.4067, G_B_loss: 0.2012\n",
            "Epoch [7/70], Step [191/1231], D_A_loss: 0.1030, D_B_loss: 0.2283, G_A_loss: 0.1841, G_B_loss: 0.1494\n",
            "Epoch [7/70], Step [201/1231], D_A_loss: 0.1776, D_B_loss: 0.3557, G_A_loss: 0.2692, G_B_loss: 0.1896\n",
            "Epoch [7/70], Step [211/1231], D_A_loss: 0.1538, D_B_loss: 0.1074, G_A_loss: 0.3550, G_B_loss: 0.3861\n",
            "Epoch [7/70], Step [221/1231], D_A_loss: 0.2345, D_B_loss: 0.1624, G_A_loss: 0.3397, G_B_loss: 0.1244\n",
            "Epoch [7/70], Step [231/1231], D_A_loss: 0.1336, D_B_loss: 0.1745, G_A_loss: 0.2969, G_B_loss: 0.1923\n",
            "Epoch [7/70], Step [241/1231], D_A_loss: 0.1121, D_B_loss: 0.1501, G_A_loss: 0.4309, G_B_loss: 0.9642\n",
            "Epoch [7/70], Step [251/1231], D_A_loss: 0.2397, D_B_loss: 0.0969, G_A_loss: 0.3986, G_B_loss: 0.4515\n",
            "Epoch [7/70], Step [261/1231], D_A_loss: 0.2874, D_B_loss: 0.3023, G_A_loss: 0.0963, G_B_loss: 0.2101\n",
            "Epoch [7/70], Step [271/1231], D_A_loss: 0.1321, D_B_loss: 0.0487, G_A_loss: 0.7294, G_B_loss: 0.3401\n",
            "Epoch [7/70], Step [281/1231], D_A_loss: 0.2992, D_B_loss: 0.1457, G_A_loss: 0.2917, G_B_loss: 0.1913\n",
            "Epoch [7/70], Step [291/1231], D_A_loss: 0.0537, D_B_loss: 0.3847, G_A_loss: 0.0938, G_B_loss: 0.5313\n",
            "Epoch [7/70], Step [301/1231], D_A_loss: 0.2138, D_B_loss: 0.0947, G_A_loss: 0.3976, G_B_loss: 0.1268\n",
            "Epoch [7/70], Step [311/1231], D_A_loss: 0.2952, D_B_loss: 0.1977, G_A_loss: 0.4310, G_B_loss: 0.0702\n",
            "Epoch [7/70], Step [321/1231], D_A_loss: 0.2823, D_B_loss: 0.2661, G_A_loss: 0.7680, G_B_loss: 0.1793\n",
            "Epoch [7/70], Step [331/1231], D_A_loss: 0.1217, D_B_loss: 0.1766, G_A_loss: 0.4133, G_B_loss: 0.4622\n",
            "Epoch [7/70], Step [341/1231], D_A_loss: 0.2176, D_B_loss: 0.1479, G_A_loss: 0.2271, G_B_loss: 0.3626\n",
            "Epoch [7/70], Step [351/1231], D_A_loss: 0.1963, D_B_loss: 0.1589, G_A_loss: 0.1587, G_B_loss: 0.2774\n",
            "Epoch [7/70], Step [361/1231], D_A_loss: 0.2199, D_B_loss: 0.1368, G_A_loss: 0.4589, G_B_loss: 0.6524\n",
            "Epoch [7/70], Step [371/1231], D_A_loss: 0.0531, D_B_loss: 0.0645, G_A_loss: 0.1706, G_B_loss: 0.4802\n",
            "Epoch [7/70], Step [381/1231], D_A_loss: 0.1245, D_B_loss: 0.1020, G_A_loss: 0.2413, G_B_loss: 0.5185\n",
            "Epoch [7/70], Step [391/1231], D_A_loss: 0.2848, D_B_loss: 0.1033, G_A_loss: 0.2587, G_B_loss: 0.1612\n",
            "Epoch [7/70], Step [401/1231], D_A_loss: 0.0421, D_B_loss: 0.0131, G_A_loss: 0.8741, G_B_loss: 0.3539\n",
            "Epoch [7/70], Step [411/1231], D_A_loss: 0.0570, D_B_loss: 0.1401, G_A_loss: 0.2626, G_B_loss: 0.0395\n",
            "Epoch [7/70], Step [421/1231], D_A_loss: 0.0246, D_B_loss: 0.2252, G_A_loss: 0.2710, G_B_loss: 0.2158\n",
            "Epoch [7/70], Step [431/1231], D_A_loss: 0.1227, D_B_loss: 0.0711, G_A_loss: 0.2301, G_B_loss: 0.3802\n",
            "Epoch [7/70], Step [441/1231], D_A_loss: 0.0753, D_B_loss: 0.0808, G_A_loss: 0.9505, G_B_loss: 0.0786\n",
            "Epoch [7/70], Step [451/1231], D_A_loss: 0.1207, D_B_loss: 0.1426, G_A_loss: 0.5372, G_B_loss: 0.4872\n",
            "Epoch [7/70], Step [461/1231], D_A_loss: 0.3056, D_B_loss: 0.0735, G_A_loss: 0.3033, G_B_loss: 0.1179\n",
            "Epoch [7/70], Step [471/1231], D_A_loss: 0.1902, D_B_loss: 0.1714, G_A_loss: 0.2329, G_B_loss: 0.2251\n",
            "Epoch [7/70], Step [481/1231], D_A_loss: 0.1338, D_B_loss: 0.0801, G_A_loss: 0.0623, G_B_loss: 0.3007\n",
            "Epoch [7/70], Step [491/1231], D_A_loss: 0.0698, D_B_loss: 0.0742, G_A_loss: 0.4555, G_B_loss: 0.1911\n",
            "Epoch [7/70], Step [501/1231], D_A_loss: 0.1279, D_B_loss: 0.2415, G_A_loss: 0.2558, G_B_loss: 0.8115\n",
            "Epoch [7/70], Step [511/1231], D_A_loss: 0.2923, D_B_loss: 0.0983, G_A_loss: 0.5223, G_B_loss: 0.4091\n",
            "Epoch [7/70], Step [521/1231], D_A_loss: 0.2797, D_B_loss: 0.3128, G_A_loss: 0.5231, G_B_loss: 0.0963\n",
            "Epoch [7/70], Step [531/1231], D_A_loss: 0.1679, D_B_loss: 0.2773, G_A_loss: 0.6012, G_B_loss: 0.1752\n",
            "Epoch [7/70], Step [541/1231], D_A_loss: 0.2674, D_B_loss: 0.3024, G_A_loss: 0.1423, G_B_loss: 0.5377\n",
            "Epoch [7/70], Step [551/1231], D_A_loss: 0.3832, D_B_loss: 0.1907, G_A_loss: 0.4038, G_B_loss: 0.0894\n",
            "Epoch [7/70], Step [561/1231], D_A_loss: 0.2367, D_B_loss: 0.1587, G_A_loss: 0.6758, G_B_loss: 0.3287\n",
            "Epoch [7/70], Step [571/1231], D_A_loss: 0.1528, D_B_loss: 0.0177, G_A_loss: 0.4435, G_B_loss: 0.3646\n",
            "Epoch [7/70], Step [581/1231], D_A_loss: 0.2168, D_B_loss: 0.0788, G_A_loss: 0.4895, G_B_loss: 0.1164\n",
            "Epoch [7/70], Step [591/1231], D_A_loss: 0.0605, D_B_loss: 0.2329, G_A_loss: 0.3899, G_B_loss: 0.0822\n",
            "Epoch [7/70], Step [601/1231], D_A_loss: 0.1225, D_B_loss: 0.1941, G_A_loss: 0.3285, G_B_loss: 0.5031\n",
            "Epoch [7/70], Step [611/1231], D_A_loss: 0.0583, D_B_loss: 0.1087, G_A_loss: 0.0826, G_B_loss: 0.3817\n",
            "Epoch [7/70], Step [621/1231], D_A_loss: 0.1496, D_B_loss: 0.0891, G_A_loss: 0.1999, G_B_loss: 0.3700\n",
            "Epoch [7/70], Step [631/1231], D_A_loss: 0.2389, D_B_loss: 0.1163, G_A_loss: 0.3677, G_B_loss: 0.2018\n",
            "Epoch [7/70], Step [641/1231], D_A_loss: 0.0756, D_B_loss: 0.1102, G_A_loss: 0.3742, G_B_loss: 0.1904\n",
            "Epoch [7/70], Step [651/1231], D_A_loss: 0.1679, D_B_loss: 0.1255, G_A_loss: 0.2723, G_B_loss: 0.3405\n",
            "Epoch [7/70], Step [661/1231], D_A_loss: 0.2866, D_B_loss: 0.1917, G_A_loss: 0.1844, G_B_loss: 0.2022\n",
            "Epoch [7/70], Step [671/1231], D_A_loss: 0.3333, D_B_loss: 0.0929, G_A_loss: 0.3884, G_B_loss: 0.1402\n",
            "Epoch [7/70], Step [681/1231], D_A_loss: 0.0384, D_B_loss: 0.2872, G_A_loss: 0.5945, G_B_loss: 0.4480\n",
            "Epoch [7/70], Step [691/1231], D_A_loss: 0.0717, D_B_loss: 0.0967, G_A_loss: 0.3140, G_B_loss: 0.3308\n",
            "Epoch [7/70], Step [701/1231], D_A_loss: 0.1059, D_B_loss: 0.0396, G_A_loss: 0.5323, G_B_loss: 0.5851\n",
            "Epoch [7/70], Step [711/1231], D_A_loss: 0.1073, D_B_loss: 0.1120, G_A_loss: 0.5474, G_B_loss: 0.3807\n",
            "Epoch [7/70], Step [721/1231], D_A_loss: 0.1893, D_B_loss: 0.0198, G_A_loss: 0.3395, G_B_loss: 0.1910\n",
            "Epoch [7/70], Step [731/1231], D_A_loss: 0.1480, D_B_loss: 0.1790, G_A_loss: 0.2855, G_B_loss: 0.1981\n",
            "Epoch [7/70], Step [741/1231], D_A_loss: 0.2010, D_B_loss: 0.1154, G_A_loss: 0.6475, G_B_loss: 0.1704\n",
            "Epoch [7/70], Step [751/1231], D_A_loss: 0.1279, D_B_loss: 0.1903, G_A_loss: 0.2369, G_B_loss: 0.3763\n",
            "Epoch [7/70], Step [761/1231], D_A_loss: 0.2120, D_B_loss: 0.4005, G_A_loss: 0.5715, G_B_loss: 0.7119\n",
            "Epoch [7/70], Step [771/1231], D_A_loss: 0.0687, D_B_loss: 0.0574, G_A_loss: 0.6288, G_B_loss: 0.3872\n",
            "Epoch [7/70], Step [781/1231], D_A_loss: 0.3249, D_B_loss: 0.2051, G_A_loss: 0.5776, G_B_loss: 0.2596\n",
            "Epoch [7/70], Step [791/1231], D_A_loss: 0.0890, D_B_loss: 0.0373, G_A_loss: 0.4697, G_B_loss: 0.4233\n",
            "Epoch [7/70], Step [801/1231], D_A_loss: 0.2715, D_B_loss: 0.2749, G_A_loss: 0.0822, G_B_loss: 0.5537\n",
            "Epoch [7/70], Step [811/1231], D_A_loss: 0.1998, D_B_loss: 0.0338, G_A_loss: 0.4549, G_B_loss: 0.4416\n",
            "Epoch [7/70], Step [821/1231], D_A_loss: 0.1885, D_B_loss: 0.3763, G_A_loss: 0.2724, G_B_loss: 0.2851\n",
            "Epoch [7/70], Step [831/1231], D_A_loss: 0.2890, D_B_loss: 0.0920, G_A_loss: 0.3774, G_B_loss: 1.3959\n",
            "Epoch [7/70], Step [841/1231], D_A_loss: 0.1194, D_B_loss: 0.0832, G_A_loss: 0.4868, G_B_loss: 0.6097\n",
            "Epoch [7/70], Step [851/1231], D_A_loss: 0.0615, D_B_loss: 0.1384, G_A_loss: 0.6253, G_B_loss: 0.4721\n",
            "Epoch [7/70], Step [861/1231], D_A_loss: 0.1320, D_B_loss: 0.0984, G_A_loss: 0.3938, G_B_loss: 0.1073\n",
            "Epoch [7/70], Step [871/1231], D_A_loss: 0.0379, D_B_loss: 0.1258, G_A_loss: 0.8979, G_B_loss: 0.1894\n",
            "Epoch [7/70], Step [881/1231], D_A_loss: 0.2102, D_B_loss: 0.1131, G_A_loss: 0.6878, G_B_loss: 0.6991\n",
            "Epoch [7/70], Step [891/1231], D_A_loss: 0.1683, D_B_loss: 0.0591, G_A_loss: 0.3775, G_B_loss: 0.2344\n",
            "Epoch [7/70], Step [901/1231], D_A_loss: 0.2199, D_B_loss: 0.1374, G_A_loss: 0.3116, G_B_loss: 0.4548\n",
            "Epoch [7/70], Step [911/1231], D_A_loss: 0.2559, D_B_loss: 0.0749, G_A_loss: 0.3868, G_B_loss: 0.2807\n",
            "Epoch [7/70], Step [921/1231], D_A_loss: 0.3816, D_B_loss: 0.0675, G_A_loss: 0.4884, G_B_loss: 0.0369\n",
            "Epoch [7/70], Step [931/1231], D_A_loss: 0.1082, D_B_loss: 0.1177, G_A_loss: 0.4211, G_B_loss: 0.4894\n",
            "Epoch [7/70], Step [941/1231], D_A_loss: 0.0904, D_B_loss: 0.0817, G_A_loss: 0.4481, G_B_loss: 0.0431\n",
            "Epoch [7/70], Step [951/1231], D_A_loss: 0.1562, D_B_loss: 0.2620, G_A_loss: 0.4688, G_B_loss: 0.2287\n",
            "Epoch [7/70], Step [961/1231], D_A_loss: 0.0293, D_B_loss: 0.1477, G_A_loss: 0.3209, G_B_loss: 0.6202\n",
            "Epoch [8/70], Step [1/1231], D_A_loss: 0.0406, D_B_loss: 0.0793, G_A_loss: 0.7256, G_B_loss: 0.4626\n",
            "Epoch [8/70], Step [11/1231], D_A_loss: 0.2803, D_B_loss: 0.0633, G_A_loss: 0.6882, G_B_loss: 0.1231\n",
            "Epoch [8/70], Step [21/1231], D_A_loss: 0.1688, D_B_loss: 0.0854, G_A_loss: 0.3037, G_B_loss: 0.3998\n",
            "Epoch [8/70], Step [31/1231], D_A_loss: 0.3005, D_B_loss: 0.0412, G_A_loss: 0.4510, G_B_loss: 0.3754\n",
            "Epoch [8/70], Step [41/1231], D_A_loss: 0.0385, D_B_loss: 0.3961, G_A_loss: 1.0394, G_B_loss: 0.4031\n",
            "Epoch [8/70], Step [51/1231], D_A_loss: 0.1912, D_B_loss: 0.0839, G_A_loss: 0.4517, G_B_loss: 0.5153\n",
            "Epoch [8/70], Step [61/1231], D_A_loss: 0.0672, D_B_loss: 0.2269, G_A_loss: 0.7719, G_B_loss: 0.3655\n",
            "Epoch [8/70], Step [71/1231], D_A_loss: 0.1459, D_B_loss: 0.2437, G_A_loss: 0.1193, G_B_loss: 0.6382\n",
            "Epoch [8/70], Step [81/1231], D_A_loss: 0.0991, D_B_loss: 0.0553, G_A_loss: 0.2842, G_B_loss: 0.3943\n",
            "Epoch [8/70], Step [91/1231], D_A_loss: 0.2111, D_B_loss: 0.1698, G_A_loss: 0.1596, G_B_loss: 0.6738\n",
            "Epoch [8/70], Step [101/1231], D_A_loss: 0.4102, D_B_loss: 0.1578, G_A_loss: 0.5767, G_B_loss: 0.2881\n",
            "Epoch [8/70], Step [111/1231], D_A_loss: 0.0492, D_B_loss: 0.1626, G_A_loss: 0.3501, G_B_loss: 0.1037\n",
            "Epoch [8/70], Step [121/1231], D_A_loss: 0.1278, D_B_loss: 0.0653, G_A_loss: 0.3700, G_B_loss: 0.3518\n",
            "Epoch [8/70], Step [131/1231], D_A_loss: 0.3168, D_B_loss: 0.2501, G_A_loss: 0.1096, G_B_loss: 0.0639\n",
            "Epoch [8/70], Step [141/1231], D_A_loss: 0.1648, D_B_loss: 0.1959, G_A_loss: 0.6083, G_B_loss: 0.6342\n",
            "Epoch [8/70], Step [151/1231], D_A_loss: 0.2213, D_B_loss: 0.0295, G_A_loss: 0.2971, G_B_loss: 0.1437\n",
            "Epoch [8/70], Step [161/1231], D_A_loss: 0.2866, D_B_loss: 0.1061, G_A_loss: 0.3612, G_B_loss: 0.1353\n",
            "Epoch [8/70], Step [171/1231], D_A_loss: 0.2110, D_B_loss: 0.2761, G_A_loss: 0.2113, G_B_loss: 0.4473\n",
            "Epoch [8/70], Step [181/1231], D_A_loss: 0.1628, D_B_loss: 0.0675, G_A_loss: 0.2252, G_B_loss: 0.2416\n",
            "Epoch [8/70], Step [191/1231], D_A_loss: 0.0751, D_B_loss: 0.1004, G_A_loss: 0.4858, G_B_loss: 0.4455\n",
            "Epoch [8/70], Step [201/1231], D_A_loss: 0.0741, D_B_loss: 0.1386, G_A_loss: 0.2824, G_B_loss: 0.5779\n",
            "Epoch [8/70], Step [211/1231], D_A_loss: 0.1778, D_B_loss: 0.2314, G_A_loss: 0.0933, G_B_loss: 0.5946\n",
            "Epoch [8/70], Step [221/1231], D_A_loss: 0.1107, D_B_loss: 0.2426, G_A_loss: 0.4737, G_B_loss: 0.2014\n",
            "Epoch [8/70], Step [231/1231], D_A_loss: 0.0885, D_B_loss: 0.0961, G_A_loss: 0.8534, G_B_loss: 0.3193\n",
            "Epoch [8/70], Step [241/1231], D_A_loss: 0.0769, D_B_loss: 0.0349, G_A_loss: 0.3833, G_B_loss: 0.4248\n",
            "Epoch [8/70], Step [251/1231], D_A_loss: 0.1057, D_B_loss: 0.0867, G_A_loss: 0.2231, G_B_loss: 0.3465\n",
            "Epoch [8/70], Step [261/1231], D_A_loss: 0.2154, D_B_loss: 0.1168, G_A_loss: 0.5274, G_B_loss: 0.4395\n",
            "Epoch [8/70], Step [271/1231], D_A_loss: 0.0551, D_B_loss: 0.0865, G_A_loss: 0.4018, G_B_loss: 0.4849\n",
            "Epoch [8/70], Step [281/1231], D_A_loss: 0.1805, D_B_loss: 0.0415, G_A_loss: 0.3951, G_B_loss: 0.4328\n",
            "Epoch [8/70], Step [291/1231], D_A_loss: 0.0990, D_B_loss: 0.1718, G_A_loss: 0.4989, G_B_loss: 0.3900\n",
            "Epoch [8/70], Step [301/1231], D_A_loss: 0.1477, D_B_loss: 0.0830, G_A_loss: 0.4121, G_B_loss: 0.1716\n",
            "Epoch [8/70], Step [311/1231], D_A_loss: 0.0700, D_B_loss: 0.0502, G_A_loss: 0.2656, G_B_loss: 0.0970\n",
            "Epoch [8/70], Step [321/1231], D_A_loss: 0.1311, D_B_loss: 0.0400, G_A_loss: 0.4973, G_B_loss: 0.3049\n",
            "Epoch [8/70], Step [331/1231], D_A_loss: 0.1538, D_B_loss: 0.0490, G_A_loss: 0.3379, G_B_loss: 0.5384\n",
            "Epoch [8/70], Step [341/1231], D_A_loss: 0.0538, D_B_loss: 0.2003, G_A_loss: 0.4090, G_B_loss: 0.1187\n",
            "Epoch [8/70], Step [351/1231], D_A_loss: 0.2332, D_B_loss: 0.1194, G_A_loss: 0.3707, G_B_loss: 0.3682\n",
            "Epoch [8/70], Step [361/1231], D_A_loss: 0.0459, D_B_loss: 0.2658, G_A_loss: 0.1969, G_B_loss: 0.0581\n",
            "Epoch [8/70], Step [371/1231], D_A_loss: 0.1895, D_B_loss: 0.0687, G_A_loss: 0.3102, G_B_loss: 0.7993\n",
            "Epoch [8/70], Step [381/1231], D_A_loss: 0.0868, D_B_loss: 0.2022, G_A_loss: 0.3612, G_B_loss: 0.4929\n",
            "Epoch [8/70], Step [391/1231], D_A_loss: 0.0587, D_B_loss: 0.1717, G_A_loss: 0.2680, G_B_loss: 0.2371\n",
            "Epoch [8/70], Step [401/1231], D_A_loss: 0.2345, D_B_loss: 0.2192, G_A_loss: 0.1501, G_B_loss: 1.3602\n",
            "Epoch [8/70], Step [411/1231], D_A_loss: 0.2918, D_B_loss: 0.1545, G_A_loss: 0.4132, G_B_loss: 0.1052\n",
            "Epoch [8/70], Step [421/1231], D_A_loss: 0.1079, D_B_loss: 0.1323, G_A_loss: 0.4559, G_B_loss: 0.3463\n",
            "Epoch [8/70], Step [431/1231], D_A_loss: 0.0882, D_B_loss: 0.1734, G_A_loss: 0.3762, G_B_loss: 0.4139\n",
            "Epoch [8/70], Step [441/1231], D_A_loss: 0.1361, D_B_loss: 0.0901, G_A_loss: 0.8307, G_B_loss: 0.4217\n",
            "Epoch [8/70], Step [451/1231], D_A_loss: 0.2303, D_B_loss: 0.1401, G_A_loss: 0.2787, G_B_loss: 0.3755\n",
            "Epoch [8/70], Step [461/1231], D_A_loss: 0.2014, D_B_loss: 0.1382, G_A_loss: 0.3362, G_B_loss: 0.4237\n",
            "Epoch [8/70], Step [471/1231], D_A_loss: 0.0777, D_B_loss: 0.0978, G_A_loss: 0.3395, G_B_loss: 0.3428\n",
            "Epoch [8/70], Step [481/1231], D_A_loss: 0.1945, D_B_loss: 0.0447, G_A_loss: 0.3631, G_B_loss: 0.2541\n",
            "Epoch [8/70], Step [491/1231], D_A_loss: 0.1109, D_B_loss: 0.1335, G_A_loss: 0.3867, G_B_loss: 0.3585\n",
            "Epoch [8/70], Step [501/1231], D_A_loss: 0.0844, D_B_loss: 0.1038, G_A_loss: 0.5817, G_B_loss: 0.4041\n",
            "Epoch [8/70], Step [511/1231], D_A_loss: 0.1052, D_B_loss: 0.2681, G_A_loss: 0.6135, G_B_loss: 0.2828\n",
            "Epoch [8/70], Step [521/1231], D_A_loss: 0.0642, D_B_loss: 0.1017, G_A_loss: 0.6895, G_B_loss: 1.1989\n",
            "Epoch [8/70], Step [531/1231], D_A_loss: 0.4090, D_B_loss: 0.3266, G_A_loss: 0.6309, G_B_loss: 0.8805\n",
            "Epoch [8/70], Step [541/1231], D_A_loss: 0.0985, D_B_loss: 0.0649, G_A_loss: 0.3678, G_B_loss: 0.4188\n",
            "Epoch [8/70], Step [551/1231], D_A_loss: 0.0485, D_B_loss: 0.0637, G_A_loss: 0.4351, G_B_loss: 0.0523\n",
            "Epoch [8/70], Step [561/1231], D_A_loss: 0.2790, D_B_loss: 0.0362, G_A_loss: 0.6309, G_B_loss: 0.2551\n",
            "Epoch [8/70], Step [571/1231], D_A_loss: 0.1807, D_B_loss: 0.1909, G_A_loss: 0.3604, G_B_loss: 0.6082\n",
            "Epoch [8/70], Step [581/1231], D_A_loss: 0.2028, D_B_loss: 0.1001, G_A_loss: 0.3810, G_B_loss: 0.2067\n",
            "Epoch [8/70], Step [591/1231], D_A_loss: 0.1687, D_B_loss: 0.1524, G_A_loss: 0.5585, G_B_loss: 0.2129\n",
            "Epoch [8/70], Step [601/1231], D_A_loss: 0.2218, D_B_loss: 0.2382, G_A_loss: 0.5921, G_B_loss: 0.2943\n",
            "Epoch [8/70], Step [611/1231], D_A_loss: 0.0589, D_B_loss: 0.2306, G_A_loss: 0.7795, G_B_loss: 0.1944\n",
            "Epoch [8/70], Step [621/1231], D_A_loss: 0.0476, D_B_loss: 0.1120, G_A_loss: 0.4047, G_B_loss: 0.6374\n",
            "Epoch [8/70], Step [631/1231], D_A_loss: 0.2620, D_B_loss: 0.0886, G_A_loss: 0.1411, G_B_loss: 0.5085\n",
            "Epoch [8/70], Step [641/1231], D_A_loss: 0.2675, D_B_loss: 0.0727, G_A_loss: 0.3870, G_B_loss: 0.1099\n",
            "Epoch [8/70], Step [651/1231], D_A_loss: 0.1841, D_B_loss: 0.1293, G_A_loss: 0.6034, G_B_loss: 0.2044\n",
            "Epoch [8/70], Step [661/1231], D_A_loss: 0.1717, D_B_loss: 0.1492, G_A_loss: 0.4130, G_B_loss: 0.5264\n",
            "Epoch [8/70], Step [671/1231], D_A_loss: 0.0578, D_B_loss: 0.1806, G_A_loss: 0.2240, G_B_loss: 0.5413\n",
            "Epoch [8/70], Step [681/1231], D_A_loss: 0.1051, D_B_loss: 0.2169, G_A_loss: 0.2574, G_B_loss: 0.4539\n",
            "Epoch [8/70], Step [691/1231], D_A_loss: 0.2050, D_B_loss: 0.0571, G_A_loss: 0.1892, G_B_loss: 0.3648\n",
            "Epoch [8/70], Step [701/1231], D_A_loss: 0.1410, D_B_loss: 0.0501, G_A_loss: 0.8794, G_B_loss: 0.4609\n",
            "Epoch [8/70], Step [711/1231], D_A_loss: 0.2245, D_B_loss: 0.3307, G_A_loss: 0.0873, G_B_loss: 0.4839\n",
            "Epoch [8/70], Step [721/1231], D_A_loss: 0.2723, D_B_loss: 0.0525, G_A_loss: 0.5882, G_B_loss: 0.2452\n",
            "Epoch [8/70], Step [731/1231], D_A_loss: 0.1783, D_B_loss: 0.1863, G_A_loss: 0.6723, G_B_loss: 0.2409\n",
            "Epoch [8/70], Step [741/1231], D_A_loss: 0.0259, D_B_loss: 0.0985, G_A_loss: 0.4902, G_B_loss: 0.3748\n",
            "Epoch [8/70], Step [751/1231], D_A_loss: 0.1971, D_B_loss: 0.0657, G_A_loss: 0.5024, G_B_loss: 0.1954\n",
            "Epoch [8/70], Step [761/1231], D_A_loss: 0.3315, D_B_loss: 0.1184, G_A_loss: 0.3838, G_B_loss: 0.0633\n",
            "Epoch [8/70], Step [771/1231], D_A_loss: 0.2868, D_B_loss: 0.1617, G_A_loss: 0.4386, G_B_loss: 0.6368\n",
            "Epoch [8/70], Step [781/1231], D_A_loss: 0.0752, D_B_loss: 0.0373, G_A_loss: 0.4071, G_B_loss: 0.3574\n",
            "Epoch [8/70], Step [791/1231], D_A_loss: 0.1700, D_B_loss: 0.1125, G_A_loss: 0.2421, G_B_loss: 0.2495\n",
            "Epoch [8/70], Step [801/1231], D_A_loss: 0.1430, D_B_loss: 0.1304, G_A_loss: 0.3589, G_B_loss: 0.2779\n",
            "Epoch [8/70], Step [811/1231], D_A_loss: 0.1327, D_B_loss: 0.0352, G_A_loss: 0.5271, G_B_loss: 0.2678\n",
            "Epoch [8/70], Step [821/1231], D_A_loss: 0.0816, D_B_loss: 0.0474, G_A_loss: 0.3247, G_B_loss: 0.5570\n",
            "Epoch [8/70], Step [831/1231], D_A_loss: 0.2380, D_B_loss: 0.2546, G_A_loss: 0.1415, G_B_loss: 0.2508\n",
            "Epoch [8/70], Step [841/1231], D_A_loss: 0.2528, D_B_loss: 0.1575, G_A_loss: 0.5559, G_B_loss: 0.0561\n",
            "Epoch [8/70], Step [851/1231], D_A_loss: 0.0779, D_B_loss: 0.3532, G_A_loss: 0.0576, G_B_loss: 0.3710\n",
            "Epoch [8/70], Step [861/1231], D_A_loss: 0.1254, D_B_loss: 0.1561, G_A_loss: 0.3304, G_B_loss: 0.6198\n",
            "Epoch [8/70], Step [871/1231], D_A_loss: 0.2329, D_B_loss: 0.4397, G_A_loss: 0.3018, G_B_loss: 0.1812\n",
            "Epoch [8/70], Step [881/1231], D_A_loss: 0.1075, D_B_loss: 0.1828, G_A_loss: 0.4042, G_B_loss: 0.3809\n",
            "Epoch [8/70], Step [891/1231], D_A_loss: 0.1127, D_B_loss: 0.2146, G_A_loss: 0.5648, G_B_loss: 0.2965\n",
            "Epoch [8/70], Step [901/1231], D_A_loss: 0.0897, D_B_loss: 0.3480, G_A_loss: 0.3157, G_B_loss: 0.7593\n",
            "Epoch [8/70], Step [911/1231], D_A_loss: 0.2227, D_B_loss: 0.0643, G_A_loss: 0.1999, G_B_loss: 0.4090\n",
            "Epoch [8/70], Step [921/1231], D_A_loss: 0.4259, D_B_loss: 0.2134, G_A_loss: 0.1577, G_B_loss: 0.0382\n",
            "Epoch [8/70], Step [931/1231], D_A_loss: 0.1867, D_B_loss: 0.1201, G_A_loss: 0.3325, G_B_loss: 0.1866\n",
            "Epoch [8/70], Step [941/1231], D_A_loss: 0.1409, D_B_loss: 0.0835, G_A_loss: 0.4255, G_B_loss: 0.9665\n",
            "Epoch [8/70], Step [951/1231], D_A_loss: 0.0880, D_B_loss: 0.2572, G_A_loss: 0.1179, G_B_loss: 0.5213\n",
            "Epoch [8/70], Step [961/1231], D_A_loss: 0.2530, D_B_loss: 0.2028, G_A_loss: 0.1705, G_B_loss: 0.1493\n",
            "Epoch [9/70], Step [1/1231], D_A_loss: 0.0994, D_B_loss: 0.1051, G_A_loss: 0.7293, G_B_loss: 0.5394\n",
            "Epoch [9/70], Step [11/1231], D_A_loss: 0.0406, D_B_loss: 0.2092, G_A_loss: 0.5249, G_B_loss: 0.1655\n",
            "Epoch [9/70], Step [21/1231], D_A_loss: 0.0334, D_B_loss: 0.1542, G_A_loss: 0.2803, G_B_loss: 0.8411\n",
            "Epoch [9/70], Step [31/1231], D_A_loss: 0.1514, D_B_loss: 0.1014, G_A_loss: 0.1790, G_B_loss: 0.5156\n",
            "Epoch [9/70], Step [41/1231], D_A_loss: 0.1355, D_B_loss: 0.1321, G_A_loss: 0.9774, G_B_loss: 0.3271\n",
            "Epoch [9/70], Step [51/1231], D_A_loss: 0.2084, D_B_loss: 0.0611, G_A_loss: 0.6842, G_B_loss: 0.1744\n",
            "Epoch [9/70], Step [61/1231], D_A_loss: 0.1867, D_B_loss: 0.0549, G_A_loss: 0.4251, G_B_loss: 0.2162\n",
            "Epoch [9/70], Step [71/1231], D_A_loss: 0.0972, D_B_loss: 0.2235, G_A_loss: 0.4694, G_B_loss: 0.5688\n",
            "Epoch [9/70], Step [81/1231], D_A_loss: 0.0874, D_B_loss: 0.1821, G_A_loss: 0.2132, G_B_loss: 0.3557\n",
            "Epoch [9/70], Step [91/1231], D_A_loss: 0.2067, D_B_loss: 0.1698, G_A_loss: 0.4350, G_B_loss: 0.7327\n",
            "Epoch [9/70], Step [101/1231], D_A_loss: 0.0410, D_B_loss: 0.0957, G_A_loss: 0.4480, G_B_loss: 0.5965\n",
            "Epoch [9/70], Step [111/1231], D_A_loss: 0.1327, D_B_loss: 0.1170, G_A_loss: 0.4781, G_B_loss: 0.2191\n",
            "Epoch [9/70], Step [121/1231], D_A_loss: 0.2682, D_B_loss: 0.1056, G_A_loss: 0.4290, G_B_loss: 0.1990\n",
            "Epoch [9/70], Step [131/1231], D_A_loss: 0.2367, D_B_loss: 0.0253, G_A_loss: 0.3305, G_B_loss: 0.3604\n",
            "Epoch [9/70], Step [141/1231], D_A_loss: 0.1050, D_B_loss: 0.0287, G_A_loss: 0.1813, G_B_loss: 0.1648\n",
            "Epoch [9/70], Step [151/1231], D_A_loss: 0.2468, D_B_loss: 0.1319, G_A_loss: 0.4444, G_B_loss: 0.1651\n",
            "Epoch [9/70], Step [161/1231], D_A_loss: 0.1505, D_B_loss: 0.0389, G_A_loss: 0.1738, G_B_loss: 0.2635\n",
            "Epoch [9/70], Step [171/1231], D_A_loss: 0.0954, D_B_loss: 0.1897, G_A_loss: 0.1543, G_B_loss: 0.1605\n",
            "Epoch [9/70], Step [181/1231], D_A_loss: 0.1143, D_B_loss: 0.0565, G_A_loss: 0.3623, G_B_loss: 0.0335\n",
            "Epoch [9/70], Step [191/1231], D_A_loss: 0.0340, D_B_loss: 0.0679, G_A_loss: 0.2170, G_B_loss: 0.1603\n",
            "Epoch [9/70], Step [201/1231], D_A_loss: 0.2018, D_B_loss: 0.0551, G_A_loss: 0.2684, G_B_loss: 0.3707\n",
            "Epoch [9/70], Step [211/1231], D_A_loss: 0.1779, D_B_loss: 0.1390, G_A_loss: 0.4706, G_B_loss: 0.1264\n",
            "Epoch [9/70], Step [221/1231], D_A_loss: 0.0694, D_B_loss: 0.1659, G_A_loss: 0.2635, G_B_loss: 0.4683\n",
            "Epoch [9/70], Step [231/1231], D_A_loss: 0.0847, D_B_loss: 0.0739, G_A_loss: 0.1591, G_B_loss: 0.0872\n",
            "Epoch [9/70], Step [241/1231], D_A_loss: 0.0762, D_B_loss: 0.0739, G_A_loss: 0.1530, G_B_loss: 0.2678\n",
            "Epoch [9/70], Step [251/1231], D_A_loss: 0.0350, D_B_loss: 0.0648, G_A_loss: 0.4707, G_B_loss: 0.9523\n",
            "Epoch [9/70], Step [261/1231], D_A_loss: 0.1707, D_B_loss: 0.2720, G_A_loss: 0.1827, G_B_loss: 0.2339\n",
            "Epoch [9/70], Step [271/1231], D_A_loss: 0.1762, D_B_loss: 0.0863, G_A_loss: 0.5905, G_B_loss: 0.2151\n",
            "Epoch [9/70], Step [281/1231], D_A_loss: 0.1838, D_B_loss: 0.2270, G_A_loss: 0.0294, G_B_loss: 0.2155\n",
            "Epoch [9/70], Step [291/1231], D_A_loss: 0.0995, D_B_loss: 0.2006, G_A_loss: 0.1957, G_B_loss: 0.4708\n",
            "Epoch [9/70], Step [301/1231], D_A_loss: 0.2124, D_B_loss: 0.2481, G_A_loss: 0.1663, G_B_loss: 0.4410\n",
            "Epoch [9/70], Step [311/1231], D_A_loss: 0.1113, D_B_loss: 0.0332, G_A_loss: 0.6878, G_B_loss: 0.1596\n",
            "Epoch [9/70], Step [321/1231], D_A_loss: 0.0205, D_B_loss: 0.1444, G_A_loss: 0.6452, G_B_loss: 0.7403\n",
            "Epoch [9/70], Step [331/1231], D_A_loss: 0.0286, D_B_loss: 0.1967, G_A_loss: 0.2533, G_B_loss: 0.5572\n",
            "Epoch [9/70], Step [341/1231], D_A_loss: 0.2128, D_B_loss: 0.1136, G_A_loss: 0.1335, G_B_loss: 0.2311\n",
            "Epoch [9/70], Step [351/1231], D_A_loss: 0.2442, D_B_loss: 0.1883, G_A_loss: 0.5589, G_B_loss: 0.1144\n",
            "Epoch [9/70], Step [361/1231], D_A_loss: 0.1390, D_B_loss: 0.1014, G_A_loss: 0.4759, G_B_loss: 0.4455\n",
            "Epoch [9/70], Step [371/1231], D_A_loss: 0.0762, D_B_loss: 0.0612, G_A_loss: 0.9260, G_B_loss: 0.4510\n",
            "Epoch [9/70], Step [381/1231], D_A_loss: 0.0699, D_B_loss: 0.1100, G_A_loss: 0.2762, G_B_loss: 0.2278\n",
            "Epoch [9/70], Step [391/1231], D_A_loss: 0.2438, D_B_loss: 0.1519, G_A_loss: 0.2979, G_B_loss: 0.1769\n",
            "Epoch [9/70], Step [401/1231], D_A_loss: 0.0787, D_B_loss: 0.0388, G_A_loss: 0.2496, G_B_loss: 0.9715\n",
            "Epoch [9/70], Step [411/1231], D_A_loss: 0.1695, D_B_loss: 0.2321, G_A_loss: 0.3705, G_B_loss: 0.4109\n",
            "Epoch [9/70], Step [421/1231], D_A_loss: 0.1110, D_B_loss: 0.0952, G_A_loss: 0.5695, G_B_loss: 0.3217\n",
            "Epoch [9/70], Step [431/1231], D_A_loss: 0.0662, D_B_loss: 0.1035, G_A_loss: 0.4153, G_B_loss: 0.9166\n",
            "Epoch [9/70], Step [441/1231], D_A_loss: 0.4219, D_B_loss: 0.2316, G_A_loss: 0.6902, G_B_loss: 0.0301\n",
            "Epoch [9/70], Step [451/1231], D_A_loss: 0.0318, D_B_loss: 0.1276, G_A_loss: 0.6378, G_B_loss: 0.4043\n",
            "Epoch [9/70], Step [461/1231], D_A_loss: 0.0762, D_B_loss: 0.0946, G_A_loss: 0.5002, G_B_loss: 0.0957\n",
            "Epoch [9/70], Step [471/1231], D_A_loss: 0.2474, D_B_loss: 0.1850, G_A_loss: 0.2870, G_B_loss: 0.1203\n",
            "Epoch [9/70], Step [481/1231], D_A_loss: 0.1360, D_B_loss: 0.1408, G_A_loss: 0.4383, G_B_loss: 0.3278\n",
            "Epoch [9/70], Step [491/1231], D_A_loss: 0.1088, D_B_loss: 0.0630, G_A_loss: 1.0025, G_B_loss: 0.3323\n",
            "Epoch [9/70], Step [501/1231], D_A_loss: 0.0795, D_B_loss: 0.1688, G_A_loss: 0.4785, G_B_loss: 0.8662\n",
            "Epoch [9/70], Step [511/1231], D_A_loss: 0.1492, D_B_loss: 0.2051, G_A_loss: 0.6791, G_B_loss: 0.6589\n",
            "Epoch [9/70], Step [521/1231], D_A_loss: 0.1207, D_B_loss: 0.1342, G_A_loss: 0.3413, G_B_loss: 0.4472\n",
            "Epoch [9/70], Step [531/1231], D_A_loss: 0.0529, D_B_loss: 0.0894, G_A_loss: 0.2782, G_B_loss: 0.2393\n",
            "Epoch [9/70], Step [541/1231], D_A_loss: 0.1621, D_B_loss: 0.2569, G_A_loss: 0.1640, G_B_loss: 0.3492\n",
            "Epoch [9/70], Step [551/1231], D_A_loss: 0.1557, D_B_loss: 0.1918, G_A_loss: 0.7495, G_B_loss: 0.2605\n",
            "Epoch [9/70], Step [561/1231], D_A_loss: 0.3008, D_B_loss: 0.1059, G_A_loss: 0.6498, G_B_loss: 0.3079\n",
            "Epoch [9/70], Step [571/1231], D_A_loss: 0.1515, D_B_loss: 0.0414, G_A_loss: 0.3672, G_B_loss: 0.4014\n",
            "Epoch [9/70], Step [581/1231], D_A_loss: 0.1599, D_B_loss: 0.1705, G_A_loss: 0.4848, G_B_loss: 0.2710\n",
            "Epoch [9/70], Step [591/1231], D_A_loss: 0.1906, D_B_loss: 0.1678, G_A_loss: 0.4123, G_B_loss: 0.1473\n",
            "Epoch [9/70], Step [601/1231], D_A_loss: 0.1452, D_B_loss: 0.0669, G_A_loss: 0.2660, G_B_loss: 0.2751\n",
            "Epoch [9/70], Step [611/1231], D_A_loss: 0.0877, D_B_loss: 0.1340, G_A_loss: 0.3906, G_B_loss: 0.4794\n",
            "Epoch [9/70], Step [621/1231], D_A_loss: 0.3524, D_B_loss: 0.2782, G_A_loss: 0.1611, G_B_loss: 0.4161\n",
            "Epoch [9/70], Step [631/1231], D_A_loss: 0.0551, D_B_loss: 0.0419, G_A_loss: 0.1861, G_B_loss: 0.8937\n",
            "Epoch [9/70], Step [641/1231], D_A_loss: 0.3540, D_B_loss: 0.0754, G_A_loss: 0.2212, G_B_loss: 0.3079\n",
            "Epoch [9/70], Step [651/1231], D_A_loss: 0.0999, D_B_loss: 0.0572, G_A_loss: 0.2761, G_B_loss: 0.1761\n",
            "Epoch [9/70], Step [661/1231], D_A_loss: 0.0494, D_B_loss: 0.2166, G_A_loss: 0.3018, G_B_loss: 0.6119\n",
            "Epoch [9/70], Step [671/1231], D_A_loss: 0.1848, D_B_loss: 0.3387, G_A_loss: 0.0617, G_B_loss: 0.5412\n",
            "Epoch [9/70], Step [681/1231], D_A_loss: 0.1364, D_B_loss: 0.1187, G_A_loss: 0.6849, G_B_loss: 0.2467\n",
            "Epoch [9/70], Step [691/1231], D_A_loss: 0.3594, D_B_loss: 0.0497, G_A_loss: 0.5717, G_B_loss: 0.0551\n",
            "Epoch [9/70], Step [701/1231], D_A_loss: 0.0582, D_B_loss: 0.2523, G_A_loss: 0.4672, G_B_loss: 0.2954\n",
            "Epoch [9/70], Step [711/1231], D_A_loss: 0.0910, D_B_loss: 0.2012, G_A_loss: 0.3961, G_B_loss: 0.0487\n",
            "Epoch [9/70], Step [721/1231], D_A_loss: 0.1303, D_B_loss: 0.1240, G_A_loss: 0.3245, G_B_loss: 0.2566\n",
            "Epoch [9/70], Step [731/1231], D_A_loss: 0.0883, D_B_loss: 0.2762, G_A_loss: 0.6174, G_B_loss: 0.2045\n",
            "Epoch [9/70], Step [741/1231], D_A_loss: 0.2141, D_B_loss: 0.0624, G_A_loss: 0.6166, G_B_loss: 0.2462\n",
            "Epoch [9/70], Step [751/1231], D_A_loss: 0.1039, D_B_loss: 0.2363, G_A_loss: 0.5757, G_B_loss: 0.2180\n",
            "Epoch [9/70], Step [761/1231], D_A_loss: 0.1963, D_B_loss: 0.0916, G_A_loss: 0.3655, G_B_loss: 1.1394\n",
            "Epoch [9/70], Step [771/1231], D_A_loss: 0.0972, D_B_loss: 0.1218, G_A_loss: 0.3844, G_B_loss: 0.1790\n",
            "Epoch [9/70], Step [781/1231], D_A_loss: 0.1327, D_B_loss: 0.0476, G_A_loss: 0.2891, G_B_loss: 0.7614\n",
            "Epoch [9/70], Step [791/1231], D_A_loss: 0.1477, D_B_loss: 0.1342, G_A_loss: 0.3564, G_B_loss: 0.2894\n",
            "Epoch [9/70], Step [801/1231], D_A_loss: 0.2332, D_B_loss: 0.1961, G_A_loss: 0.3092, G_B_loss: 0.1946\n",
            "Epoch [9/70], Step [811/1231], D_A_loss: 0.1072, D_B_loss: 0.0271, G_A_loss: 0.6612, G_B_loss: 0.8296\n",
            "Epoch [9/70], Step [821/1231], D_A_loss: 0.4745, D_B_loss: 0.1860, G_A_loss: 0.2753, G_B_loss: 0.0651\n",
            "Epoch [9/70], Step [831/1231], D_A_loss: 0.0708, D_B_loss: 0.1606, G_A_loss: 0.2336, G_B_loss: 0.4169\n",
            "Epoch [9/70], Step [841/1231], D_A_loss: 0.0510, D_B_loss: 0.1884, G_A_loss: 0.1529, G_B_loss: 0.2911\n",
            "Epoch [9/70], Step [851/1231], D_A_loss: 0.1516, D_B_loss: 0.2420, G_A_loss: 0.2887, G_B_loss: 0.4813\n",
            "Epoch [9/70], Step [861/1231], D_A_loss: 0.1166, D_B_loss: 0.0215, G_A_loss: 0.6883, G_B_loss: 0.3499\n",
            "Epoch [9/70], Step [871/1231], D_A_loss: 0.1205, D_B_loss: 0.0569, G_A_loss: 0.2641, G_B_loss: 0.5766\n",
            "Epoch [9/70], Step [881/1231], D_A_loss: 0.2964, D_B_loss: 0.0942, G_A_loss: 0.3525, G_B_loss: 0.5848\n",
            "Epoch [9/70], Step [891/1231], D_A_loss: 0.1342, D_B_loss: 0.1442, G_A_loss: 0.3289, G_B_loss: 0.3618\n",
            "Epoch [9/70], Step [901/1231], D_A_loss: 0.0777, D_B_loss: 0.1214, G_A_loss: 0.4286, G_B_loss: 0.6143\n",
            "Epoch [9/70], Step [911/1231], D_A_loss: 0.0261, D_B_loss: 0.0856, G_A_loss: 0.2804, G_B_loss: 0.7470\n",
            "Epoch [9/70], Step [921/1231], D_A_loss: 0.0907, D_B_loss: 0.0554, G_A_loss: 0.1077, G_B_loss: 0.2339\n",
            "Epoch [9/70], Step [931/1231], D_A_loss: 0.0484, D_B_loss: 0.1247, G_A_loss: 0.4458, G_B_loss: 0.3498\n",
            "Epoch [9/70], Step [941/1231], D_A_loss: 0.0766, D_B_loss: 0.0287, G_A_loss: 0.2612, G_B_loss: 0.1458\n",
            "Epoch [9/70], Step [951/1231], D_A_loss: 0.0561, D_B_loss: 0.1188, G_A_loss: 0.3550, G_B_loss: 0.4607\n",
            "Epoch [9/70], Step [961/1231], D_A_loss: 0.1067, D_B_loss: 0.2523, G_A_loss: 0.1842, G_B_loss: 0.3879\n",
            "Epoch [10/70], Step [1/1231], D_A_loss: 0.1120, D_B_loss: 0.1315, G_A_loss: 0.3488, G_B_loss: 0.2785\n",
            "Epoch [10/70], Step [11/1231], D_A_loss: 0.1206, D_B_loss: 0.2088, G_A_loss: 0.4857, G_B_loss: 0.2027\n",
            "Epoch [10/70], Step [21/1231], D_A_loss: 0.1470, D_B_loss: 0.2315, G_A_loss: 0.1541, G_B_loss: 1.1597\n",
            "Epoch [10/70], Step [31/1231], D_A_loss: 0.2417, D_B_loss: 0.1898, G_A_loss: 0.2091, G_B_loss: 0.2177\n",
            "Epoch [10/70], Step [41/1231], D_A_loss: 0.2941, D_B_loss: 0.1092, G_A_loss: 0.4391, G_B_loss: 0.1068\n",
            "Epoch [10/70], Step [51/1231], D_A_loss: 0.1072, D_B_loss: 0.1120, G_A_loss: 0.4149, G_B_loss: 0.7211\n",
            "Epoch [10/70], Step [61/1231], D_A_loss: 0.1934, D_B_loss: 0.0810, G_A_loss: 0.4275, G_B_loss: 0.4262\n",
            "Epoch [10/70], Step [71/1231], D_A_loss: 0.0525, D_B_loss: 0.1977, G_A_loss: 0.4233, G_B_loss: 0.2152\n",
            "Epoch [10/70], Step [81/1231], D_A_loss: 0.3846, D_B_loss: 0.1931, G_A_loss: 0.4125, G_B_loss: 0.2834\n",
            "Epoch [10/70], Step [91/1231], D_A_loss: 0.0468, D_B_loss: 0.0501, G_A_loss: 0.3053, G_B_loss: 0.3264\n",
            "Epoch [10/70], Step [101/1231], D_A_loss: 0.1662, D_B_loss: 0.0539, G_A_loss: 0.5689, G_B_loss: 0.2984\n",
            "Epoch [10/70], Step [111/1231], D_A_loss: 0.0795, D_B_loss: 0.2412, G_A_loss: 0.7021, G_B_loss: 0.2246\n",
            "Epoch [10/70], Step [121/1231], D_A_loss: 0.1351, D_B_loss: 0.0464, G_A_loss: 0.2486, G_B_loss: 0.4003\n",
            "Epoch [10/70], Step [131/1231], D_A_loss: 0.1330, D_B_loss: 0.0590, G_A_loss: 0.5802, G_B_loss: 0.0984\n",
            "Epoch [10/70], Step [141/1231], D_A_loss: 0.3602, D_B_loss: 0.4778, G_A_loss: 0.0630, G_B_loss: 0.0604\n",
            "Epoch [10/70], Step [151/1231], D_A_loss: 0.0208, D_B_loss: 0.0456, G_A_loss: 0.5509, G_B_loss: 0.1083\n",
            "Epoch [10/70], Step [161/1231], D_A_loss: 0.3975, D_B_loss: 0.1000, G_A_loss: 0.7681, G_B_loss: 0.0341\n",
            "Epoch [10/70], Step [171/1231], D_A_loss: 0.1293, D_B_loss: 0.1268, G_A_loss: 0.4849, G_B_loss: 0.3246\n",
            "Epoch [10/70], Step [181/1231], D_A_loss: 0.1927, D_B_loss: 0.2330, G_A_loss: 0.4837, G_B_loss: 0.2565\n",
            "Epoch [10/70], Step [191/1231], D_A_loss: 0.2101, D_B_loss: 0.2321, G_A_loss: 0.3330, G_B_loss: 0.3304\n",
            "Epoch [10/70], Step [201/1231], D_A_loss: 0.1909, D_B_loss: 0.0930, G_A_loss: 0.5338, G_B_loss: 0.6217\n",
            "Epoch [10/70], Step [211/1231], D_A_loss: 0.1130, D_B_loss: 0.1371, G_A_loss: 0.2792, G_B_loss: 0.3573\n",
            "Epoch [10/70], Step [221/1231], D_A_loss: 0.1185, D_B_loss: 0.1386, G_A_loss: 0.6172, G_B_loss: 0.2236\n",
            "Epoch [10/70], Step [231/1231], D_A_loss: 0.0777, D_B_loss: 0.0332, G_A_loss: 0.4267, G_B_loss: 0.4544\n",
            "Epoch [10/70], Step [241/1231], D_A_loss: 0.1131, D_B_loss: 0.0559, G_A_loss: 0.5476, G_B_loss: 0.3707\n",
            "Epoch [10/70], Step [251/1231], D_A_loss: 0.1972, D_B_loss: 0.0460, G_A_loss: 0.3680, G_B_loss: 0.6801\n",
            "Epoch [10/70], Step [261/1231], D_A_loss: 0.2005, D_B_loss: 0.0839, G_A_loss: 0.4985, G_B_loss: 0.2180\n",
            "Epoch [10/70], Step [271/1231], D_A_loss: 0.1482, D_B_loss: 0.2091, G_A_loss: 0.5899, G_B_loss: 0.4596\n",
            "Epoch [10/70], Step [281/1231], D_A_loss: 0.1928, D_B_loss: 0.1050, G_A_loss: 0.1843, G_B_loss: 0.2802\n",
            "Epoch [10/70], Step [291/1231], D_A_loss: 0.1070, D_B_loss: 0.1660, G_A_loss: 0.2553, G_B_loss: 0.5033\n",
            "Epoch [10/70], Step [301/1231], D_A_loss: 0.1167, D_B_loss: 0.0402, G_A_loss: 0.6289, G_B_loss: 0.3976\n",
            "Epoch [10/70], Step [311/1231], D_A_loss: 0.2342, D_B_loss: 0.0739, G_A_loss: 0.5758, G_B_loss: 0.4338\n",
            "Epoch [10/70], Step [321/1231], D_A_loss: 0.1156, D_B_loss: 0.1137, G_A_loss: 0.4334, G_B_loss: 0.6835\n",
            "Epoch [10/70], Step [331/1231], D_A_loss: 0.1267, D_B_loss: 0.0470, G_A_loss: 0.5111, G_B_loss: 0.4900\n",
            "Epoch [10/70], Step [341/1231], D_A_loss: 0.1235, D_B_loss: 0.0656, G_A_loss: 0.1865, G_B_loss: 0.3600\n",
            "Epoch [10/70], Step [351/1231], D_A_loss: 0.3306, D_B_loss: 0.0695, G_A_loss: 0.4839, G_B_loss: 1.2767\n",
            "Epoch [10/70], Step [361/1231], D_A_loss: 0.2855, D_B_loss: 0.1520, G_A_loss: 0.5949, G_B_loss: 0.1274\n",
            "Epoch [10/70], Step [371/1231], D_A_loss: 0.0962, D_B_loss: 0.1012, G_A_loss: 0.2085, G_B_loss: 0.4506\n",
            "Epoch [10/70], Step [381/1231], D_A_loss: 0.1043, D_B_loss: 0.0410, G_A_loss: 0.3190, G_B_loss: 0.5841\n",
            "Epoch [10/70], Step [391/1231], D_A_loss: 0.1393, D_B_loss: 0.1700, G_A_loss: 0.2634, G_B_loss: 0.2755\n",
            "Epoch [10/70], Step [401/1231], D_A_loss: 0.2599, D_B_loss: 0.0706, G_A_loss: 0.9649, G_B_loss: 0.1462\n",
            "Epoch [10/70], Step [411/1231], D_A_loss: 0.0990, D_B_loss: 0.1481, G_A_loss: 0.3326, G_B_loss: 0.5240\n",
            "Epoch [10/70], Step [421/1231], D_A_loss: 0.2076, D_B_loss: 0.1039, G_A_loss: 0.2162, G_B_loss: 0.3449\n",
            "Epoch [10/70], Step [431/1231], D_A_loss: 0.2750, D_B_loss: 0.1186, G_A_loss: 0.3518, G_B_loss: 0.5390\n",
            "Epoch [10/70], Step [441/1231], D_A_loss: 0.0419, D_B_loss: 0.1666, G_A_loss: 0.5603, G_B_loss: 0.2425\n",
            "Epoch [10/70], Step [451/1231], D_A_loss: 0.1183, D_B_loss: 0.1732, G_A_loss: 0.3252, G_B_loss: 0.4204\n",
            "Epoch [10/70], Step [461/1231], D_A_loss: 0.1707, D_B_loss: 0.1250, G_A_loss: 0.5460, G_B_loss: 0.2955\n",
            "Epoch [10/70], Step [471/1231], D_A_loss: 0.1580, D_B_loss: 0.1311, G_A_loss: 0.3548, G_B_loss: 0.3969\n",
            "Epoch [10/70], Step [481/1231], D_A_loss: 0.1549, D_B_loss: 0.2462, G_A_loss: 0.3382, G_B_loss: 0.6469\n",
            "Epoch [10/70], Step [491/1231], D_A_loss: 0.1851, D_B_loss: 0.0435, G_A_loss: 0.4592, G_B_loss: 0.1936\n",
            "Epoch [10/70], Step [501/1231], D_A_loss: 0.3275, D_B_loss: 0.2080, G_A_loss: 0.6269, G_B_loss: 0.0592\n",
            "Epoch [10/70], Step [511/1231], D_A_loss: 0.1372, D_B_loss: 0.3387, G_A_loss: 0.0737, G_B_loss: 0.2504\n",
            "Epoch [10/70], Step [521/1231], D_A_loss: 0.1428, D_B_loss: 0.0750, G_A_loss: 0.1884, G_B_loss: 0.2765\n",
            "Epoch [10/70], Step [531/1231], D_A_loss: 0.3218, D_B_loss: 0.2055, G_A_loss: 0.2598, G_B_loss: 0.1331\n",
            "Epoch [10/70], Step [541/1231], D_A_loss: 0.0695, D_B_loss: 0.0710, G_A_loss: 0.6333, G_B_loss: 0.7399\n",
            "Epoch [10/70], Step [551/1231], D_A_loss: 0.1201, D_B_loss: 0.1583, G_A_loss: 0.8190, G_B_loss: 0.1744\n",
            "Epoch [10/70], Step [561/1231], D_A_loss: 0.2434, D_B_loss: 0.1404, G_A_loss: 0.5336, G_B_loss: 0.3605\n",
            "Epoch [10/70], Step [571/1231], D_A_loss: 0.0568, D_B_loss: 0.0683, G_A_loss: 0.2954, G_B_loss: 0.4008\n",
            "Epoch [10/70], Step [581/1231], D_A_loss: 0.1018, D_B_loss: 0.0558, G_A_loss: 0.2836, G_B_loss: 0.8052\n",
            "Epoch [10/70], Step [591/1231], D_A_loss: 0.1577, D_B_loss: 0.2396, G_A_loss: 0.1488, G_B_loss: 0.3392\n",
            "Epoch [10/70], Step [601/1231], D_A_loss: 0.0594, D_B_loss: 0.1087, G_A_loss: 0.6395, G_B_loss: 0.6784\n",
            "Epoch [10/70], Step [611/1231], D_A_loss: 0.4900, D_B_loss: 0.0454, G_A_loss: 0.4728, G_B_loss: 0.0174\n",
            "Epoch [10/70], Step [621/1231], D_A_loss: 0.0764, D_B_loss: 0.1400, G_A_loss: 0.1352, G_B_loss: 0.9848\n",
            "Epoch [10/70], Step [631/1231], D_A_loss: 0.0408, D_B_loss: 0.1411, G_A_loss: 0.0535, G_B_loss: 0.3521\n",
            "Epoch [10/70], Step [641/1231], D_A_loss: 0.0627, D_B_loss: 0.0834, G_A_loss: 1.0310, G_B_loss: 0.4213\n",
            "Epoch [10/70], Step [651/1231], D_A_loss: 0.1313, D_B_loss: 0.1765, G_A_loss: 0.2728, G_B_loss: 0.4547\n",
            "Epoch [10/70], Step [661/1231], D_A_loss: 0.1228, D_B_loss: 0.2401, G_A_loss: 0.1723, G_B_loss: 0.8290\n",
            "Epoch [10/70], Step [671/1231], D_A_loss: 0.0774, D_B_loss: 0.0301, G_A_loss: 0.1300, G_B_loss: 0.4366\n",
            "Epoch [10/70], Step [681/1231], D_A_loss: 0.0221, D_B_loss: 0.1147, G_A_loss: 0.4361, G_B_loss: 0.4055\n",
            "Epoch [10/70], Step [691/1231], D_A_loss: 0.0767, D_B_loss: 0.1067, G_A_loss: 0.4761, G_B_loss: 0.9424\n",
            "Epoch [10/70], Step [701/1231], D_A_loss: 0.0403, D_B_loss: 0.0840, G_A_loss: 0.1437, G_B_loss: 1.1226\n",
            "Epoch [10/70], Step [711/1231], D_A_loss: 0.1442, D_B_loss: 0.1918, G_A_loss: 0.4944, G_B_loss: 0.3163\n",
            "Epoch [10/70], Step [721/1231], D_A_loss: 0.1006, D_B_loss: 0.1129, G_A_loss: 0.6418, G_B_loss: 0.2909\n",
            "Epoch [10/70], Step [731/1231], D_A_loss: 0.1870, D_B_loss: 0.1466, G_A_loss: 0.1748, G_B_loss: 0.5260\n",
            "Epoch [10/70], Step [741/1231], D_A_loss: 0.1967, D_B_loss: 0.1893, G_A_loss: 0.4728, G_B_loss: 0.2796\n",
            "Epoch [10/70], Step [751/1231], D_A_loss: 0.0980, D_B_loss: 0.0638, G_A_loss: 0.4386, G_B_loss: 0.4055\n",
            "Epoch [10/70], Step [761/1231], D_A_loss: 0.2163, D_B_loss: 0.1387, G_A_loss: 0.5841, G_B_loss: 0.1902\n",
            "Epoch [10/70], Step [771/1231], D_A_loss: 0.2539, D_B_loss: 0.2361, G_A_loss: 0.5791, G_B_loss: 0.6704\n",
            "Epoch [10/70], Step [781/1231], D_A_loss: 0.0468, D_B_loss: 0.0710, G_A_loss: 0.7711, G_B_loss: 0.4774\n",
            "Epoch [10/70], Step [791/1231], D_A_loss: 0.2016, D_B_loss: 0.3228, G_A_loss: 0.0779, G_B_loss: 0.1892\n",
            "Epoch [10/70], Step [801/1231], D_A_loss: 0.1804, D_B_loss: 0.0459, G_A_loss: 0.3704, G_B_loss: 0.2811\n",
            "Epoch [10/70], Step [811/1231], D_A_loss: 0.1293, D_B_loss: 0.1061, G_A_loss: 0.7022, G_B_loss: 0.3305\n",
            "Epoch [10/70], Step [821/1231], D_A_loss: 0.2949, D_B_loss: 0.0400, G_A_loss: 0.7436, G_B_loss: 0.0793\n",
            "Epoch [10/70], Step [831/1231], D_A_loss: 0.0834, D_B_loss: 0.0891, G_A_loss: 0.2916, G_B_loss: 0.6581\n",
            "Epoch [10/70], Step [841/1231], D_A_loss: 0.0439, D_B_loss: 0.0979, G_A_loss: 0.5246, G_B_loss: 0.4180\n",
            "Epoch [10/70], Step [851/1231], D_A_loss: 0.1867, D_B_loss: 0.1180, G_A_loss: 0.3533, G_B_loss: 0.2439\n",
            "Epoch [10/70], Step [861/1231], D_A_loss: 0.0425, D_B_loss: 0.1116, G_A_loss: 0.3576, G_B_loss: 0.3823\n",
            "Epoch [10/70], Step [871/1231], D_A_loss: 0.0347, D_B_loss: 0.0678, G_A_loss: 0.4058, G_B_loss: 0.7102\n",
            "Epoch [10/70], Step [881/1231], D_A_loss: 0.2695, D_B_loss: 0.0946, G_A_loss: 0.4571, G_B_loss: 0.7215\n",
            "Epoch [10/70], Step [891/1231], D_A_loss: 0.2754, D_B_loss: 0.2918, G_A_loss: 0.3454, G_B_loss: 0.2884\n",
            "Epoch [10/70], Step [901/1231], D_A_loss: 0.1748, D_B_loss: 0.1951, G_A_loss: 0.2912, G_B_loss: 0.2475\n",
            "Epoch [10/70], Step [911/1231], D_A_loss: 0.0964, D_B_loss: 0.0578, G_A_loss: 0.5182, G_B_loss: 0.8282\n",
            "Epoch [10/70], Step [921/1231], D_A_loss: 0.1400, D_B_loss: 0.0735, G_A_loss: 0.1273, G_B_loss: 0.3010\n",
            "Epoch [10/70], Step [931/1231], D_A_loss: 0.1681, D_B_loss: 0.0572, G_A_loss: 0.5171, G_B_loss: 0.3155\n",
            "Epoch [10/70], Step [941/1231], D_A_loss: 0.0765, D_B_loss: 0.0851, G_A_loss: 0.5181, G_B_loss: 0.8533\n",
            "Epoch [10/70], Step [951/1231], D_A_loss: 0.0298, D_B_loss: 0.3345, G_A_loss: 0.0797, G_B_loss: 0.3502\n",
            "Epoch [10/70], Step [961/1231], D_A_loss: 0.1409, D_B_loss: 0.0711, G_A_loss: 0.6554, G_B_loss: 0.3504\n",
            "Epoch [11/70], Step [1/1231], D_A_loss: 0.1354, D_B_loss: 0.0410, G_A_loss: 0.2398, G_B_loss: 0.4051\n",
            "Epoch [11/70], Step [11/1231], D_A_loss: 0.2423, D_B_loss: 0.1470, G_A_loss: 0.6617, G_B_loss: 0.2600\n",
            "Epoch [11/70], Step [21/1231], D_A_loss: 0.2200, D_B_loss: 0.0954, G_A_loss: 0.4048, G_B_loss: 0.2385\n",
            "Epoch [11/70], Step [31/1231], D_A_loss: 0.2567, D_B_loss: 0.0367, G_A_loss: 0.5022, G_B_loss: 0.1625\n",
            "Epoch [11/70], Step [41/1231], D_A_loss: 0.1055, D_B_loss: 0.1312, G_A_loss: 0.4689, G_B_loss: 0.5053\n",
            "Epoch [11/70], Step [51/1231], D_A_loss: 0.1275, D_B_loss: 0.1628, G_A_loss: 0.3765, G_B_loss: 0.5609\n",
            "Epoch [11/70], Step [61/1231], D_A_loss: 0.1843, D_B_loss: 0.0201, G_A_loss: 0.5469, G_B_loss: 0.2046\n",
            "Epoch [11/70], Step [71/1231], D_A_loss: 0.1860, D_B_loss: 0.1601, G_A_loss: 0.6703, G_B_loss: 0.7044\n",
            "Epoch [11/70], Step [81/1231], D_A_loss: 0.1160, D_B_loss: 0.0299, G_A_loss: 0.2658, G_B_loss: 0.7878\n",
            "Epoch [11/70], Step [91/1231], D_A_loss: 0.0541, D_B_loss: 0.1367, G_A_loss: 0.2403, G_B_loss: 0.4270\n",
            "Epoch [11/70], Step [101/1231], D_A_loss: 0.2277, D_B_loss: 0.0764, G_A_loss: 0.1680, G_B_loss: 0.1901\n",
            "Epoch [11/70], Step [111/1231], D_A_loss: 0.1141, D_B_loss: 0.1419, G_A_loss: 0.5536, G_B_loss: 0.2604\n",
            "Epoch [11/70], Step [121/1231], D_A_loss: 0.0241, D_B_loss: 0.1142, G_A_loss: 0.9176, G_B_loss: 0.2279\n",
            "Epoch [11/70], Step [131/1231], D_A_loss: 0.2466, D_B_loss: 0.3138, G_A_loss: 0.7154, G_B_loss: 0.1369\n",
            "Epoch [11/70], Step [141/1231], D_A_loss: 0.0974, D_B_loss: 0.1111, G_A_loss: 0.1457, G_B_loss: 0.3873\n",
            "Epoch [11/70], Step [151/1231], D_A_loss: 0.0706, D_B_loss: 0.0800, G_A_loss: 0.2633, G_B_loss: 0.2226\n",
            "Epoch [11/70], Step [161/1231], D_A_loss: 0.0858, D_B_loss: 0.1381, G_A_loss: 0.3624, G_B_loss: 0.1972\n",
            "Epoch [11/70], Step [171/1231], D_A_loss: 0.0395, D_B_loss: 0.1874, G_A_loss: 0.1922, G_B_loss: 0.4427\n",
            "Epoch [11/70], Step [181/1231], D_A_loss: 0.1511, D_B_loss: 0.0934, G_A_loss: 0.5237, G_B_loss: 0.2977\n",
            "Epoch [11/70], Step [191/1231], D_A_loss: 0.0737, D_B_loss: 0.0505, G_A_loss: 0.3951, G_B_loss: 0.0997\n",
            "Epoch [11/70], Step [201/1231], D_A_loss: 0.1955, D_B_loss: 0.1682, G_A_loss: 0.2674, G_B_loss: 0.4662\n",
            "Epoch [11/70], Step [211/1231], D_A_loss: 0.2979, D_B_loss: 0.0198, G_A_loss: 0.3630, G_B_loss: 0.4361\n",
            "Epoch [11/70], Step [221/1231], D_A_loss: 0.1147, D_B_loss: 0.0683, G_A_loss: 0.5132, G_B_loss: 0.4718\n",
            "Epoch [11/70], Step [231/1231], D_A_loss: 0.2389, D_B_loss: 0.0818, G_A_loss: 0.6235, G_B_loss: 0.1810\n",
            "Epoch [11/70], Step [241/1231], D_A_loss: 0.1481, D_B_loss: 0.0730, G_A_loss: 0.3871, G_B_loss: 0.2456\n",
            "Epoch [11/70], Step [251/1231], D_A_loss: 0.2751, D_B_loss: 0.0199, G_A_loss: 0.3884, G_B_loss: 0.5501\n",
            "Epoch [11/70], Step [261/1231], D_A_loss: 0.0695, D_B_loss: 0.0715, G_A_loss: 0.6812, G_B_loss: 0.2066\n",
            "Epoch [11/70], Step [271/1231], D_A_loss: 0.2724, D_B_loss: 0.1771, G_A_loss: 0.4942, G_B_loss: 0.1049\n",
            "Epoch [11/70], Step [281/1231], D_A_loss: 0.0628, D_B_loss: 0.1821, G_A_loss: 0.1240, G_B_loss: 0.3836\n",
            "Epoch [11/70], Step [291/1231], D_A_loss: 0.3457, D_B_loss: 0.1114, G_A_loss: 0.6393, G_B_loss: 0.9003\n",
            "Epoch [11/70], Step [301/1231], D_A_loss: 0.0687, D_B_loss: 0.2032, G_A_loss: 0.1802, G_B_loss: 0.6339\n",
            "Epoch [11/70], Step [311/1231], D_A_loss: 0.1659, D_B_loss: 0.1800, G_A_loss: 0.2546, G_B_loss: 0.3279\n",
            "Epoch [11/70], Step [321/1231], D_A_loss: 0.0615, D_B_loss: 0.0848, G_A_loss: 0.5630, G_B_loss: 0.6610\n",
            "Epoch [11/70], Step [331/1231], D_A_loss: 0.1712, D_B_loss: 0.0717, G_A_loss: 0.3953, G_B_loss: 0.2212\n",
            "Epoch [11/70], Step [341/1231], D_A_loss: 0.0839, D_B_loss: 0.0182, G_A_loss: 0.3769, G_B_loss: 0.3689\n",
            "Epoch [11/70], Step [351/1231], D_A_loss: 0.0976, D_B_loss: 0.3088, G_A_loss: 0.2973, G_B_loss: 0.3666\n",
            "Epoch [11/70], Step [361/1231], D_A_loss: 0.1404, D_B_loss: 0.2407, G_A_loss: 0.1267, G_B_loss: 0.1162\n",
            "Epoch [11/70], Step [371/1231], D_A_loss: 0.2044, D_B_loss: 0.1149, G_A_loss: 0.3986, G_B_loss: 0.2757\n",
            "Epoch [11/70], Step [381/1231], D_A_loss: 0.1056, D_B_loss: 0.1783, G_A_loss: 0.2372, G_B_loss: 0.4337\n",
            "Epoch [11/70], Step [391/1231], D_A_loss: 0.1080, D_B_loss: 0.2466, G_A_loss: 0.4254, G_B_loss: 0.5679\n",
            "Epoch [11/70], Step [401/1231], D_A_loss: 0.1368, D_B_loss: 0.2855, G_A_loss: 0.8302, G_B_loss: 0.6235\n",
            "Epoch [11/70], Step [411/1231], D_A_loss: 0.1113, D_B_loss: 0.1416, G_A_loss: 0.5586, G_B_loss: 0.8780\n",
            "Epoch [11/70], Step [421/1231], D_A_loss: 0.1644, D_B_loss: 0.1193, G_A_loss: 0.4385, G_B_loss: 0.3742\n",
            "Epoch [11/70], Step [431/1231], D_A_loss: 0.2621, D_B_loss: 0.0706, G_A_loss: 0.2048, G_B_loss: 0.4934\n",
            "Epoch [11/70], Step [441/1231], D_A_loss: 0.0643, D_B_loss: 0.1787, G_A_loss: 0.3058, G_B_loss: 0.4580\n",
            "Epoch [11/70], Step [451/1231], D_A_loss: 0.1188, D_B_loss: 0.1568, G_A_loss: 0.5323, G_B_loss: 0.5679\n",
            "Epoch [11/70], Step [461/1231], D_A_loss: 0.1659, D_B_loss: 0.0807, G_A_loss: 0.6393, G_B_loss: 0.4294\n",
            "Epoch [11/70], Step [471/1231], D_A_loss: 0.0783, D_B_loss: 0.0289, G_A_loss: 0.5250, G_B_loss: 0.5722\n",
            "Epoch [11/70], Step [481/1231], D_A_loss: 0.1870, D_B_loss: 0.1957, G_A_loss: 0.6205, G_B_loss: 0.7155\n",
            "Epoch [11/70], Step [491/1231], D_A_loss: 0.1228, D_B_loss: 0.1366, G_A_loss: 0.3831, G_B_loss: 0.5218\n",
            "Epoch [11/70], Step [501/1231], D_A_loss: 0.5907, D_B_loss: 0.0595, G_A_loss: 0.2676, G_B_loss: 0.0453\n",
            "Epoch [11/70], Step [511/1231], D_A_loss: 0.0617, D_B_loss: 0.0496, G_A_loss: 0.5846, G_B_loss: 0.1100\n",
            "Epoch [11/70], Step [521/1231], D_A_loss: 0.1288, D_B_loss: 0.2026, G_A_loss: 0.1838, G_B_loss: 0.4815\n",
            "Epoch [11/70], Step [531/1231], D_A_loss: 0.0695, D_B_loss: 0.0177, G_A_loss: 0.3246, G_B_loss: 0.2321\n",
            "Epoch [11/70], Step [541/1231], D_A_loss: 0.2432, D_B_loss: 0.1681, G_A_loss: 0.4296, G_B_loss: 0.4560\n",
            "Epoch [11/70], Step [551/1231], D_A_loss: 0.2673, D_B_loss: 0.0590, G_A_loss: 0.2215, G_B_loss: 0.1396\n",
            "Epoch [11/70], Step [561/1231], D_A_loss: 0.1630, D_B_loss: 0.0541, G_A_loss: 0.2993, G_B_loss: 0.3916\n",
            "Epoch [11/70], Step [571/1231], D_A_loss: 0.0649, D_B_loss: 0.0996, G_A_loss: 0.8760, G_B_loss: 0.5416\n",
            "Epoch [11/70], Step [581/1231], D_A_loss: 0.1137, D_B_loss: 0.2201, G_A_loss: 0.5051, G_B_loss: 0.4015\n",
            "Epoch [11/70], Step [591/1231], D_A_loss: 0.1791, D_B_loss: 0.1004, G_A_loss: 0.5484, G_B_loss: 0.5063\n",
            "Epoch [11/70], Step [601/1231], D_A_loss: 0.1432, D_B_loss: 0.0377, G_A_loss: 0.4061, G_B_loss: 0.9747\n",
            "Epoch [11/70], Step [611/1231], D_A_loss: 0.1928, D_B_loss: 0.2089, G_A_loss: 0.2341, G_B_loss: 0.1924\n",
            "Epoch [11/70], Step [621/1231], D_A_loss: 0.1513, D_B_loss: 0.1699, G_A_loss: 0.2647, G_B_loss: 0.6139\n",
            "Epoch [11/70], Step [631/1231], D_A_loss: 0.2477, D_B_loss: 0.1605, G_A_loss: 0.4591, G_B_loss: 0.5523\n",
            "Epoch [11/70], Step [641/1231], D_A_loss: 0.0732, D_B_loss: 0.0537, G_A_loss: 0.5105, G_B_loss: 0.4076\n",
            "Epoch [11/70], Step [651/1231], D_A_loss: 0.1337, D_B_loss: 0.1338, G_A_loss: 0.4726, G_B_loss: 0.3656\n",
            "Epoch [11/70], Step [661/1231], D_A_loss: 0.1755, D_B_loss: 0.1351, G_A_loss: 0.4946, G_B_loss: 0.2724\n",
            "Epoch [11/70], Step [671/1231], D_A_loss: 0.0505, D_B_loss: 0.1347, G_A_loss: 0.4795, G_B_loss: 0.4455\n",
            "Epoch [11/70], Step [681/1231], D_A_loss: 0.0845, D_B_loss: 0.0812, G_A_loss: 0.8481, G_B_loss: 0.4558\n",
            "Epoch [11/70], Step [691/1231], D_A_loss: 0.0618, D_B_loss: 0.0617, G_A_loss: 0.5028, G_B_loss: 0.3091\n",
            "Epoch [11/70], Step [701/1231], D_A_loss: 0.2308, D_B_loss: 0.0947, G_A_loss: 0.7874, G_B_loss: 0.8361\n",
            "Epoch [11/70], Step [711/1231], D_A_loss: 0.0734, D_B_loss: 0.0792, G_A_loss: 0.5175, G_B_loss: 0.4559\n",
            "Epoch [11/70], Step [721/1231], D_A_loss: 0.0214, D_B_loss: 0.1493, G_A_loss: 0.3675, G_B_loss: 0.5573\n",
            "Epoch [11/70], Step [731/1231], D_A_loss: 0.2220, D_B_loss: 0.0529, G_A_loss: 0.3045, G_B_loss: 0.3778\n",
            "Epoch [11/70], Step [741/1231], D_A_loss: 0.0599, D_B_loss: 0.0648, G_A_loss: 0.3163, G_B_loss: 0.4915\n",
            "Epoch [11/70], Step [751/1231], D_A_loss: 0.0724, D_B_loss: 0.1985, G_A_loss: 0.1772, G_B_loss: 0.7106\n",
            "Epoch [11/70], Step [761/1231], D_A_loss: 0.2243, D_B_loss: 0.1617, G_A_loss: 0.5239, G_B_loss: 0.4259\n",
            "Epoch [11/70], Step [771/1231], D_A_loss: 0.1681, D_B_loss: 0.0499, G_A_loss: 0.2229, G_B_loss: 0.5022\n",
            "Epoch [11/70], Step [781/1231], D_A_loss: 0.0622, D_B_loss: 0.0809, G_A_loss: 0.5201, G_B_loss: 0.2953\n",
            "Epoch [11/70], Step [791/1231], D_A_loss: 0.0440, D_B_loss: 0.1827, G_A_loss: 0.6705, G_B_loss: 0.6631\n",
            "Epoch [11/70], Step [801/1231], D_A_loss: 0.1813, D_B_loss: 0.0890, G_A_loss: 0.4015, G_B_loss: 0.2766\n",
            "Epoch [11/70], Step [811/1231], D_A_loss: 0.1030, D_B_loss: 0.2221, G_A_loss: 0.1898, G_B_loss: 0.4676\n",
            "Epoch [11/70], Step [821/1231], D_A_loss: 0.0506, D_B_loss: 0.0891, G_A_loss: 0.4028, G_B_loss: 0.5817\n",
            "Epoch [11/70], Step [831/1231], D_A_loss: 0.0442, D_B_loss: 0.1325, G_A_loss: 0.5059, G_B_loss: 0.4148\n",
            "Epoch [11/70], Step [841/1231], D_A_loss: 0.1003, D_B_loss: 0.1045, G_A_loss: 0.4091, G_B_loss: 0.3955\n",
            "Epoch [11/70], Step [851/1231], D_A_loss: 0.0997, D_B_loss: 0.1108, G_A_loss: 0.3988, G_B_loss: 0.6120\n",
            "Epoch [11/70], Step [861/1231], D_A_loss: 0.1450, D_B_loss: 0.0769, G_A_loss: 0.6817, G_B_loss: 0.3100\n",
            "Epoch [11/70], Step [871/1231], D_A_loss: 0.2322, D_B_loss: 0.1877, G_A_loss: 0.2269, G_B_loss: 0.9465\n",
            "Epoch [11/70], Step [881/1231], D_A_loss: 0.0475, D_B_loss: 0.1559, G_A_loss: 0.3639, G_B_loss: 0.6304\n",
            "Epoch [11/70], Step [891/1231], D_A_loss: 0.1863, D_B_loss: 0.1570, G_A_loss: 0.3660, G_B_loss: 0.2082\n",
            "Epoch [11/70], Step [901/1231], D_A_loss: 0.3354, D_B_loss: 0.2147, G_A_loss: 0.1705, G_B_loss: 0.3380\n",
            "Epoch [11/70], Step [911/1231], D_A_loss: 0.2530, D_B_loss: 0.1347, G_A_loss: 0.4208, G_B_loss: 0.6141\n",
            "Epoch [11/70], Step [921/1231], D_A_loss: 0.1633, D_B_loss: 0.0565, G_A_loss: 0.7950, G_B_loss: 0.3080\n",
            "Epoch [11/70], Step [931/1231], D_A_loss: 0.1783, D_B_loss: 0.2015, G_A_loss: 0.2491, G_B_loss: 0.1050\n",
            "Epoch [11/70], Step [941/1231], D_A_loss: 0.3815, D_B_loss: 0.1462, G_A_loss: 0.4312, G_B_loss: 0.4834\n",
            "Epoch [11/70], Step [951/1231], D_A_loss: 0.1031, D_B_loss: 0.0926, G_A_loss: 0.4888, G_B_loss: 0.2678\n",
            "Epoch [11/70], Step [961/1231], D_A_loss: 0.0832, D_B_loss: 0.0128, G_A_loss: 0.7317, G_B_loss: 0.8333\n",
            "Epoch [12/70], Step [1/1231], D_A_loss: 0.0298, D_B_loss: 0.2198, G_A_loss: 0.6073, G_B_loss: 0.2276\n",
            "Epoch [12/70], Step [11/1231], D_A_loss: 0.1657, D_B_loss: 0.0782, G_A_loss: 0.3757, G_B_loss: 0.2256\n",
            "Epoch [12/70], Step [21/1231], D_A_loss: 0.0142, D_B_loss: 0.0882, G_A_loss: 0.4935, G_B_loss: 0.2647\n",
            "Epoch [12/70], Step [31/1231], D_A_loss: 0.0895, D_B_loss: 0.1942, G_A_loss: 0.2142, G_B_loss: 0.3085\n",
            "Epoch [12/70], Step [41/1231], D_A_loss: 0.1443, D_B_loss: 0.0764, G_A_loss: 0.6420, G_B_loss: 0.6206\n",
            "Epoch [12/70], Step [51/1231], D_A_loss: 0.1042, D_B_loss: 0.1763, G_A_loss: 0.2392, G_B_loss: 0.2249\n",
            "Epoch [12/70], Step [61/1231], D_A_loss: 0.2765, D_B_loss: 0.0786, G_A_loss: 0.5146, G_B_loss: 0.3860\n",
            "Epoch [12/70], Step [71/1231], D_A_loss: 0.0958, D_B_loss: 0.1509, G_A_loss: 0.2579, G_B_loss: 0.5193\n",
            "Epoch [12/70], Step [81/1231], D_A_loss: 0.1804, D_B_loss: 0.1112, G_A_loss: 0.5070, G_B_loss: 0.4056\n",
            "Epoch [12/70], Step [91/1231], D_A_loss: 0.1455, D_B_loss: 0.1451, G_A_loss: 0.4489, G_B_loss: 0.4030\n",
            "Epoch [12/70], Step [101/1231], D_A_loss: 0.0393, D_B_loss: 0.2582, G_A_loss: 0.3724, G_B_loss: 0.2591\n",
            "Epoch [12/70], Step [111/1231], D_A_loss: 0.0690, D_B_loss: 0.1319, G_A_loss: 0.7462, G_B_loss: 0.4464\n",
            "Epoch [12/70], Step [121/1231], D_A_loss: 0.1384, D_B_loss: 0.0755, G_A_loss: 0.4159, G_B_loss: 0.2995\n",
            "Epoch [12/70], Step [131/1231], D_A_loss: 0.1581, D_B_loss: 0.0831, G_A_loss: 0.9007, G_B_loss: 0.2720\n",
            "Epoch [12/70], Step [141/1231], D_A_loss: 0.2040, D_B_loss: 0.1778, G_A_loss: 0.2017, G_B_loss: 0.2694\n",
            "Epoch [12/70], Step [151/1231], D_A_loss: 0.1162, D_B_loss: 0.1530, G_A_loss: 0.2513, G_B_loss: 0.4131\n",
            "Epoch [12/70], Step [161/1231], D_A_loss: 0.0959, D_B_loss: 0.0598, G_A_loss: 0.7472, G_B_loss: 0.9064\n",
            "Epoch [12/70], Step [171/1231], D_A_loss: 0.3862, D_B_loss: 0.0840, G_A_loss: 0.4072, G_B_loss: 0.0282\n",
            "Epoch [12/70], Step [181/1231], D_A_loss: 0.0367, D_B_loss: 0.0911, G_A_loss: 0.3459, G_B_loss: 0.2406\n",
            "Epoch [12/70], Step [191/1231], D_A_loss: 0.4090, D_B_loss: 0.1027, G_A_loss: 0.5154, G_B_loss: 0.0847\n",
            "Epoch [12/70], Step [201/1231], D_A_loss: 0.0688, D_B_loss: 0.2653, G_A_loss: 0.1687, G_B_loss: 0.6233\n",
            "Epoch [12/70], Step [211/1231], D_A_loss: 0.1514, D_B_loss: 0.0544, G_A_loss: 0.4994, G_B_loss: 0.2580\n",
            "Epoch [12/70], Step [221/1231], D_A_loss: 0.0877, D_B_loss: 0.0591, G_A_loss: 0.4867, G_B_loss: 0.4769\n",
            "Epoch [12/70], Step [231/1231], D_A_loss: 0.1479, D_B_loss: 0.1285, G_A_loss: 0.3140, G_B_loss: 0.3130\n",
            "Epoch [12/70], Step [241/1231], D_A_loss: 0.1198, D_B_loss: 0.1235, G_A_loss: 0.1907, G_B_loss: 0.5474\n",
            "Epoch [12/70], Step [251/1231], D_A_loss: 0.0783, D_B_loss: 0.0595, G_A_loss: 0.2029, G_B_loss: 0.3102\n",
            "Epoch [12/70], Step [261/1231], D_A_loss: 0.0665, D_B_loss: 0.0732, G_A_loss: 0.2789, G_B_loss: 0.4690\n",
            "Epoch [12/70], Step [271/1231], D_A_loss: 0.1457, D_B_loss: 0.1841, G_A_loss: 0.7124, G_B_loss: 0.0348\n",
            "Epoch [12/70], Step [281/1231], D_A_loss: 0.1106, D_B_loss: 0.2554, G_A_loss: 0.6811, G_B_loss: 0.4453\n",
            "Epoch [12/70], Step [291/1231], D_A_loss: 0.1038, D_B_loss: 0.1260, G_A_loss: 0.5330, G_B_loss: 0.5321\n",
            "Epoch [12/70], Step [301/1231], D_A_loss: 0.1214, D_B_loss: 0.0964, G_A_loss: 0.6607, G_B_loss: 0.8680\n",
            "Epoch [12/70], Step [311/1231], D_A_loss: 0.0657, D_B_loss: 0.0819, G_A_loss: 0.7089, G_B_loss: 0.3976\n",
            "Epoch [12/70], Step [321/1231], D_A_loss: 0.1885, D_B_loss: 0.2715, G_A_loss: 0.4108, G_B_loss: 0.2616\n",
            "Epoch [12/70], Step [331/1231], D_A_loss: 0.2790, D_B_loss: 0.2463, G_A_loss: 0.4480, G_B_loss: 0.6100\n",
            "Epoch [12/70], Step [341/1231], D_A_loss: 0.1787, D_B_loss: 0.0708, G_A_loss: 0.9723, G_B_loss: 0.3030\n",
            "Epoch [12/70], Step [351/1231], D_A_loss: 0.1986, D_B_loss: 0.0869, G_A_loss: 0.1200, G_B_loss: 0.2209\n",
            "Epoch [12/70], Step [361/1231], D_A_loss: 0.0462, D_B_loss: 0.0795, G_A_loss: 0.3728, G_B_loss: 0.9770\n",
            "Epoch [12/70], Step [371/1231], D_A_loss: 0.2747, D_B_loss: 0.2720, G_A_loss: 0.1128, G_B_loss: 0.4502\n",
            "Epoch [12/70], Step [381/1231], D_A_loss: 0.2125, D_B_loss: 0.1185, G_A_loss: 0.6353, G_B_loss: 0.1810\n",
            "Epoch [12/70], Step [391/1231], D_A_loss: 0.2217, D_B_loss: 0.2253, G_A_loss: 0.3855, G_B_loss: 0.2256\n",
            "Epoch [12/70], Step [401/1231], D_A_loss: 0.1528, D_B_loss: 0.0672, G_A_loss: 0.0708, G_B_loss: 0.4231\n",
            "Epoch [12/70], Step [411/1231], D_A_loss: 0.1606, D_B_loss: 0.0223, G_A_loss: 0.5202, G_B_loss: 0.3831\n",
            "Epoch [12/70], Step [421/1231], D_A_loss: 0.0240, D_B_loss: 0.0966, G_A_loss: 0.4311, G_B_loss: 0.5749\n",
            "Epoch [12/70], Step [431/1231], D_A_loss: 0.1058, D_B_loss: 0.1246, G_A_loss: 0.5195, G_B_loss: 0.1978\n",
            "Epoch [12/70], Step [441/1231], D_A_loss: 0.0916, D_B_loss: 0.0438, G_A_loss: 0.5519, G_B_loss: 0.2766\n",
            "Epoch [12/70], Step [451/1231], D_A_loss: 0.1353, D_B_loss: 0.0620, G_A_loss: 0.3091, G_B_loss: 0.3564\n",
            "Epoch [12/70], Step [461/1231], D_A_loss: 0.0732, D_B_loss: 0.0742, G_A_loss: 0.1529, G_B_loss: 0.2439\n",
            "Epoch [12/70], Step [471/1231], D_A_loss: 0.0837, D_B_loss: 0.1259, G_A_loss: 0.3118, G_B_loss: 0.4290\n",
            "Epoch [12/70], Step [481/1231], D_A_loss: 0.0623, D_B_loss: 0.1346, G_A_loss: 0.3273, G_B_loss: 0.1432\n",
            "Epoch [12/70], Step [491/1231], D_A_loss: 0.0855, D_B_loss: 0.3005, G_A_loss: 0.8463, G_B_loss: 0.3880\n",
            "Epoch [12/70], Step [501/1231], D_A_loss: 0.0573, D_B_loss: 0.0944, G_A_loss: 0.2495, G_B_loss: 0.2044\n",
            "Epoch [12/70], Step [511/1231], D_A_loss: 0.1388, D_B_loss: 0.0278, G_A_loss: 0.2797, G_B_loss: 0.7813\n",
            "Epoch [12/70], Step [521/1231], D_A_loss: 0.1060, D_B_loss: 0.0309, G_A_loss: 0.6061, G_B_loss: 0.5120\n",
            "Epoch [12/70], Step [531/1231], D_A_loss: 0.0977, D_B_loss: 0.0621, G_A_loss: 0.1226, G_B_loss: 0.8808\n",
            "Epoch [12/70], Step [541/1231], D_A_loss: 0.0543, D_B_loss: 0.2211, G_A_loss: 0.6598, G_B_loss: 0.1689\n",
            "Epoch [12/70], Step [551/1231], D_A_loss: 0.0765, D_B_loss: 0.2476, G_A_loss: 1.1253, G_B_loss: 0.2711\n",
            "Epoch [12/70], Step [561/1231], D_A_loss: 0.0788, D_B_loss: 0.0598, G_A_loss: 0.6775, G_B_loss: 0.3969\n",
            "Epoch [12/70], Step [571/1231], D_A_loss: 0.0969, D_B_loss: 0.1264, G_A_loss: 0.2648, G_B_loss: 0.3902\n",
            "Epoch [12/70], Step [581/1231], D_A_loss: 0.0962, D_B_loss: 0.1713, G_A_loss: 0.6246, G_B_loss: 0.5842\n",
            "Epoch [12/70], Step [591/1231], D_A_loss: 0.1445, D_B_loss: 0.1490, G_A_loss: 0.4953, G_B_loss: 0.2767\n",
            "Epoch [12/70], Step [601/1231], D_A_loss: 0.0851, D_B_loss: 0.1811, G_A_loss: 0.4678, G_B_loss: 0.7641\n",
            "Epoch [12/70], Step [611/1231], D_A_loss: 0.2543, D_B_loss: 0.1743, G_A_loss: 0.4123, G_B_loss: 0.1506\n",
            "Epoch [12/70], Step [621/1231], D_A_loss: 0.1185, D_B_loss: 0.0748, G_A_loss: 0.4721, G_B_loss: 0.2168\n",
            "Epoch [12/70], Step [631/1231], D_A_loss: 0.1152, D_B_loss: 0.1509, G_A_loss: 0.9009, G_B_loss: 0.1730\n",
            "Epoch [12/70], Step [641/1231], D_A_loss: 0.3138, D_B_loss: 0.0623, G_A_loss: 0.6323, G_B_loss: 0.1320\n",
            "Epoch [12/70], Step [651/1231], D_A_loss: 0.0908, D_B_loss: 0.0376, G_A_loss: 0.1769, G_B_loss: 0.4155\n",
            "Epoch [12/70], Step [661/1231], D_A_loss: 0.0789, D_B_loss: 0.1834, G_A_loss: 0.4921, G_B_loss: 0.5698\n",
            "Epoch [12/70], Step [671/1231], D_A_loss: 0.0298, D_B_loss: 0.1594, G_A_loss: 0.2333, G_B_loss: 0.2556\n",
            "Epoch [12/70], Step [681/1231], D_A_loss: 0.0213, D_B_loss: 0.1851, G_A_loss: 0.4858, G_B_loss: 0.3817\n",
            "Epoch [12/70], Step [691/1231], D_A_loss: 0.0422, D_B_loss: 0.0632, G_A_loss: 0.5380, G_B_loss: 0.9147\n",
            "Epoch [12/70], Step [701/1231], D_A_loss: 0.2257, D_B_loss: 0.0758, G_A_loss: 0.5626, G_B_loss: 0.7071\n",
            "Epoch [12/70], Step [711/1231], D_A_loss: 0.1556, D_B_loss: 0.1093, G_A_loss: 0.3521, G_B_loss: 0.2562\n",
            "Epoch [12/70], Step [721/1231], D_A_loss: 0.0420, D_B_loss: 0.2317, G_A_loss: 0.2742, G_B_loss: 0.5263\n",
            "Epoch [12/70], Step [731/1231], D_A_loss: 0.1005, D_B_loss: 0.1791, G_A_loss: 0.2328, G_B_loss: 0.3889\n",
            "Epoch [12/70], Step [741/1231], D_A_loss: 0.0655, D_B_loss: 0.2007, G_A_loss: 0.3532, G_B_loss: 0.3800\n",
            "Epoch [12/70], Step [751/1231], D_A_loss: 0.1384, D_B_loss: 0.2240, G_A_loss: 0.8051, G_B_loss: 0.4691\n",
            "Epoch [12/70], Step [761/1231], D_A_loss: 0.0229, D_B_loss: 0.1243, G_A_loss: 0.7785, G_B_loss: 0.3145\n",
            "Epoch [12/70], Step [771/1231], D_A_loss: 0.1089, D_B_loss: 0.0949, G_A_loss: 0.2865, G_B_loss: 0.4386\n",
            "Epoch [12/70], Step [781/1231], D_A_loss: 0.0462, D_B_loss: 0.0286, G_A_loss: 0.9453, G_B_loss: 0.3097\n",
            "Epoch [12/70], Step [791/1231], D_A_loss: 0.1527, D_B_loss: 0.1126, G_A_loss: 0.6026, G_B_loss: 0.5293\n",
            "Epoch [12/70], Step [801/1231], D_A_loss: 0.1003, D_B_loss: 0.0774, G_A_loss: 0.4835, G_B_loss: 0.4104\n",
            "Epoch [12/70], Step [811/1231], D_A_loss: 0.0649, D_B_loss: 0.1395, G_A_loss: 0.6864, G_B_loss: 0.2287\n",
            "Epoch [12/70], Step [821/1231], D_A_loss: 0.0419, D_B_loss: 0.1059, G_A_loss: 0.2842, G_B_loss: 0.5201\n",
            "Epoch [12/70], Step [831/1231], D_A_loss: 0.1191, D_B_loss: 0.1343, G_A_loss: 0.4242, G_B_loss: 0.1184\n",
            "Epoch [12/70], Step [841/1231], D_A_loss: 0.0683, D_B_loss: 0.1369, G_A_loss: 0.5188, G_B_loss: 0.4920\n",
            "Epoch [12/70], Step [851/1231], D_A_loss: 0.0947, D_B_loss: 0.0702, G_A_loss: 0.6208, G_B_loss: 0.4304\n",
            "Epoch [12/70], Step [861/1231], D_A_loss: 0.1133, D_B_loss: 0.0334, G_A_loss: 0.3246, G_B_loss: 0.7146\n",
            "Epoch [12/70], Step [871/1231], D_A_loss: 0.0415, D_B_loss: 0.1696, G_A_loss: 0.7408, G_B_loss: 0.2486\n",
            "Epoch [12/70], Step [881/1231], D_A_loss: 0.1244, D_B_loss: 0.0338, G_A_loss: 0.1963, G_B_loss: 0.4904\n",
            "Epoch [12/70], Step [891/1231], D_A_loss: 0.0687, D_B_loss: 0.1649, G_A_loss: 0.3397, G_B_loss: 0.3533\n",
            "Epoch [12/70], Step [901/1231], D_A_loss: 0.1481, D_B_loss: 0.1021, G_A_loss: 0.6437, G_B_loss: 0.2814\n",
            "Epoch [12/70], Step [911/1231], D_A_loss: 0.0939, D_B_loss: 0.1069, G_A_loss: 0.4353, G_B_loss: 0.4541\n",
            "Epoch [12/70], Step [921/1231], D_A_loss: 0.2290, D_B_loss: 0.0507, G_A_loss: 0.1699, G_B_loss: 0.4048\n",
            "Epoch [12/70], Step [931/1231], D_A_loss: 0.1853, D_B_loss: 0.0244, G_A_loss: 0.5573, G_B_loss: 0.4536\n",
            "Epoch [12/70], Step [941/1231], D_A_loss: 0.1865, D_B_loss: 0.2589, G_A_loss: 0.2326, G_B_loss: 0.4199\n",
            "Epoch [12/70], Step [951/1231], D_A_loss: 0.0409, D_B_loss: 0.0428, G_A_loss: 0.3640, G_B_loss: 0.3839\n",
            "Epoch [12/70], Step [961/1231], D_A_loss: 0.0571, D_B_loss: 0.0715, G_A_loss: 0.5506, G_B_loss: 0.5034\n",
            "Epoch [13/70], Step [1/1231], D_A_loss: 0.1116, D_B_loss: 0.0384, G_A_loss: 0.6613, G_B_loss: 0.3498\n",
            "Epoch [13/70], Step [11/1231], D_A_loss: 0.1867, D_B_loss: 0.0426, G_A_loss: 0.3589, G_B_loss: 0.2748\n",
            "Epoch [13/70], Step [21/1231], D_A_loss: 0.0921, D_B_loss: 0.1686, G_A_loss: 0.3081, G_B_loss: 0.3908\n",
            "Epoch [13/70], Step [31/1231], D_A_loss: 0.0837, D_B_loss: 0.1386, G_A_loss: 0.4862, G_B_loss: 0.2121\n",
            "Epoch [13/70], Step [41/1231], D_A_loss: 0.2334, D_B_loss: 0.0642, G_A_loss: 0.4448, G_B_loss: 0.7451\n",
            "Epoch [13/70], Step [51/1231], D_A_loss: 0.0934, D_B_loss: 0.0508, G_A_loss: 0.2628, G_B_loss: 0.3992\n",
            "Epoch [13/70], Step [61/1231], D_A_loss: 0.1746, D_B_loss: 0.0450, G_A_loss: 0.5056, G_B_loss: 0.8596\n",
            "Epoch [13/70], Step [71/1231], D_A_loss: 0.1051, D_B_loss: 0.2010, G_A_loss: 0.2758, G_B_loss: 0.6843\n",
            "Epoch [13/70], Step [81/1231], D_A_loss: 0.0427, D_B_loss: 0.0599, G_A_loss: 0.2712, G_B_loss: 0.4163\n",
            "Epoch [13/70], Step [91/1231], D_A_loss: 0.1521, D_B_loss: 0.1315, G_A_loss: 0.4466, G_B_loss: 0.3644\n",
            "Epoch [13/70], Step [101/1231], D_A_loss: 0.1838, D_B_loss: 0.2963, G_A_loss: 0.1946, G_B_loss: 0.1986\n",
            "Epoch [13/70], Step [111/1231], D_A_loss: 0.2165, D_B_loss: 0.1876, G_A_loss: 0.4075, G_B_loss: 0.2021\n",
            "Epoch [13/70], Step [121/1231], D_A_loss: 0.0954, D_B_loss: 0.0932, G_A_loss: 0.4916, G_B_loss: 0.6022\n",
            "Epoch [13/70], Step [131/1231], D_A_loss: 0.0469, D_B_loss: 0.1232, G_A_loss: 0.5642, G_B_loss: 0.4186\n",
            "Epoch [13/70], Step [141/1231], D_A_loss: 0.3006, D_B_loss: 0.0181, G_A_loss: 0.6665, G_B_loss: 0.1776\n",
            "Epoch [13/70], Step [151/1231], D_A_loss: 0.0386, D_B_loss: 0.0727, G_A_loss: 0.2417, G_B_loss: 0.4456\n",
            "Epoch [13/70], Step [161/1231], D_A_loss: 0.1898, D_B_loss: 0.0516, G_A_loss: 0.7478, G_B_loss: 0.2940\n",
            "Epoch [13/70], Step [171/1231], D_A_loss: 0.0503, D_B_loss: 0.0359, G_A_loss: 0.7376, G_B_loss: 0.6301\n",
            "Epoch [13/70], Step [181/1231], D_A_loss: 0.0931, D_B_loss: 0.1441, G_A_loss: 0.5201, G_B_loss: 0.7993\n",
            "Epoch [13/70], Step [191/1231], D_A_loss: 0.1539, D_B_loss: 0.0855, G_A_loss: 0.1236, G_B_loss: 0.3383\n",
            "Epoch [13/70], Step [201/1231], D_A_loss: 0.2408, D_B_loss: 0.1699, G_A_loss: 0.3544, G_B_loss: 0.1442\n",
            "Epoch [13/70], Step [211/1231], D_A_loss: 0.1939, D_B_loss: 0.0490, G_A_loss: 0.1689, G_B_loss: 0.4390\n",
            "Epoch [13/70], Step [221/1231], D_A_loss: 0.1581, D_B_loss: 0.0296, G_A_loss: 0.5277, G_B_loss: 0.4325\n",
            "Epoch [13/70], Step [231/1231], D_A_loss: 0.1308, D_B_loss: 0.0661, G_A_loss: 0.7019, G_B_loss: 0.3920\n",
            "Epoch [13/70], Step [241/1231], D_A_loss: 0.0608, D_B_loss: 0.0770, G_A_loss: 0.2110, G_B_loss: 0.5770\n",
            "Epoch [13/70], Step [251/1231], D_A_loss: 0.1115, D_B_loss: 0.0526, G_A_loss: 1.0261, G_B_loss: 0.4189\n",
            "Epoch [13/70], Step [261/1231], D_A_loss: 0.1840, D_B_loss: 0.0421, G_A_loss: 0.3519, G_B_loss: 0.2399\n",
            "Epoch [13/70], Step [271/1231], D_A_loss: 0.2128, D_B_loss: 0.1883, G_A_loss: 0.1513, G_B_loss: 0.1996\n",
            "Epoch [13/70], Step [281/1231], D_A_loss: 0.1806, D_B_loss: 0.0377, G_A_loss: 0.4303, G_B_loss: 0.7053\n",
            "Epoch [13/70], Step [291/1231], D_A_loss: 0.0325, D_B_loss: 0.0526, G_A_loss: 0.8620, G_B_loss: 0.4413\n",
            "Epoch [13/70], Step [301/1231], D_A_loss: 0.1043, D_B_loss: 0.0733, G_A_loss: 0.4784, G_B_loss: 0.4301\n",
            "Epoch [13/70], Step [311/1231], D_A_loss: 0.0652, D_B_loss: 0.0411, G_A_loss: 0.3723, G_B_loss: 0.2151\n",
            "Epoch [13/70], Step [321/1231], D_A_loss: 0.1336, D_B_loss: 0.1427, G_A_loss: 0.3457, G_B_loss: 0.3878\n",
            "Epoch [13/70], Step [331/1231], D_A_loss: 0.1285, D_B_loss: 0.2307, G_A_loss: 0.2435, G_B_loss: 0.4462\n",
            "Epoch [13/70], Step [341/1231], D_A_loss: 0.1806, D_B_loss: 0.2874, G_A_loss: 0.1336, G_B_loss: 0.2327\n",
            "Epoch [13/70], Step [351/1231], D_A_loss: 0.0791, D_B_loss: 0.0935, G_A_loss: 0.1777, G_B_loss: 0.3784\n",
            "Epoch [13/70], Step [361/1231], D_A_loss: 0.0370, D_B_loss: 0.0382, G_A_loss: 0.4845, G_B_loss: 0.1686\n",
            "Epoch [13/70], Step [371/1231], D_A_loss: 0.0779, D_B_loss: 0.1436, G_A_loss: 0.3663, G_B_loss: 0.6432\n",
            "Epoch [13/70], Step [381/1231], D_A_loss: 0.1434, D_B_loss: 0.1317, G_A_loss: 0.4272, G_B_loss: 0.4792\n",
            "Epoch [13/70], Step [391/1231], D_A_loss: 0.1785, D_B_loss: 0.0691, G_A_loss: 0.6878, G_B_loss: 0.2793\n",
            "Epoch [13/70], Step [401/1231], D_A_loss: 0.1204, D_B_loss: 0.0327, G_A_loss: 0.2701, G_B_loss: 0.3245\n",
            "Epoch [13/70], Step [411/1231], D_A_loss: 0.0442, D_B_loss: 0.1344, G_A_loss: 0.9662, G_B_loss: 0.5613\n",
            "Epoch [13/70], Step [421/1231], D_A_loss: 0.0708, D_B_loss: 0.1303, G_A_loss: 0.3284, G_B_loss: 0.5548\n",
            "Epoch [13/70], Step [431/1231], D_A_loss: 0.2328, D_B_loss: 0.2125, G_A_loss: 0.5438, G_B_loss: 0.1964\n",
            "Epoch [13/70], Step [441/1231], D_A_loss: 0.0876, D_B_loss: 0.1444, G_A_loss: 0.4076, G_B_loss: 0.6450\n",
            "Epoch [13/70], Step [451/1231], D_A_loss: 0.1969, D_B_loss: 0.1426, G_A_loss: 0.8094, G_B_loss: 0.3188\n",
            "Epoch [13/70], Step [461/1231], D_A_loss: 0.1787, D_B_loss: 0.1810, G_A_loss: 0.5073, G_B_loss: 0.5388\n",
            "Epoch [13/70], Step [471/1231], D_A_loss: 0.1756, D_B_loss: 0.1134, G_A_loss: 0.3499, G_B_loss: 0.5586\n",
            "Epoch [13/70], Step [481/1231], D_A_loss: 0.0794, D_B_loss: 0.2337, G_A_loss: 0.3173, G_B_loss: 0.3325\n",
            "Epoch [13/70], Step [491/1231], D_A_loss: 0.0636, D_B_loss: 0.0366, G_A_loss: 0.7054, G_B_loss: 0.8326\n",
            "Epoch [13/70], Step [501/1231], D_A_loss: 0.0432, D_B_loss: 0.2634, G_A_loss: 0.1290, G_B_loss: 0.6189\n",
            "Epoch [13/70], Step [511/1231], D_A_loss: 0.1462, D_B_loss: 0.1675, G_A_loss: 0.2347, G_B_loss: 0.3906\n",
            "Epoch [13/70], Step [521/1231], D_A_loss: 0.0777, D_B_loss: 0.0742, G_A_loss: 0.5318, G_B_loss: 0.2327\n",
            "Epoch [13/70], Step [531/1231], D_A_loss: 0.0429, D_B_loss: 0.1010, G_A_loss: 0.5967, G_B_loss: 0.3218\n",
            "Epoch [13/70], Step [541/1231], D_A_loss: 0.1444, D_B_loss: 0.1094, G_A_loss: 0.5455, G_B_loss: 0.5578\n",
            "Epoch [13/70], Step [551/1231], D_A_loss: 0.0954, D_B_loss: 0.1757, G_A_loss: 0.4328, G_B_loss: 0.3317\n",
            "Epoch [13/70], Step [561/1231], D_A_loss: 0.0528, D_B_loss: 0.1075, G_A_loss: 0.7394, G_B_loss: 0.7961\n",
            "Epoch [13/70], Step [571/1231], D_A_loss: 0.1425, D_B_loss: 0.2708, G_A_loss: 0.1462, G_B_loss: 0.2804\n",
            "Epoch [13/70], Step [581/1231], D_A_loss: 0.1930, D_B_loss: 0.1507, G_A_loss: 0.7517, G_B_loss: 0.2868\n",
            "Epoch [13/70], Step [591/1231], D_A_loss: 0.2105, D_B_loss: 0.1544, G_A_loss: 0.2815, G_B_loss: 0.5126\n",
            "Epoch [13/70], Step [601/1231], D_A_loss: 0.0549, D_B_loss: 0.0267, G_A_loss: 0.5511, G_B_loss: 0.1673\n",
            "Epoch [13/70], Step [611/1231], D_A_loss: 0.0886, D_B_loss: 0.0403, G_A_loss: 0.6973, G_B_loss: 0.1782\n",
            "Epoch [13/70], Step [621/1231], D_A_loss: 0.1591, D_B_loss: 0.1251, G_A_loss: 0.5018, G_B_loss: 0.3928\n",
            "Epoch [13/70], Step [631/1231], D_A_loss: 0.1767, D_B_loss: 0.1201, G_A_loss: 0.3691, G_B_loss: 0.2192\n",
            "Epoch [13/70], Step [641/1231], D_A_loss: 0.2022, D_B_loss: 0.0749, G_A_loss: 0.5087, G_B_loss: 0.2918\n",
            "Epoch [13/70], Step [651/1231], D_A_loss: 0.1036, D_B_loss: 0.1459, G_A_loss: 0.2665, G_B_loss: 0.7666\n",
            "Epoch [13/70], Step [661/1231], D_A_loss: 0.0838, D_B_loss: 0.2241, G_A_loss: 0.3378, G_B_loss: 0.4756\n",
            "Epoch [13/70], Step [671/1231], D_A_loss: 0.1722, D_B_loss: 0.0666, G_A_loss: 0.3518, G_B_loss: 0.4388\n",
            "Epoch [13/70], Step [681/1231], D_A_loss: 0.1756, D_B_loss: 0.0629, G_A_loss: 0.2884, G_B_loss: 0.4532\n",
            "Epoch [13/70], Step [691/1231], D_A_loss: 0.3053, D_B_loss: 0.1242, G_A_loss: 0.4562, G_B_loss: 0.2175\n",
            "Epoch [13/70], Step [701/1231], D_A_loss: 0.2086, D_B_loss: 0.0257, G_A_loss: 0.1319, G_B_loss: 0.1796\n",
            "Epoch [13/70], Step [711/1231], D_A_loss: 0.1931, D_B_loss: 0.0569, G_A_loss: 0.1877, G_B_loss: 0.1884\n",
            "Epoch [13/70], Step [721/1231], D_A_loss: 0.2349, D_B_loss: 0.1356, G_A_loss: 0.2080, G_B_loss: 0.1308\n",
            "Epoch [13/70], Step [731/1231], D_A_loss: 0.0466, D_B_loss: 0.1233, G_A_loss: 0.3676, G_B_loss: 0.4929\n",
            "Epoch [13/70], Step [741/1231], D_A_loss: 0.1099, D_B_loss: 0.1728, G_A_loss: 0.2970, G_B_loss: 0.4868\n",
            "Epoch [13/70], Step [751/1231], D_A_loss: 0.1046, D_B_loss: 0.0481, G_A_loss: 0.5877, G_B_loss: 0.3985\n",
            "Epoch [13/70], Step [761/1231], D_A_loss: 0.3333, D_B_loss: 0.0720, G_A_loss: 0.6632, G_B_loss: 0.7290\n",
            "Epoch [13/70], Step [771/1231], D_A_loss: 0.0947, D_B_loss: 0.1757, G_A_loss: 0.2810, G_B_loss: 0.5131\n",
            "Epoch [13/70], Step [781/1231], D_A_loss: 0.0960, D_B_loss: 0.0359, G_A_loss: 0.4019, G_B_loss: 0.6882\n",
            "Epoch [13/70], Step [791/1231], D_A_loss: 0.0630, D_B_loss: 0.0983, G_A_loss: 0.2835, G_B_loss: 0.5312\n",
            "Epoch [13/70], Step [801/1231], D_A_loss: 0.0818, D_B_loss: 0.2099, G_A_loss: 0.6409, G_B_loss: 0.4990\n",
            "Epoch [13/70], Step [811/1231], D_A_loss: 0.1140, D_B_loss: 0.1650, G_A_loss: 0.7244, G_B_loss: 0.6753\n",
            "Epoch [13/70], Step [821/1231], D_A_loss: 0.1530, D_B_loss: 0.1657, G_A_loss: 0.2442, G_B_loss: 0.3978\n",
            "Epoch [13/70], Step [831/1231], D_A_loss: 0.2064, D_B_loss: 0.0907, G_A_loss: 0.3703, G_B_loss: 0.3193\n",
            "Epoch [13/70], Step [841/1231], D_A_loss: 0.0224, D_B_loss: 0.1104, G_A_loss: 0.6389, G_B_loss: 0.4074\n",
            "Epoch [13/70], Step [851/1231], D_A_loss: 0.1206, D_B_loss: 0.1351, G_A_loss: 0.3214, G_B_loss: 0.4875\n",
            "Epoch [13/70], Step [861/1231], D_A_loss: 0.1143, D_B_loss: 0.1707, G_A_loss: 0.6064, G_B_loss: 0.4545\n",
            "Epoch [13/70], Step [871/1231], D_A_loss: 0.1257, D_B_loss: 0.3647, G_A_loss: 0.0820, G_B_loss: 0.5036\n",
            "Epoch [13/70], Step [881/1231], D_A_loss: 0.1922, D_B_loss: 0.0463, G_A_loss: 0.5323, G_B_loss: 0.3267\n",
            "Epoch [13/70], Step [891/1231], D_A_loss: 0.1216, D_B_loss: 0.0642, G_A_loss: 0.5291, G_B_loss: 0.4687\n",
            "Epoch [13/70], Step [901/1231], D_A_loss: 0.0846, D_B_loss: 0.3126, G_A_loss: 0.2435, G_B_loss: 0.6357\n",
            "Epoch [13/70], Step [911/1231], D_A_loss: 0.0225, D_B_loss: 0.1481, G_A_loss: 0.3543, G_B_loss: 0.2976\n",
            "Epoch [13/70], Step [921/1231], D_A_loss: 0.0321, D_B_loss: 0.1185, G_A_loss: 0.3851, G_B_loss: 0.7206\n",
            "Epoch [13/70], Step [931/1231], D_A_loss: 0.0560, D_B_loss: 0.1815, G_A_loss: 0.5578, G_B_loss: 0.4278\n",
            "Epoch [13/70], Step [941/1231], D_A_loss: 0.0288, D_B_loss: 0.1790, G_A_loss: 0.5402, G_B_loss: 0.3680\n",
            "Epoch [13/70], Step [951/1231], D_A_loss: 0.0659, D_B_loss: 0.1127, G_A_loss: 0.2011, G_B_loss: 0.3678\n",
            "Epoch [13/70], Step [961/1231], D_A_loss: 0.0440, D_B_loss: 0.0516, G_A_loss: 0.5000, G_B_loss: 0.7582\n",
            "Epoch [14/70], Step [1/1231], D_A_loss: 0.0485, D_B_loss: 0.1060, G_A_loss: 0.3858, G_B_loss: 1.0363\n",
            "Epoch [14/70], Step [11/1231], D_A_loss: 0.2026, D_B_loss: 0.0207, G_A_loss: 0.2546, G_B_loss: 0.1772\n",
            "Epoch [14/70], Step [21/1231], D_A_loss: 0.0775, D_B_loss: 0.0318, G_A_loss: 0.7053, G_B_loss: 0.4225\n",
            "Epoch [14/70], Step [31/1231], D_A_loss: 0.0787, D_B_loss: 0.2810, G_A_loss: 0.7527, G_B_loss: 0.4930\n",
            "Epoch [14/70], Step [41/1231], D_A_loss: 0.0488, D_B_loss: 0.0407, G_A_loss: 0.9098, G_B_loss: 0.5805\n",
            "Epoch [14/70], Step [51/1231], D_A_loss: 0.0954, D_B_loss: 0.0695, G_A_loss: 0.5395, G_B_loss: 0.2710\n",
            "Epoch [14/70], Step [61/1231], D_A_loss: 0.0838, D_B_loss: 0.2043, G_A_loss: 0.2385, G_B_loss: 0.3434\n",
            "Epoch [14/70], Step [71/1231], D_A_loss: 0.0447, D_B_loss: 0.1059, G_A_loss: 0.7377, G_B_loss: 0.5457\n",
            "Epoch [14/70], Step [81/1231], D_A_loss: 0.1841, D_B_loss: 0.1446, G_A_loss: 0.4822, G_B_loss: 0.4627\n",
            "Epoch [14/70], Step [91/1231], D_A_loss: 0.0758, D_B_loss: 0.0650, G_A_loss: 0.6880, G_B_loss: 0.5315\n",
            "Epoch [14/70], Step [101/1231], D_A_loss: 0.1769, D_B_loss: 0.0577, G_A_loss: 0.5475, G_B_loss: 0.5277\n",
            "Epoch [14/70], Step [111/1231], D_A_loss: 0.1261, D_B_loss: 0.1849, G_A_loss: 0.7592, G_B_loss: 0.7373\n",
            "Epoch [14/70], Step [121/1231], D_A_loss: 0.1980, D_B_loss: 0.0629, G_A_loss: 0.2100, G_B_loss: 0.3655\n",
            "Epoch [14/70], Step [131/1231], D_A_loss: 0.0993, D_B_loss: 0.0883, G_A_loss: 0.5683, G_B_loss: 0.9396\n",
            "Epoch [14/70], Step [141/1231], D_A_loss: 0.0495, D_B_loss: 0.0185, G_A_loss: 0.6607, G_B_loss: 0.6595\n",
            "Epoch [14/70], Step [151/1231], D_A_loss: 0.0428, D_B_loss: 0.0234, G_A_loss: 0.4593, G_B_loss: 0.8511\n",
            "Epoch [14/70], Step [161/1231], D_A_loss: 0.0883, D_B_loss: 0.1240, G_A_loss: 0.3373, G_B_loss: 0.3487\n",
            "Epoch [14/70], Step [171/1231], D_A_loss: 0.1111, D_B_loss: 0.0406, G_A_loss: 0.3641, G_B_loss: 0.4582\n",
            "Epoch [14/70], Step [181/1231], D_A_loss: 0.2058, D_B_loss: 0.2243, G_A_loss: 0.2349, G_B_loss: 0.1907\n",
            "Epoch [14/70], Step [191/1231], D_A_loss: 0.0295, D_B_loss: 0.1808, G_A_loss: 0.2472, G_B_loss: 0.8986\n",
            "Epoch [14/70], Step [201/1231], D_A_loss: 0.1674, D_B_loss: 0.0655, G_A_loss: 0.2375, G_B_loss: 0.4927\n",
            "Epoch [14/70], Step [211/1231], D_A_loss: 0.0818, D_B_loss: 0.0475, G_A_loss: 0.6058, G_B_loss: 0.2251\n",
            "Epoch [14/70], Step [221/1231], D_A_loss: 0.1151, D_B_loss: 0.2231, G_A_loss: 0.8547, G_B_loss: 0.4183\n",
            "Epoch [14/70], Step [231/1231], D_A_loss: 0.2699, D_B_loss: 0.3028, G_A_loss: 0.1258, G_B_loss: 0.4239\n",
            "Epoch [14/70], Step [241/1231], D_A_loss: 0.3092, D_B_loss: 0.1122, G_A_loss: 0.5898, G_B_loss: 0.3408\n",
            "Epoch [14/70], Step [251/1231], D_A_loss: 0.0705, D_B_loss: 0.0471, G_A_loss: 0.5103, G_B_loss: 0.4303\n",
            "Epoch [14/70], Step [261/1231], D_A_loss: 0.0316, D_B_loss: 0.1610, G_A_loss: 0.4616, G_B_loss: 0.5908\n",
            "Epoch [14/70], Step [271/1231], D_A_loss: 0.1175, D_B_loss: 0.1975, G_A_loss: 0.2496, G_B_loss: 0.1513\n",
            "Epoch [14/70], Step [281/1231], D_A_loss: 0.0402, D_B_loss: 0.0847, G_A_loss: 0.5263, G_B_loss: 0.3740\n",
            "Epoch [14/70], Step [291/1231], D_A_loss: 0.1898, D_B_loss: 0.2282, G_A_loss: 0.3295, G_B_loss: 0.2525\n",
            "Epoch [14/70], Step [301/1231], D_A_loss: 0.0424, D_B_loss: 0.0651, G_A_loss: 0.3191, G_B_loss: 0.3861\n",
            "Epoch [14/70], Step [311/1231], D_A_loss: 0.2303, D_B_loss: 0.0619, G_A_loss: 0.5596, G_B_loss: 0.2224\n",
            "Epoch [14/70], Step [321/1231], D_A_loss: 0.0352, D_B_loss: 0.0610, G_A_loss: 0.3348, G_B_loss: 0.3646\n",
            "Epoch [14/70], Step [331/1231], D_A_loss: 0.0296, D_B_loss: 0.1169, G_A_loss: 0.3535, G_B_loss: 0.2968\n",
            "Epoch [14/70], Step [341/1231], D_A_loss: 0.1047, D_B_loss: 0.1145, G_A_loss: 0.4763, G_B_loss: 0.5891\n",
            "Epoch [14/70], Step [351/1231], D_A_loss: 0.0443, D_B_loss: 0.0463, G_A_loss: 0.6347, G_B_loss: 0.5423\n",
            "Epoch [14/70], Step [361/1231], D_A_loss: 0.0881, D_B_loss: 0.0305, G_A_loss: 0.4369, G_B_loss: 0.6490\n",
            "Epoch [14/70], Step [371/1231], D_A_loss: 0.0895, D_B_loss: 0.0646, G_A_loss: 0.3820, G_B_loss: 0.5679\n",
            "Epoch [14/70], Step [381/1231], D_A_loss: 0.1164, D_B_loss: 0.0768, G_A_loss: 0.5022, G_B_loss: 0.8966\n",
            "Epoch [14/70], Step [391/1231], D_A_loss: 0.1797, D_B_loss: 0.1809, G_A_loss: 0.2463, G_B_loss: 0.3182\n",
            "Epoch [14/70], Step [401/1231], D_A_loss: 0.1229, D_B_loss: 0.0539, G_A_loss: 0.5698, G_B_loss: 0.4017\n",
            "Epoch [14/70], Step [411/1231], D_A_loss: 0.1141, D_B_loss: 0.1346, G_A_loss: 0.5893, G_B_loss: 0.9454\n",
            "Epoch [14/70], Step [421/1231], D_A_loss: 0.1536, D_B_loss: 0.0685, G_A_loss: 0.3280, G_B_loss: 0.2947\n",
            "Epoch [14/70], Step [431/1231], D_A_loss: 0.1132, D_B_loss: 0.1587, G_A_loss: 0.2669, G_B_loss: 0.6556\n",
            "Epoch [14/70], Step [441/1231], D_A_loss: 0.3465, D_B_loss: 0.1383, G_A_loss: 0.3993, G_B_loss: 0.8249\n",
            "Epoch [14/70], Step [451/1231], D_A_loss: 0.1739, D_B_loss: 0.1684, G_A_loss: 0.5891, G_B_loss: 0.2752\n",
            "Epoch [14/70], Step [461/1231], D_A_loss: 0.1122, D_B_loss: 0.0826, G_A_loss: 0.6090, G_B_loss: 0.4244\n",
            "Epoch [14/70], Step [471/1231], D_A_loss: 0.1087, D_B_loss: 0.0385, G_A_loss: 0.7414, G_B_loss: 0.5188\n",
            "Epoch [14/70], Step [481/1231], D_A_loss: 0.1435, D_B_loss: 0.0798, G_A_loss: 0.4142, G_B_loss: 0.2962\n",
            "Epoch [14/70], Step [491/1231], D_A_loss: 0.1306, D_B_loss: 0.0627, G_A_loss: 0.5733, G_B_loss: 0.3387\n",
            "Epoch [14/70], Step [501/1231], D_A_loss: 0.0798, D_B_loss: 0.1274, G_A_loss: 0.5626, G_B_loss: 0.2147\n",
            "Epoch [14/70], Step [511/1231], D_A_loss: 0.0337, D_B_loss: 0.2173, G_A_loss: 0.5628, G_B_loss: 0.2565\n",
            "Epoch [14/70], Step [521/1231], D_A_loss: 0.1627, D_B_loss: 0.0478, G_A_loss: 0.5214, G_B_loss: 0.2660\n",
            "Epoch [14/70], Step [531/1231], D_A_loss: 0.1356, D_B_loss: 0.1758, G_A_loss: 0.2948, G_B_loss: 0.4874\n",
            "Epoch [14/70], Step [541/1231], D_A_loss: 0.1680, D_B_loss: 0.1099, G_A_loss: 0.5040, G_B_loss: 0.4229\n",
            "Epoch [14/70], Step [551/1231], D_A_loss: 0.2804, D_B_loss: 0.1895, G_A_loss: 0.3243, G_B_loss: 0.3980\n",
            "Epoch [14/70], Step [561/1231], D_A_loss: 0.0890, D_B_loss: 0.1489, G_A_loss: 0.6204, G_B_loss: 0.6034\n",
            "Epoch [14/70], Step [571/1231], D_A_loss: 0.1178, D_B_loss: 0.0907, G_A_loss: 0.3355, G_B_loss: 0.7016\n",
            "Epoch [14/70], Step [581/1231], D_A_loss: 0.1115, D_B_loss: 0.2050, G_A_loss: 0.2381, G_B_loss: 0.4317\n",
            "Epoch [14/70], Step [591/1231], D_A_loss: 0.1213, D_B_loss: 0.1044, G_A_loss: 0.4274, G_B_loss: 0.3856\n",
            "Epoch [14/70], Step [601/1231], D_A_loss: 0.2933, D_B_loss: 0.0385, G_A_loss: 0.4702, G_B_loss: 0.8959\n",
            "Epoch [14/70], Step [611/1231], D_A_loss: 0.0651, D_B_loss: 0.1337, G_A_loss: 0.6619, G_B_loss: 0.5441\n",
            "Epoch [14/70], Step [621/1231], D_A_loss: 0.0335, D_B_loss: 0.0910, G_A_loss: 0.8332, G_B_loss: 0.4047\n",
            "Epoch [14/70], Step [631/1231], D_A_loss: 0.0390, D_B_loss: 0.1989, G_A_loss: 0.9771, G_B_loss: 0.7578\n",
            "Epoch [14/70], Step [641/1231], D_A_loss: 0.4094, D_B_loss: 0.2312, G_A_loss: 0.2393, G_B_loss: 0.0440\n",
            "Epoch [14/70], Step [651/1231], D_A_loss: 0.2152, D_B_loss: 0.1404, G_A_loss: 0.7192, G_B_loss: 0.2920\n",
            "Epoch [14/70], Step [661/1231], D_A_loss: 0.0903, D_B_loss: 0.0636, G_A_loss: 0.2817, G_B_loss: 0.3110\n",
            "Epoch [14/70], Step [671/1231], D_A_loss: 0.0886, D_B_loss: 0.0470, G_A_loss: 0.8640, G_B_loss: 0.4831\n",
            "Epoch [14/70], Step [681/1231], D_A_loss: 0.0626, D_B_loss: 0.0999, G_A_loss: 0.4073, G_B_loss: 0.4955\n",
            "Epoch [14/70], Step [691/1231], D_A_loss: 0.0296, D_B_loss: 0.0458, G_A_loss: 0.2947, G_B_loss: 0.3332\n",
            "Epoch [14/70], Step [701/1231], D_A_loss: 0.0766, D_B_loss: 0.0471, G_A_loss: 0.5877, G_B_loss: 0.1337\n",
            "Epoch [14/70], Step [711/1231], D_A_loss: 0.1249, D_B_loss: 0.1410, G_A_loss: 0.1238, G_B_loss: 0.4795\n",
            "Epoch [14/70], Step [721/1231], D_A_loss: 0.1104, D_B_loss: 0.0296, G_A_loss: 0.2701, G_B_loss: 0.3896\n",
            "Epoch [14/70], Step [731/1231], D_A_loss: 0.1019, D_B_loss: 0.0331, G_A_loss: 0.7567, G_B_loss: 0.3309\n",
            "Epoch [14/70], Step [741/1231], D_A_loss: 0.1036, D_B_loss: 0.0448, G_A_loss: 0.5292, G_B_loss: 0.5287\n",
            "Epoch [14/70], Step [751/1231], D_A_loss: 0.0974, D_B_loss: 0.1399, G_A_loss: 0.3957, G_B_loss: 0.4733\n",
            "Epoch [14/70], Step [761/1231], D_A_loss: 0.0585, D_B_loss: 0.1723, G_A_loss: 0.2580, G_B_loss: 0.5581\n",
            "Epoch [14/70], Step [771/1231], D_A_loss: 0.0914, D_B_loss: 0.0613, G_A_loss: 0.4827, G_B_loss: 0.5384\n",
            "Epoch [14/70], Step [781/1231], D_A_loss: 0.0759, D_B_loss: 0.1968, G_A_loss: 0.6733, G_B_loss: 0.8436\n",
            "Epoch [14/70], Step [791/1231], D_A_loss: 0.0763, D_B_loss: 0.0485, G_A_loss: 0.3416, G_B_loss: 0.4661\n",
            "Epoch [14/70], Step [801/1231], D_A_loss: 0.1101, D_B_loss: 0.0473, G_A_loss: 0.3168, G_B_loss: 0.3884\n",
            "Epoch [14/70], Step [811/1231], D_A_loss: 0.1392, D_B_loss: 0.1673, G_A_loss: 0.7455, G_B_loss: 0.4834\n",
            "Epoch [14/70], Step [821/1231], D_A_loss: 0.0895, D_B_loss: 0.1421, G_A_loss: 0.3110, G_B_loss: 0.4070\n",
            "Epoch [14/70], Step [831/1231], D_A_loss: 0.0454, D_B_loss: 0.1032, G_A_loss: 0.4033, G_B_loss: 0.4811\n",
            "Epoch [14/70], Step [841/1231], D_A_loss: 0.0826, D_B_loss: 0.0300, G_A_loss: 0.4146, G_B_loss: 0.2205\n",
            "Epoch [14/70], Step [851/1231], D_A_loss: 0.2507, D_B_loss: 0.2758, G_A_loss: 0.6984, G_B_loss: 0.1919\n",
            "Epoch [14/70], Step [861/1231], D_A_loss: 0.2632, D_B_loss: 0.1886, G_A_loss: 0.6302, G_B_loss: 0.1256\n",
            "Epoch [14/70], Step [871/1231], D_A_loss: 0.0900, D_B_loss: 0.1458, G_A_loss: 0.2813, G_B_loss: 0.5402\n",
            "Epoch [14/70], Step [881/1231], D_A_loss: 0.1991, D_B_loss: 0.1140, G_A_loss: 0.5353, G_B_loss: 0.2395\n",
            "Epoch [14/70], Step [891/1231], D_A_loss: 0.1151, D_B_loss: 0.1178, G_A_loss: 0.3712, G_B_loss: 0.3914\n",
            "Epoch [14/70], Step [901/1231], D_A_loss: 0.0352, D_B_loss: 0.0415, G_A_loss: 0.5027, G_B_loss: 0.9550\n",
            "Epoch [14/70], Step [911/1231], D_A_loss: 0.0252, D_B_loss: 0.0876, G_A_loss: 0.4448, G_B_loss: 0.3503\n",
            "Epoch [14/70], Step [921/1231], D_A_loss: 0.2002, D_B_loss: 0.0405, G_A_loss: 0.2404, G_B_loss: 0.8045\n",
            "Epoch [14/70], Step [931/1231], D_A_loss: 0.2322, D_B_loss: 0.1550, G_A_loss: 0.2633, G_B_loss: 0.3309\n",
            "Epoch [14/70], Step [941/1231], D_A_loss: 0.0834, D_B_loss: 0.0344, G_A_loss: 0.4535, G_B_loss: 0.6406\n",
            "Epoch [14/70], Step [951/1231], D_A_loss: 0.0933, D_B_loss: 0.0403, G_A_loss: 0.8481, G_B_loss: 0.6488\n",
            "Epoch [14/70], Step [961/1231], D_A_loss: 0.0645, D_B_loss: 0.0565, G_A_loss: 0.4693, G_B_loss: 0.6406\n",
            "Epoch [15/70], Step [1/1231], D_A_loss: 0.2101, D_B_loss: 0.1429, G_A_loss: 0.3212, G_B_loss: 0.6394\n",
            "Epoch [15/70], Step [11/1231], D_A_loss: 0.0925, D_B_loss: 0.0940, G_A_loss: 0.4404, G_B_loss: 0.1232\n",
            "Epoch [15/70], Step [21/1231], D_A_loss: 0.1902, D_B_loss: 0.0486, G_A_loss: 0.6685, G_B_loss: 0.4582\n",
            "Epoch [15/70], Step [31/1231], D_A_loss: 0.0882, D_B_loss: 0.0426, G_A_loss: 0.3929, G_B_loss: 0.4370\n",
            "Epoch [15/70], Step [41/1231], D_A_loss: 0.0947, D_B_loss: 0.0767, G_A_loss: 0.7118, G_B_loss: 0.5252\n",
            "Epoch [15/70], Step [51/1231], D_A_loss: 0.1618, D_B_loss: 0.1083, G_A_loss: 0.4954, G_B_loss: 0.9720\n",
            "Epoch [15/70], Step [61/1231], D_A_loss: 0.1490, D_B_loss: 0.1823, G_A_loss: 0.3000, G_B_loss: 0.7150\n",
            "Epoch [15/70], Step [71/1231], D_A_loss: 0.0596, D_B_loss: 0.0656, G_A_loss: 0.3497, G_B_loss: 0.3399\n",
            "Epoch [15/70], Step [81/1231], D_A_loss: 0.0677, D_B_loss: 0.1328, G_A_loss: 0.3411, G_B_loss: 0.0772\n",
            "Epoch [15/70], Step [91/1231], D_A_loss: 0.1272, D_B_loss: 0.1287, G_A_loss: 0.3150, G_B_loss: 0.4124\n",
            "Epoch [15/70], Step [101/1231], D_A_loss: 0.0817, D_B_loss: 0.0731, G_A_loss: 0.4618, G_B_loss: 0.3433\n",
            "Epoch [15/70], Step [111/1231], D_A_loss: 0.1979, D_B_loss: 0.0322, G_A_loss: 0.2227, G_B_loss: 0.2099\n",
            "Epoch [15/70], Step [121/1231], D_A_loss: 0.1302, D_B_loss: 0.1349, G_A_loss: 0.6140, G_B_loss: 0.4260\n",
            "Epoch [15/70], Step [131/1231], D_A_loss: 0.0264, D_B_loss: 0.0449, G_A_loss: 0.3259, G_B_loss: 0.5824\n",
            "Epoch [15/70], Step [141/1231], D_A_loss: 0.0763, D_B_loss: 0.0408, G_A_loss: 0.3136, G_B_loss: 0.5354\n",
            "Epoch [15/70], Step [151/1231], D_A_loss: 0.0739, D_B_loss: 0.0586, G_A_loss: 0.7146, G_B_loss: 0.4913\n",
            "Epoch [15/70], Step [161/1231], D_A_loss: 0.0567, D_B_loss: 0.0882, G_A_loss: 1.0184, G_B_loss: 0.4708\n",
            "Epoch [15/70], Step [171/1231], D_A_loss: 0.2791, D_B_loss: 0.1582, G_A_loss: 0.2716, G_B_loss: 0.0972\n",
            "Epoch [15/70], Step [181/1231], D_A_loss: 0.1869, D_B_loss: 0.0852, G_A_loss: 0.9469, G_B_loss: 0.3350\n",
            "Epoch [15/70], Step [191/1231], D_A_loss: 0.1457, D_B_loss: 0.1841, G_A_loss: 0.3647, G_B_loss: 0.5916\n",
            "Epoch [15/70], Step [201/1231], D_A_loss: 0.0801, D_B_loss: 0.1442, G_A_loss: 0.5140, G_B_loss: 0.3158\n",
            "Epoch [15/70], Step [211/1231], D_A_loss: 0.1625, D_B_loss: 0.0464, G_A_loss: 0.4795, G_B_loss: 0.6670\n",
            "Epoch [15/70], Step [221/1231], D_A_loss: 0.0776, D_B_loss: 0.1198, G_A_loss: 0.5859, G_B_loss: 0.4770\n",
            "Epoch [15/70], Step [231/1231], D_A_loss: 0.0479, D_B_loss: 0.0684, G_A_loss: 0.4507, G_B_loss: 0.4911\n",
            "Epoch [15/70], Step [241/1231], D_A_loss: 0.0761, D_B_loss: 0.2043, G_A_loss: 0.5322, G_B_loss: 0.4443\n",
            "Epoch [15/70], Step [251/1231], D_A_loss: 0.0756, D_B_loss: 0.1885, G_A_loss: 0.5175, G_B_loss: 0.5649\n",
            "Epoch [15/70], Step [261/1231], D_A_loss: 0.0710, D_B_loss: 0.0387, G_A_loss: 0.1688, G_B_loss: 1.0085\n",
            "Epoch [15/70], Step [271/1231], D_A_loss: 0.1832, D_B_loss: 0.0616, G_A_loss: 0.2438, G_B_loss: 0.4118\n",
            "Epoch [15/70], Step [281/1231], D_A_loss: 0.1719, D_B_loss: 0.0430, G_A_loss: 0.7225, G_B_loss: 0.5601\n",
            "Epoch [15/70], Step [291/1231], D_A_loss: 0.0551, D_B_loss: 0.1620, G_A_loss: 0.6549, G_B_loss: 0.8496\n",
            "Epoch [15/70], Step [301/1231], D_A_loss: 0.0637, D_B_loss: 0.2698, G_A_loss: 0.9110, G_B_loss: 0.2271\n",
            "Epoch [15/70], Step [311/1231], D_A_loss: 0.1496, D_B_loss: 0.2034, G_A_loss: 0.3106, G_B_loss: 0.3408\n",
            "Epoch [15/70], Step [321/1231], D_A_loss: 0.1195, D_B_loss: 0.1074, G_A_loss: 0.3988, G_B_loss: 0.3489\n",
            "Epoch [15/70], Step [331/1231], D_A_loss: 0.0961, D_B_loss: 0.0351, G_A_loss: 0.4113, G_B_loss: 0.5566\n",
            "Epoch [15/70], Step [341/1231], D_A_loss: 0.1227, D_B_loss: 0.1487, G_A_loss: 0.4431, G_B_loss: 0.7136\n",
            "Epoch [15/70], Step [351/1231], D_A_loss: 0.0445, D_B_loss: 0.1138, G_A_loss: 0.3760, G_B_loss: 0.6550\n",
            "Epoch [15/70], Step [361/1231], D_A_loss: 0.1106, D_B_loss: 0.0552, G_A_loss: 0.7994, G_B_loss: 0.5738\n",
            "Epoch [15/70], Step [371/1231], D_A_loss: 0.0437, D_B_loss: 0.0779, G_A_loss: 0.3826, G_B_loss: 0.2568\n",
            "Epoch [15/70], Step [381/1231], D_A_loss: 0.2254, D_B_loss: 0.0705, G_A_loss: 0.3802, G_B_loss: 0.4526\n",
            "Epoch [15/70], Step [391/1231], D_A_loss: 0.1369, D_B_loss: 0.1296, G_A_loss: 0.3538, G_B_loss: 0.5043\n",
            "Epoch [15/70], Step [401/1231], D_A_loss: 0.2888, D_B_loss: 0.1689, G_A_loss: 0.5708, G_B_loss: 0.8653\n",
            "Epoch [15/70], Step [411/1231], D_A_loss: 0.2448, D_B_loss: 0.0348, G_A_loss: 0.7436, G_B_loss: 0.5271\n",
            "Epoch [15/70], Step [421/1231], D_A_loss: 0.0344, D_B_loss: 0.0877, G_A_loss: 0.2926, G_B_loss: 0.6997\n",
            "Epoch [15/70], Step [431/1231], D_A_loss: 0.1495, D_B_loss: 0.1273, G_A_loss: 0.4105, G_B_loss: 0.3198\n",
            "Epoch [15/70], Step [441/1231], D_A_loss: 0.0371, D_B_loss: 0.0501, G_A_loss: 0.3506, G_B_loss: 0.3010\n",
            "Epoch [15/70], Step [451/1231], D_A_loss: 0.1227, D_B_loss: 0.1062, G_A_loss: 0.3942, G_B_loss: 0.5351\n",
            "Epoch [15/70], Step [461/1231], D_A_loss: 0.0610, D_B_loss: 0.0688, G_A_loss: 0.5184, G_B_loss: 0.2881\n",
            "Epoch [15/70], Step [471/1231], D_A_loss: 0.1048, D_B_loss: 0.1189, G_A_loss: 0.3749, G_B_loss: 0.6824\n",
            "Epoch [15/70], Step [481/1231], D_A_loss: 0.0512, D_B_loss: 0.0846, G_A_loss: 0.1816, G_B_loss: 0.8414\n",
            "Epoch [15/70], Step [491/1231], D_A_loss: 0.0988, D_B_loss: 0.1993, G_A_loss: 0.3854, G_B_loss: 0.4671\n",
            "Epoch [15/70], Step [501/1231], D_A_loss: 0.1564, D_B_loss: 0.2168, G_A_loss: 0.9825, G_B_loss: 0.4498\n",
            "Epoch [15/70], Step [511/1231], D_A_loss: 0.1233, D_B_loss: 0.0802, G_A_loss: 0.2431, G_B_loss: 0.3229\n",
            "Epoch [15/70], Step [521/1231], D_A_loss: 0.0493, D_B_loss: 0.0234, G_A_loss: 0.3942, G_B_loss: 0.5742\n",
            "Epoch [15/70], Step [531/1231], D_A_loss: 0.1370, D_B_loss: 0.0737, G_A_loss: 0.6058, G_B_loss: 0.4805\n",
            "Epoch [15/70], Step [541/1231], D_A_loss: 0.1267, D_B_loss: 0.1039, G_A_loss: 0.3989, G_B_loss: 0.4202\n",
            "Epoch [15/70], Step [551/1231], D_A_loss: 0.2176, D_B_loss: 0.0904, G_A_loss: 0.5920, G_B_loss: 0.1837\n",
            "Epoch [15/70], Step [561/1231], D_A_loss: 0.0692, D_B_loss: 0.0390, G_A_loss: 0.4388, G_B_loss: 0.6824\n",
            "Epoch [15/70], Step [571/1231], D_A_loss: 0.0385, D_B_loss: 0.0479, G_A_loss: 0.3185, G_B_loss: 0.3007\n",
            "Epoch [15/70], Step [581/1231], D_A_loss: 0.1854, D_B_loss: 0.1029, G_A_loss: 0.3536, G_B_loss: 0.7600\n",
            "Epoch [15/70], Step [591/1231], D_A_loss: 0.1245, D_B_loss: 0.2213, G_A_loss: 0.2600, G_B_loss: 0.5343\n",
            "Epoch [15/70], Step [601/1231], D_A_loss: 0.0248, D_B_loss: 0.1469, G_A_loss: 0.2742, G_B_loss: 1.1981\n",
            "Epoch [15/70], Step [611/1231], D_A_loss: 0.0442, D_B_loss: 0.1104, G_A_loss: 0.4913, G_B_loss: 0.5681\n",
            "Epoch [15/70], Step [621/1231], D_A_loss: 0.1639, D_B_loss: 0.2785, G_A_loss: 0.2306, G_B_loss: 0.3751\n",
            "Epoch [15/70], Step [631/1231], D_A_loss: 0.0622, D_B_loss: 0.1684, G_A_loss: 0.4148, G_B_loss: 0.5408\n",
            "Epoch [15/70], Step [641/1231], D_A_loss: 0.0263, D_B_loss: 0.0292, G_A_loss: 0.8985, G_B_loss: 0.2445\n",
            "Epoch [15/70], Step [651/1231], D_A_loss: 0.0768, D_B_loss: 0.0678, G_A_loss: 0.5500, G_B_loss: 0.3523\n",
            "Epoch [15/70], Step [661/1231], D_A_loss: 0.1844, D_B_loss: 0.1197, G_A_loss: 0.3408, G_B_loss: 0.3432\n",
            "Epoch [15/70], Step [671/1231], D_A_loss: 0.1110, D_B_loss: 0.0798, G_A_loss: 0.6917, G_B_loss: 0.5841\n",
            "Epoch [15/70], Step [681/1231], D_A_loss: 0.1393, D_B_loss: 0.0910, G_A_loss: 0.4443, G_B_loss: 0.7722\n",
            "Epoch [15/70], Step [691/1231], D_A_loss: 0.1623, D_B_loss: 0.1056, G_A_loss: 0.4344, G_B_loss: 0.6601\n",
            "Epoch [15/70], Step [701/1231], D_A_loss: 0.0532, D_B_loss: 0.1660, G_A_loss: 0.2747, G_B_loss: 0.3695\n",
            "Epoch [15/70], Step [711/1231], D_A_loss: 0.1107, D_B_loss: 0.0636, G_A_loss: 0.5953, G_B_loss: 0.6574\n",
            "Epoch [15/70], Step [721/1231], D_A_loss: 0.2994, D_B_loss: 0.0320, G_A_loss: 0.4976, G_B_loss: 0.2741\n",
            "Epoch [15/70], Step [731/1231], D_A_loss: 0.0872, D_B_loss: 0.0732, G_A_loss: 0.7467, G_B_loss: 0.2875\n",
            "Epoch [15/70], Step [741/1231], D_A_loss: 0.0351, D_B_loss: 0.0336, G_A_loss: 0.4655, G_B_loss: 0.3833\n",
            "Epoch [15/70], Step [751/1231], D_A_loss: 0.0806, D_B_loss: 0.0811, G_A_loss: 0.7058, G_B_loss: 0.5029\n",
            "Epoch [15/70], Step [761/1231], D_A_loss: 0.1383, D_B_loss: 0.0727, G_A_loss: 0.3034, G_B_loss: 0.6918\n",
            "Epoch [15/70], Step [771/1231], D_A_loss: 0.1170, D_B_loss: 0.0499, G_A_loss: 0.6111, G_B_loss: 0.1141\n",
            "Epoch [15/70], Step [781/1231], D_A_loss: 0.1547, D_B_loss: 0.0523, G_A_loss: 0.3808, G_B_loss: 0.3028\n",
            "Epoch [15/70], Step [791/1231], D_A_loss: 0.1530, D_B_loss: 0.0384, G_A_loss: 0.1557, G_B_loss: 0.6554\n",
            "Epoch [15/70], Step [801/1231], D_A_loss: 0.0649, D_B_loss: 0.0853, G_A_loss: 0.4275, G_B_loss: 0.4332\n",
            "Epoch [15/70], Step [811/1231], D_A_loss: 0.1162, D_B_loss: 0.1942, G_A_loss: 0.2606, G_B_loss: 0.6678\n",
            "Epoch [15/70], Step [821/1231], D_A_loss: 0.2224, D_B_loss: 0.1776, G_A_loss: 0.5574, G_B_loss: 1.1992\n",
            "Epoch [15/70], Step [831/1231], D_A_loss: 0.1863, D_B_loss: 0.3036, G_A_loss: 0.8550, G_B_loss: 0.4802\n",
            "Epoch [15/70], Step [841/1231], D_A_loss: 0.1376, D_B_loss: 0.0481, G_A_loss: 0.3030, G_B_loss: 0.3409\n",
            "Epoch [15/70], Step [851/1231], D_A_loss: 0.0406, D_B_loss: 0.0334, G_A_loss: 0.7596, G_B_loss: 0.3258\n",
            "Epoch [15/70], Step [861/1231], D_A_loss: 0.0689, D_B_loss: 0.0785, G_A_loss: 0.6270, G_B_loss: 0.7344\n",
            "Epoch [15/70], Step [871/1231], D_A_loss: 0.2807, D_B_loss: 0.0498, G_A_loss: 0.6368, G_B_loss: 0.1780\n",
            "Epoch [15/70], Step [881/1231], D_A_loss: 0.2127, D_B_loss: 0.0370, G_A_loss: 0.4625, G_B_loss: 0.5487\n",
            "Epoch [15/70], Step [891/1231], D_A_loss: 0.1710, D_B_loss: 0.1001, G_A_loss: 0.3926, G_B_loss: 0.2333\n",
            "Epoch [15/70], Step [901/1231], D_A_loss: 0.0433, D_B_loss: 0.0620, G_A_loss: 0.8465, G_B_loss: 0.3236\n",
            "Epoch [15/70], Step [911/1231], D_A_loss: 0.0780, D_B_loss: 0.2688, G_A_loss: 0.1865, G_B_loss: 0.5367\n",
            "Epoch [15/70], Step [921/1231], D_A_loss: 0.0390, D_B_loss: 0.1292, G_A_loss: 0.6261, G_B_loss: 0.4080\n",
            "Epoch [15/70], Step [931/1231], D_A_loss: 0.2134, D_B_loss: 0.0557, G_A_loss: 0.5893, G_B_loss: 0.1934\n",
            "Epoch [15/70], Step [941/1231], D_A_loss: 0.0547, D_B_loss: 0.0330, G_A_loss: 0.3759, G_B_loss: 0.3288\n",
            "Epoch [15/70], Step [951/1231], D_A_loss: 0.1119, D_B_loss: 0.1079, G_A_loss: 0.4507, G_B_loss: 0.3711\n",
            "Epoch [15/70], Step [961/1231], D_A_loss: 0.0521, D_B_loss: 0.1915, G_A_loss: 0.2370, G_B_loss: 0.5891\n",
            "Epoch [16/70], Step [1/1231], D_A_loss: 0.0992, D_B_loss: 0.0874, G_A_loss: 0.5674, G_B_loss: 0.7180\n",
            "Epoch [16/70], Step [11/1231], D_A_loss: 0.1519, D_B_loss: 0.0875, G_A_loss: 0.4632, G_B_loss: 0.3209\n",
            "Epoch [16/70], Step [21/1231], D_A_loss: 0.1347, D_B_loss: 0.0347, G_A_loss: 0.2925, G_B_loss: 0.4703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting and saving the average losses over the epochs and also creating a GIF of the generated images."
      ],
      "metadata": {
        "id": "I6EhgSCvhN42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot average losses\n",
        "avg_losses = []\n",
        "avg_losses.append(D_A_avg_losses)\n",
        "avg_losses.append(D_B_avg_losses)\n",
        "avg_losses.append(G_A_avg_losses)\n",
        "avg_losses.append(G_B_avg_losses)\n",
        "avg_losses.append(cycle_A_avg_losses)\n",
        "avg_losses.append(cycle_B_avg_losses)\n",
        "plot_loss(avg_losses, params.num_epochs, save=True, save_dir=plot_gif_dir)\n",
        "\n",
        "# Make gif\n",
        "make_gif(params.dataset, params.num_epochs, save_dir=plot_gif_dir, source_dir=save_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HADHCe9GxxhJ",
        "outputId": "73f202bd-facf-4cda-d8ef-b2cee45d9e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-aece8031fe14>:125: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  gen_image_plots.append(imageio.imread(save_fn))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the Model"
      ],
      "metadata": {
        "id": "K06XHQ5Kh8bc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating test results for both the A-to-B and B-to-A directions. For each direction, we loop through the test data loader and generate fake images using the corresponding generator"
      ],
      "metadata": {
        "id": "Bzo0Y44ZhRGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, real_A in enumerate(test_data_loader_A):\n",
        "    # input image data\n",
        "    real_A = Variable(real_A.cuda())\n",
        "    \n",
        "    # A --> B --> A\n",
        "    fake_B = G_A(real_A)\n",
        "    recon_A = G_B(fake_B)\n",
        "    \n",
        "    # Show result for test data\n",
        "    plot_test_result(real_A, fake_B, recon_A, i, save=True, save_dir=test_res_dir + 'AtoB/')\n",
        "\n",
        "    print('%d images are generated.' % (i + 1))\n",
        "\n",
        "for i, real_B in enumerate(test_data_loader_B):\n",
        "\n",
        "    # input image data\n",
        "    real_B = Variable(real_B.cuda())\n",
        "\n",
        "    # B -> A -> B\n",
        "    fake_A = G_B(real_B)\n",
        "    recon_B = G_A(fake_A)\n",
        "\n",
        "    # Show result for test data\n",
        "    plot_test_result(real_B, fake_A, recon_B, i, save=True, save_dir=test_res_dir + 'BtoA/')\n",
        "\n",
        "    print('%d images are generated.' % (i + 1))"
      ],
      "metadata": {
        "id": "s_u_Z-oRhSEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2aab3a2-4bf1-465f-d310-a0255f16c9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 images are generated.\n",
            "2 images are generated.\n",
            "3 images are generated.\n",
            "4 images are generated.\n",
            "5 images are generated.\n",
            "6 images are generated.\n",
            "7 images are generated.\n",
            "8 images are generated.\n",
            "9 images are generated.\n",
            "10 images are generated.\n",
            "11 images are generated.\n",
            "12 images are generated.\n",
            "13 images are generated.\n",
            "14 images are generated.\n",
            "15 images are generated.\n",
            "16 images are generated.\n",
            "17 images are generated.\n",
            "18 images are generated.\n",
            "19 images are generated.\n",
            "20 images are generated.\n",
            "21 images are generated.\n",
            "22 images are generated.\n",
            "23 images are generated.\n",
            "24 images are generated.\n",
            "25 images are generated.\n",
            "26 images are generated.\n",
            "27 images are generated.\n",
            "28 images are generated.\n",
            "29 images are generated.\n",
            "30 images are generated.\n",
            "31 images are generated.\n",
            "32 images are generated.\n",
            "33 images are generated.\n",
            "34 images are generated.\n",
            "35 images are generated.\n",
            "36 images are generated.\n",
            "37 images are generated.\n",
            "38 images are generated.\n",
            "39 images are generated.\n",
            "40 images are generated.\n",
            "41 images are generated.\n",
            "42 images are generated.\n",
            "43 images are generated.\n",
            "44 images are generated.\n",
            "45 images are generated.\n",
            "46 images are generated.\n",
            "47 images are generated.\n",
            "48 images are generated.\n",
            "49 images are generated.\n",
            "50 images are generated.\n",
            "51 images are generated.\n",
            "52 images are generated.\n",
            "53 images are generated.\n",
            "54 images are generated.\n",
            "55 images are generated.\n",
            "56 images are generated.\n",
            "57 images are generated.\n",
            "58 images are generated.\n",
            "59 images are generated.\n",
            "60 images are generated.\n",
            "61 images are generated.\n",
            "62 images are generated.\n",
            "63 images are generated.\n",
            "64 images are generated.\n",
            "65 images are generated.\n",
            "66 images are generated.\n",
            "67 images are generated.\n",
            "68 images are generated.\n",
            "69 images are generated.\n",
            "70 images are generated.\n",
            "71 images are generated.\n",
            "72 images are generated.\n",
            "73 images are generated.\n",
            "74 images are generated.\n",
            "75 images are generated.\n",
            "76 images are generated.\n",
            "77 images are generated.\n",
            "78 images are generated.\n",
            "79 images are generated.\n",
            "80 images are generated.\n",
            "81 images are generated.\n",
            "82 images are generated.\n",
            "83 images are generated.\n",
            "84 images are generated.\n",
            "85 images are generated.\n",
            "86 images are generated.\n",
            "87 images are generated.\n",
            "88 images are generated.\n",
            "89 images are generated.\n",
            "90 images are generated.\n",
            "91 images are generated.\n",
            "92 images are generated.\n",
            "93 images are generated.\n",
            "94 images are generated.\n",
            "95 images are generated.\n",
            "96 images are generated.\n",
            "97 images are generated.\n",
            "98 images are generated.\n",
            "99 images are generated.\n",
            "100 images are generated.\n",
            "101 images are generated.\n",
            "102 images are generated.\n",
            "103 images are generated.\n",
            "104 images are generated.\n",
            "105 images are generated.\n",
            "106 images are generated.\n",
            "107 images are generated.\n",
            "108 images are generated.\n",
            "109 images are generated.\n",
            "110 images are generated.\n",
            "111 images are generated.\n",
            "112 images are generated.\n",
            "113 images are generated.\n",
            "114 images are generated.\n",
            "115 images are generated.\n",
            "116 images are generated.\n",
            "117 images are generated.\n",
            "118 images are generated.\n",
            "119 images are generated.\n",
            "120 images are generated.\n",
            "121 images are generated.\n",
            "122 images are generated.\n",
            "123 images are generated.\n",
            "124 images are generated.\n",
            "125 images are generated.\n",
            "126 images are generated.\n",
            "127 images are generated.\n",
            "128 images are generated.\n",
            "129 images are generated.\n",
            "130 images are generated.\n",
            "131 images are generated.\n",
            "132 images are generated.\n",
            "133 images are generated.\n",
            "134 images are generated.\n",
            "135 images are generated.\n",
            "136 images are generated.\n",
            "137 images are generated.\n",
            "138 images are generated.\n",
            "139 images are generated.\n",
            "140 images are generated.\n",
            "141 images are generated.\n",
            "142 images are generated.\n",
            "143 images are generated.\n",
            "144 images are generated.\n",
            "145 images are generated.\n",
            "146 images are generated.\n",
            "147 images are generated.\n",
            "148 images are generated.\n",
            "149 images are generated.\n",
            "150 images are generated.\n",
            "151 images are generated.\n",
            "152 images are generated.\n",
            "153 images are generated.\n",
            "154 images are generated.\n",
            "155 images are generated.\n",
            "156 images are generated.\n",
            "157 images are generated.\n",
            "158 images are generated.\n",
            "159 images are generated.\n",
            "160 images are generated.\n",
            "161 images are generated.\n",
            "162 images are generated.\n",
            "163 images are generated.\n",
            "164 images are generated.\n",
            "165 images are generated.\n",
            "166 images are generated.\n",
            "167 images are generated.\n",
            "168 images are generated.\n",
            "169 images are generated.\n",
            "170 images are generated.\n",
            "171 images are generated.\n",
            "172 images are generated.\n",
            "173 images are generated.\n",
            "174 images are generated.\n",
            "175 images are generated.\n",
            "176 images are generated.\n",
            "177 images are generated.\n",
            "178 images are generated.\n",
            "179 images are generated.\n",
            "180 images are generated.\n",
            "181 images are generated.\n",
            "182 images are generated.\n",
            "183 images are generated.\n",
            "184 images are generated.\n",
            "185 images are generated.\n",
            "186 images are generated.\n",
            "187 images are generated.\n",
            "188 images are generated.\n",
            "189 images are generated.\n",
            "190 images are generated.\n",
            "191 images are generated.\n",
            "192 images are generated.\n",
            "193 images are generated.\n",
            "194 images are generated.\n",
            "195 images are generated.\n",
            "196 images are generated.\n",
            "197 images are generated.\n",
            "198 images are generated.\n",
            "199 images are generated.\n",
            "200 images are generated.\n",
            "201 images are generated.\n",
            "202 images are generated.\n",
            "203 images are generated.\n",
            "204 images are generated.\n",
            "205 images are generated.\n",
            "206 images are generated.\n",
            "207 images are generated.\n",
            "208 images are generated.\n",
            "209 images are generated.\n",
            "210 images are generated.\n",
            "211 images are generated.\n",
            "212 images are generated.\n",
            "213 images are generated.\n",
            "214 images are generated.\n",
            "215 images are generated.\n",
            "216 images are generated.\n",
            "217 images are generated.\n",
            "218 images are generated.\n",
            "219 images are generated.\n",
            "220 images are generated.\n",
            "221 images are generated.\n",
            "222 images are generated.\n",
            "223 images are generated.\n",
            "224 images are generated.\n",
            "225 images are generated.\n",
            "226 images are generated.\n",
            "227 images are generated.\n",
            "228 images are generated.\n",
            "229 images are generated.\n",
            "230 images are generated.\n",
            "231 images are generated.\n",
            "232 images are generated.\n",
            "233 images are generated.\n",
            "234 images are generated.\n",
            "235 images are generated.\n",
            "236 images are generated.\n",
            "237 images are generated.\n",
            "238 images are generated.\n",
            "239 images are generated.\n",
            "240 images are generated.\n",
            "241 images are generated.\n",
            "242 images are generated.\n",
            "243 images are generated.\n",
            "244 images are generated.\n",
            "245 images are generated.\n",
            "246 images are generated.\n",
            "247 images are generated.\n",
            "248 images are generated.\n",
            "249 images are generated.\n",
            "250 images are generated.\n",
            "251 images are generated.\n",
            "252 images are generated.\n",
            "253 images are generated.\n",
            "254 images are generated.\n",
            "255 images are generated.\n",
            "256 images are generated.\n",
            "257 images are generated.\n",
            "258 images are generated.\n",
            "259 images are generated.\n",
            "260 images are generated.\n",
            "261 images are generated.\n",
            "262 images are generated.\n",
            "263 images are generated.\n",
            "264 images are generated.\n",
            "265 images are generated.\n",
            "266 images are generated.\n",
            "267 images are generated.\n",
            "268 images are generated.\n",
            "269 images are generated.\n",
            "270 images are generated.\n",
            "271 images are generated.\n",
            "272 images are generated.\n",
            "273 images are generated.\n",
            "274 images are generated.\n",
            "275 images are generated.\n",
            "276 images are generated.\n",
            "277 images are generated.\n",
            "278 images are generated.\n",
            "279 images are generated.\n",
            "280 images are generated.\n",
            "281 images are generated.\n",
            "282 images are generated.\n",
            "283 images are generated.\n",
            "284 images are generated.\n",
            "285 images are generated.\n",
            "286 images are generated.\n",
            "287 images are generated.\n",
            "288 images are generated.\n",
            "289 images are generated.\n",
            "290 images are generated.\n",
            "291 images are generated.\n",
            "292 images are generated.\n",
            "293 images are generated.\n",
            "294 images are generated.\n",
            "295 images are generated.\n",
            "296 images are generated.\n",
            "297 images are generated.\n",
            "298 images are generated.\n",
            "299 images are generated.\n",
            "300 images are generated.\n",
            "301 images are generated.\n",
            "302 images are generated.\n",
            "303 images are generated.\n",
            "304 images are generated.\n",
            "305 images are generated.\n",
            "306 images are generated.\n",
            "307 images are generated.\n",
            "308 images are generated.\n",
            "309 images are generated.\n",
            "1 images are generated.\n",
            "2 images are generated.\n",
            "3 images are generated.\n",
            "4 images are generated.\n",
            "5 images are generated.\n",
            "6 images are generated.\n",
            "7 images are generated.\n",
            "8 images are generated.\n",
            "9 images are generated.\n",
            "10 images are generated.\n",
            "11 images are generated.\n",
            "12 images are generated.\n",
            "13 images are generated.\n",
            "14 images are generated.\n",
            "15 images are generated.\n",
            "16 images are generated.\n",
            "17 images are generated.\n",
            "18 images are generated.\n",
            "19 images are generated.\n",
            "20 images are generated.\n",
            "21 images are generated.\n",
            "22 images are generated.\n",
            "23 images are generated.\n",
            "24 images are generated.\n",
            "25 images are generated.\n",
            "26 images are generated.\n",
            "27 images are generated.\n",
            "28 images are generated.\n",
            "29 images are generated.\n",
            "30 images are generated.\n",
            "31 images are generated.\n",
            "32 images are generated.\n",
            "33 images are generated.\n",
            "34 images are generated.\n",
            "35 images are generated.\n",
            "36 images are generated.\n",
            "37 images are generated.\n",
            "38 images are generated.\n",
            "39 images are generated.\n",
            "40 images are generated.\n",
            "41 images are generated.\n",
            "42 images are generated.\n",
            "43 images are generated.\n",
            "44 images are generated.\n",
            "45 images are generated.\n",
            "46 images are generated.\n",
            "47 images are generated.\n",
            "48 images are generated.\n",
            "49 images are generated.\n",
            "50 images are generated.\n",
            "51 images are generated.\n",
            "52 images are generated.\n",
            "53 images are generated.\n",
            "54 images are generated.\n",
            "55 images are generated.\n",
            "56 images are generated.\n",
            "57 images are generated.\n",
            "58 images are generated.\n",
            "59 images are generated.\n",
            "60 images are generated.\n",
            "61 images are generated.\n",
            "62 images are generated.\n",
            "63 images are generated.\n",
            "64 images are generated.\n",
            "65 images are generated.\n",
            "66 images are generated.\n",
            "67 images are generated.\n",
            "68 images are generated.\n",
            "69 images are generated.\n",
            "70 images are generated.\n",
            "71 images are generated.\n",
            "72 images are generated.\n",
            "73 images are generated.\n",
            "74 images are generated.\n",
            "75 images are generated.\n",
            "76 images are generated.\n",
            "77 images are generated.\n",
            "78 images are generated.\n",
            "79 images are generated.\n",
            "80 images are generated.\n",
            "81 images are generated.\n",
            "82 images are generated.\n",
            "83 images are generated.\n",
            "84 images are generated.\n",
            "85 images are generated.\n",
            "86 images are generated.\n",
            "87 images are generated.\n",
            "88 images are generated.\n",
            "89 images are generated.\n",
            "90 images are generated.\n",
            "91 images are generated.\n",
            "92 images are generated.\n",
            "93 images are generated.\n",
            "94 images are generated.\n",
            "95 images are generated.\n",
            "96 images are generated.\n",
            "97 images are generated.\n",
            "98 images are generated.\n",
            "99 images are generated.\n",
            "100 images are generated.\n",
            "101 images are generated.\n",
            "102 images are generated.\n",
            "103 images are generated.\n",
            "104 images are generated.\n",
            "105 images are generated.\n",
            "106 images are generated.\n",
            "107 images are generated.\n",
            "108 images are generated.\n",
            "109 images are generated.\n",
            "110 images are generated.\n",
            "111 images are generated.\n",
            "112 images are generated.\n",
            "113 images are generated.\n",
            "114 images are generated.\n",
            "115 images are generated.\n",
            "116 images are generated.\n",
            "117 images are generated.\n",
            "118 images are generated.\n",
            "119 images are generated.\n",
            "120 images are generated.\n",
            "121 images are generated.\n",
            "122 images are generated.\n",
            "123 images are generated.\n",
            "124 images are generated.\n",
            "125 images are generated.\n",
            "126 images are generated.\n",
            "127 images are generated.\n",
            "128 images are generated.\n",
            "129 images are generated.\n",
            "130 images are generated.\n",
            "131 images are generated.\n",
            "132 images are generated.\n",
            "133 images are generated.\n",
            "134 images are generated.\n",
            "135 images are generated.\n",
            "136 images are generated.\n",
            "137 images are generated.\n",
            "138 images are generated.\n",
            "139 images are generated.\n",
            "140 images are generated.\n",
            "141 images are generated.\n",
            "142 images are generated.\n",
            "143 images are generated.\n",
            "144 images are generated.\n",
            "145 images are generated.\n",
            "146 images are generated.\n",
            "147 images are generated.\n",
            "148 images are generated.\n",
            "149 images are generated.\n",
            "150 images are generated.\n",
            "151 images are generated.\n",
            "152 images are generated.\n",
            "153 images are generated.\n",
            "154 images are generated.\n",
            "155 images are generated.\n",
            "156 images are generated.\n",
            "157 images are generated.\n",
            "158 images are generated.\n",
            "159 images are generated.\n",
            "160 images are generated.\n",
            "161 images are generated.\n",
            "162 images are generated.\n",
            "163 images are generated.\n",
            "164 images are generated.\n",
            "165 images are generated.\n",
            "166 images are generated.\n",
            "167 images are generated.\n",
            "168 images are generated.\n",
            "169 images are generated.\n",
            "170 images are generated.\n",
            "171 images are generated.\n",
            "172 images are generated.\n",
            "173 images are generated.\n",
            "174 images are generated.\n",
            "175 images are generated.\n",
            "176 images are generated.\n",
            "177 images are generated.\n",
            "178 images are generated.\n",
            "179 images are generated.\n",
            "180 images are generated.\n",
            "181 images are generated.\n",
            "182 images are generated.\n",
            "183 images are generated.\n",
            "184 images are generated.\n",
            "185 images are generated.\n",
            "186 images are generated.\n",
            "187 images are generated.\n",
            "188 images are generated.\n",
            "189 images are generated.\n",
            "190 images are generated.\n",
            "191 images are generated.\n",
            "192 images are generated.\n",
            "193 images are generated.\n",
            "194 images are generated.\n",
            "195 images are generated.\n",
            "196 images are generated.\n",
            "197 images are generated.\n",
            "198 images are generated.\n",
            "199 images are generated.\n",
            "200 images are generated.\n",
            "201 images are generated.\n",
            "202 images are generated.\n",
            "203 images are generated.\n",
            "204 images are generated.\n",
            "205 images are generated.\n",
            "206 images are generated.\n",
            "207 images are generated.\n",
            "208 images are generated.\n",
            "209 images are generated.\n",
            "210 images are generated.\n",
            "211 images are generated.\n",
            "212 images are generated.\n",
            "213 images are generated.\n",
            "214 images are generated.\n",
            "215 images are generated.\n",
            "216 images are generated.\n",
            "217 images are generated.\n",
            "218 images are generated.\n",
            "219 images are generated.\n",
            "220 images are generated.\n",
            "221 images are generated.\n",
            "222 images are generated.\n",
            "223 images are generated.\n",
            "224 images are generated.\n",
            "225 images are generated.\n",
            "226 images are generated.\n",
            "227 images are generated.\n",
            "228 images are generated.\n",
            "229 images are generated.\n",
            "230 images are generated.\n",
            "231 images are generated.\n",
            "232 images are generated.\n",
            "233 images are generated.\n",
            "234 images are generated.\n",
            "235 images are generated.\n",
            "236 images are generated.\n",
            "237 images are generated.\n",
            "238 images are generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the results"
      ],
      "metadata": {
        "id": "eOOrObSyhV4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/results.zip /content/results\n",
        "!zip -r /content/test_results.zip /content/test_results\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/results.zip\")\n",
        "files.download(\"/content/test_results.zip\")"
      ],
      "metadata": {
        "id": "ktkzyOrGFLPg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4a559bb2-a70b-410e-afd6-3d99c7ea9e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/results/ (stored 0%)\n",
            "  adding: content/results/plot_gifLoss_values_epoch_1.png (deflated 18%)\n",
            "  adding: content/results/summer2winter_CycleGAN_epochs_1.gif (deflated 1%)\n",
            "  adding: content/results/Loss_values_epoch_1.png (deflated 18%)\n",
            "  adding: content/results/plot_gif/ (stored 0%)\n",
            "  adding: content/results/plot_gif/summer2winter_CycleGAN_epochs_1.gif (deflated 1%)\n",
            "  adding: content/results/plot_gif/Loss_values_epoch_1.png (deflated 18%)\n",
            "  adding: content/results/Result_epoch_1.png (deflated 1%)\n",
            "  adding: content/test_results/ (stored 0%)\n",
            "  adding: content/test_results/BtoA/ (stored 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_57.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_216.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_78.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_169.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_81.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_100.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_43.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_149.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_46.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_189.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_159.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_156.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_97.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_16.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_235.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_125.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_117.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_35.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_197.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_180.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_215.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_86.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_4.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_161.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_20.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_72.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_124.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_208.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_138.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_109.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_95.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_85.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_101.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_132.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_234.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_122.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_34.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_183.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_93.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_184.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_53.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_108.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_71.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_44.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_231.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_69.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_7.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_228.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_96.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_230.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_213.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_155.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_131.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_217.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_15.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_25.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_167.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_158.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_141.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_128.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_209.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_206.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_55.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_222.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_127.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_236.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_203.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_19.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_104.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_165.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_207.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_188.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_135.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_76.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_9.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_92.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_192.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_137.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_140.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_181.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_146.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_11.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_39.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_225.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_130.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_3.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_114.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_142.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_45.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_28.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_174.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_111.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_175.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_187.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_37.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_123.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_157.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_41.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_116.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_115.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_205.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_136.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_126.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_12.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_52.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_134.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_67.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_103.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_219.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_38.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_36.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_190.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_229.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_186.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_237.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_194.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_106.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_172.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_49.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_6.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_42.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_8.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_50.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_29.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_118.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_129.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_178.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_199.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_27.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_48.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_13.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_14.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_147.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_232.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_226.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_145.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_202.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_60.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_112.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_223.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_61.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_153.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_22.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_210.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_17.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_105.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_32.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_73.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_110.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_179.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_160.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_201.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_162.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_233.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_64.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_224.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_70.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_89.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_21.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_59.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_65.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_182.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_144.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_18.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_51.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_5.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_98.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_2.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_121.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_214.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_99.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_90.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_66.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_62.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_31.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_185.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_63.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_74.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_139.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_163.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_238.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_218.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_204.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_148.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_58.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_94.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_151.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_176.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_88.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_83.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_168.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_84.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_196.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_143.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_33.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_166.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_227.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_193.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_154.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_23.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_120.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_26.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_75.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_191.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_47.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_113.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_195.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_1.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_24.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_91.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_150.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_77.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_82.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_200.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_198.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_40.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_152.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_212.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_220.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_211.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_30.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_177.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_133.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_10.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_56.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_68.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_107.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_221.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_119.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_54.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_173.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_171.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_164.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_80.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_102.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_170.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_79.png (deflated 0%)\n",
            "  adding: content/test_results/BtoA/Test_result_87.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/ (stored 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_57.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_216.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_78.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_169.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_81.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_100.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_43.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_274.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_149.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_46.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_189.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_248.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_159.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_156.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_97.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_16.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_235.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_125.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_305.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_245.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_117.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_35.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_197.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_180.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_215.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_86.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_4.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_294.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_161.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_20.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_72.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_282.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_250.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_124.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_283.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_276.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_295.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_208.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_264.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_138.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_109.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_95.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_85.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_101.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_273.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_132.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_234.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_122.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_34.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_183.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_93.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_275.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_300.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_281.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_184.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_53.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_108.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_71.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_44.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_231.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_69.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_7.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_228.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_96.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_230.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_213.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_155.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_131.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_217.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_15.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_25.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_167.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_158.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_141.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_128.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_241.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_209.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_206.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_55.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_222.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_242.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_127.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_307.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_236.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_203.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_19.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_104.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_165.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_207.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_188.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_135.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_284.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_76.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_9.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_92.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_192.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_137.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_140.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_181.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_146.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_11.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_285.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_239.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_39.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_286.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_246.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_306.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_225.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_130.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_3.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_293.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_114.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_142.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_296.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_256.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_45.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_28.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_174.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_254.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_111.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_175.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_187.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_37.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_123.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_157.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_41.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_116.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_115.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_205.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_136.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_280.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_271.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_272.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_126.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_12.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_288.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_52.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_134.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_67.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_103.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_219.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_292.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_38.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_247.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_36.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_190.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_229.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_186.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_237.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_289.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_194.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_266.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_106.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_172.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_240.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_49.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_6.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_301.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_42.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_8.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_50.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_287.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_29.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_118.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_129.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_178.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_199.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_27.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_48.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_13.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_297.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_258.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_14.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_147.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_232.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_226.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_145.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_251.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_202.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_60.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_112.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_263.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_223.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_61.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_270.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_153.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_22.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_210.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_17.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_105.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_32.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_73.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_110.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_179.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_160.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_201.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_162.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_233.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_64.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_224.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_70.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_89.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_21.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_59.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_65.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_182.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_144.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_308.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_18.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_51.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_5.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_244.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_98.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_2.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_121.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_214.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_99.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_90.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_66.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_62.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_31.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_185.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_255.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_63.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_74.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_257.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_262.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_278.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_139.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_163.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_238.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_218.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_204.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_148.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_58.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_94.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_268.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_309.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_151.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_176.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_88.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_83.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_290.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_168.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_84.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_196.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_269.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_143.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_253.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_33.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_166.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_227.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_193.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_154.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_23.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_120.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_26.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_75.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_191.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_302.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_47.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_113.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_195.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_1.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_24.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_91.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_150.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_77.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_82.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_291.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_200.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_298.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_198.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_304.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_249.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_40.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_152.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_212.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_299.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_261.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_220.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_243.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_211.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_30.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_177.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_133.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_10.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_252.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_56.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_279.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_68.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_259.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_107.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_221.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_260.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_119.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_277.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_54.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_173.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_267.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_171.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_164.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_265.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_303.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_80.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_102.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_170.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_79.png (deflated 0%)\n",
            "  adding: content/test_results/AtoB/Test_result_87.png (deflated 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6f677f4b-d25f-4660-8033-6fce5a54f0fb\", \"results.zip\", 416013)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9fe00b06-4430-4fc4-8019-151fcf4a107f\", \"test_results.zip\", 268110887)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}